{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "banned-croatia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_score, f1_score, recall_score, classification_report\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "weird-animation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "earned-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = AutoTokenizer.from_pretrained('KB/bert-base-swedish-cased', use_fast=False)\n",
    "#model = AutoModel.from_pretrained('KB/bert-base-swedish-cased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "revolutionary-pioneer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs = tok(['hälsa hälsan hälsans'], return_tensors=\"pt\", padding='max_length', max_length = 512, truncation=True)\n",
    "#inputs = tok(X[:10].values.tolist(), return_tensors=\"pt\", padding='max_length', max_length = 512, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "supposed-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs = model(**inputs)\n",
    "#outputs = outputs['pooler_output'].detach().numpy().reshape(X.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "israeli-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLPTransformer(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        print('Init called')\n",
    "        self.model_name = 'KB/bert-base-swedish-cased'\n",
    "        self.Bert = AutoModel.from_pretrained(self.model_name)\n",
    "        self.Tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.batch_size = 10\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        print('Fit called')\n",
    "        \n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def partial_fit(self, X, y=None):\n",
    "        print('Partial Fit called')\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        print('Transform Called')\n",
    "       \n",
    "        # Transform input tokens. This is most efficient if done in one batch \n",
    "        inputs = self.Tokenizer(X.values.tolist(), return_tensors=\"pt\", padding='max_length', max_length = 512, truncation=True)\n",
    "\n",
    "        # Run Bert model, We must mini batch this in order to not overflow the memory of the system\n",
    "        transformed = []\n",
    "        \n",
    "        batches = int(np.ceil(X.shape[0] / self.batch_size))\n",
    "        for batchId in range(batches):\n",
    "            print(f'Running batch {batchId+1}/{batches}')\n",
    "        \n",
    "            inputs_batch = {}\n",
    "            for key in inputs.keys():\n",
    "                inputs_batch[key] = inputs[key][batchId * self.batch_size:(batchId + 1) * self.batch_size]\n",
    "\n",
    "            outputs = self.Bert(**inputs_batch)\n",
    "            outputs = outputs['pooler_output'].detach().numpy()\n",
    "            print(f'output shape: {outputs.shape}')\n",
    "            transformed.extend(outputs)\n",
    "        \n",
    "        transformed = np.array(transformed)\n",
    "        print(f'transformed.shape: {transformed.shape}')\n",
    "        \n",
    "        return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cubic-professor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init called\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at KB/bert-base-swedish-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([    \n",
    "            ('nlpTransformer', NLPTransformer()),\n",
    "            ('clf', RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "electrical-poland",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ultimate-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/bbc-text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unnecessary-source",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "worthy-aberdeen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tech', 'business', 'sport', 'entertainment', 'politics'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "renewable-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.get_dummies(df, columns=['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "compressed-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "surprised-hughes",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df2.drop(columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "apart-candy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-47-01876a210620>:3: DtypeWarning: Columns (1,3,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,39,41,43,45,47,49,51,52,54,56,57,58) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../data/CRMIncidents_Anonymized_Complete_Table.csv')\n"
     ]
    }
   ],
   "source": [
    "#Test data anonymized\n",
    "#df = pd.read_csv('../data/CRMIncidents_Anonymized.csv')\n",
    "df = pd.read_csv('../data/CRMIncidents_Anonymized_Complete_Table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "political-plant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CRMIncidentId</th>\n",
       "      <th>IncidentId</th>\n",
       "      <th>LineId</th>\n",
       "      <th>Linje</th>\n",
       "      <th>JourneyId</th>\n",
       "      <th>TurNummer</th>\n",
       "      <th>Trafikslag</th>\n",
       "      <th>Ankomstdag</th>\n",
       "      <th>...</th>\n",
       "      <th>Enhet</th>\n",
       "      <th>Queue_SK</th>\n",
       "      <th>Kö</th>\n",
       "      <th>ModifiedOn</th>\n",
       "      <th>ContactId</th>\n",
       "      <th>Contact_SK</th>\n",
       "      <th>iBID</th>\n",
       "      <th>IsActive</th>\n",
       "      <th>TicketId</th>\n",
       "      <th>Beskrivning_Anonymized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>673326.0</td>\n",
       "      <td>77DE23B5-43D8-E811-80F6-005056B63599</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-10-25</td>\n",
       "      <td>...</td>\n",
       "      <td>Kundtjänst</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Support Synpunkter</td>\n",
       "      <td>2018-10-29 11:33:19</td>\n",
       "      <td>586769.0</td>\n",
       "      <td>C0BDFF48-2C0B-E811-80F1-005056B64D75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hej,\\r\\r\\n \\r\\r\\nHar nu fått tag i föraren som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>673354.0</td>\n",
       "      <td>EBD68435-41D8-E811-80F6-005056B63599</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-10-25</td>\n",
       "      <td>...</td>\n",
       "      <td>Kundtjänst</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Support Synpunkter</td>\n",
       "      <td>2018-11-08 08:17:09</td>\n",
       "      <td>331145.0</td>\n",
       "      <td>E429FD9A-5DEC-E411-80D6-0050569071BE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buss 000 00:00\\r\\r\\n\\r\\r\\nKristianstad Hästtor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>673617.0</td>\n",
       "      <td>3ED0AA37-16D9-E811-80F4-005056B62B18</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-10-26</td>\n",
       "      <td>...</td>\n",
       "      <td>Kundtjänst</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Support Synpunkter</td>\n",
       "      <td>2021-10-07 08:49:10</td>\n",
       "      <td>726145.0</td>\n",
       "      <td>12F4B35F-16D9-E811-80F4-005056B62B18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Skadeanmälan för påkörning av bil bakifrån vid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>673807.0</td>\n",
       "      <td>AAA91AC9-E0D8-E811-80F5-005056B64D75</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-10-26</td>\n",
       "      <td>...</td>\n",
       "      <td>Kundtjänst</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Support Synpunkter</td>\n",
       "      <td>2018-11-08 10:36:12</td>\n",
       "      <td>603794.0</td>\n",
       "      <td>56A30A33-A32D-E811-80F2-005056B62B18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hej, \\r\\r\\nVarför heter en av hållplatserna i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>673850.0</td>\n",
       "      <td>5F1165E6-63D9-E811-80F5-005056B64D75</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-10-26</td>\n",
       "      <td>...</td>\n",
       "      <td>Kundtjänst</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Support Synpunkter</td>\n",
       "      <td>2019-11-27 15:06:13</td>\n",
       "      <td>22229.0</td>\n",
       "      <td>383EAEB1-1DEB-E411-80D8-005056903A38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hej!\\r\\r\\nHar en fråga som gäller busskurerna ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1 Unnamed: 0  CRMIncidentId  \\\n",
       "0             0          0       673326.0   \n",
       "1             1          1       673354.0   \n",
       "2             2          2       673617.0   \n",
       "3             3          3       673807.0   \n",
       "4             4          4       673850.0   \n",
       "\n",
       "                             IncidentId  LineId Linje  JourneyId TurNummer  \\\n",
       "0  77DE23B5-43D8-E811-80F6-005056B63599    -1.0   NaN       -1.0       NaN   \n",
       "1  EBD68435-41D8-E811-80F6-005056B63599    -1.0   NaN       -1.0       NaN   \n",
       "2  3ED0AA37-16D9-E811-80F4-005056B62B18    -1.0   NaN       -1.0       NaN   \n",
       "3  AAA91AC9-E0D8-E811-80F5-005056B64D75    -1.0   NaN       -1.0       NaN   \n",
       "4  5F1165E6-63D9-E811-80F5-005056B64D75    -1.0   NaN       -1.0       NaN   \n",
       "\n",
       "  Trafikslag  Ankomstdag  ...       Enhet Queue_SK                  Kö  \\\n",
       "0        NaN  2018-10-25  ...  Kundtjänst      8.0  Support Synpunkter   \n",
       "1        NaN  2018-10-25  ...  Kundtjänst      8.0  Support Synpunkter   \n",
       "2        NaN  2018-10-26  ...  Kundtjänst      8.0  Support Synpunkter   \n",
       "3        NaN  2018-10-26  ...  Kundtjänst      8.0  Support Synpunkter   \n",
       "4        NaN  2018-10-26  ...  Kundtjänst      8.0  Support Synpunkter   \n",
       "\n",
       "            ModifiedOn ContactId                            Contact_SK iBID  \\\n",
       "0  2018-10-29 11:33:19  586769.0  C0BDFF48-2C0B-E811-80F1-005056B64D75  NaN   \n",
       "1  2018-11-08 08:17:09  331145.0  E429FD9A-5DEC-E411-80D6-0050569071BE  NaN   \n",
       "2  2021-10-07 08:49:10  726145.0  12F4B35F-16D9-E811-80F4-005056B62B18  NaN   \n",
       "3  2018-11-08 10:36:12  603794.0  56A30A33-A32D-E811-80F2-005056B62B18  NaN   \n",
       "4  2019-11-27 15:06:13   22229.0  383EAEB1-1DEB-E411-80D8-005056903A38  NaN   \n",
       "\n",
       "  IsActive TicketId                             Beskrivning_Anonymized  \n",
       "0     True      NaN  Hej,\\r\\r\\n \\r\\r\\nHar nu fått tag i föraren som...  \n",
       "1     True      NaN  Buss 000 00:00\\r\\r\\n\\r\\r\\nKristianstad Hästtor...  \n",
       "2     True      NaN  Skadeanmälan för påkörning av bil bakifrån vid...  \n",
       "3     True      NaN  Hej, \\r\\r\\nVarför heter en av hållplatserna i ...  \n",
       "4     True      NaN  Hej!\\r\\r\\nHar en fråga som gäller busskurerna ...  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "quarterly-physics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'CRMIncidentId', 'IncidentId', 'LineId',\n",
       "       'Linje', 'JourneyId', 'TurNummer', 'Trafikslag', 'Ankomstdag',\n",
       "       'Händelsedatum', 'Hanteratdatum', 'Ärendenummer', 'KategoriId11',\n",
       "       'Kategori11', 'KategoriId12', 'Kategori12', 'KategoriId13',\n",
       "       'Kategori13', 'KategoriId21', 'Kategori21', 'KategoriId22',\n",
       "       'Kategori22', 'KategoriId23', 'Kategori23', 'KategoriId31',\n",
       "       'Kategori31', 'KategoriId32', 'Kategori32', 'KategoriId33',\n",
       "       'Kategori33', 'KategoriId41', 'Kategori41', 'KategoriId42',\n",
       "       'Kategori42', 'KategoriId43', 'Kategori43', 'Titel', 'CaseType_SK',\n",
       "       'Ärendetyp', 'CaseOrigin_SK', 'Ursprung', 'Priority_SK', 'Prioritet',\n",
       "       'IncidentStage_SK', 'ÄrendeStatus', 'Owner_SK', 'Handläggare',\n",
       "       'BusinessUnit_SK', 'Enhet', 'Queue_SK', 'Kö', 'ModifiedOn', 'ContactId',\n",
       "       'Contact_SK', 'iBID', 'IsActive', 'TicketId', 'Beskrivning_Anonymized'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cordless-arrival",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:10000] #Max for this computer\n",
    "df = df[~df['Ärendetyp'].isna()]\n",
    "df = df[~df['Beskrivning_Anonymized'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "egyptian-diana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.210e+02, 5.880e+02, 0.000e+00, 1.200e+01, 0.000e+00, 2.960e+02,\n",
       "        8.573e+03, 0.000e+00, 5.000e+00, 5.000e+00]),\n",
       " array([0. , 0.6, 1.2, 1.8, 2.4, 3. , 3.6, 4.2, 4.8, 5.4, 6. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(df['Ärendetyp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "exceptional-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Beskrivning_Anonymized'].str.lower() #Lower case to slim the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "disciplinary-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.get_dummies(df['Ärendetyp'], columns=['Ärendetyp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "minimal-marketing",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = Y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "choice-embassy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Avvikelse', 'Beröm', 'Fråga', 'Förseningsersättning', 'Klagomål',\n",
       "       'Skada', 'Synpunkt/Önskemål'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "visible-avatar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 7)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "middle-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note in case of pytorch CrossEntropyLoss, the targets should be the class index, not one hot encoded\n",
    "Y = Y.values.argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "narrow-convenience",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 6, 5, ..., 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "satisfactory-charity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "demonstrated-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This could also be a target\n",
    "Y2 = pd.get_dummies(df['Prioritet'], columns=['Prioritet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-province",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "unable-conducting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hög</th>\n",
       "      <th>Normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hög  Normal\n",
       "0    0       1\n",
       "1    0       1\n",
       "2    1       0\n",
       "3    0       1\n",
       "4    0       1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "intermediate-lending",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    hej,\\r\\n \\r\\nhar nu fått tag i föraren som är ...\n",
       "1    buss 000 00:00\\r\\n\\r\\nkristianstad hästtorget ...\n",
       "2    skadeanmälan för påkörning av bil bakifrån vid...\n",
       "3    hej, \\r\\nvarför heter en av hållplatserna i lu...\n",
       "4    hej!\\r\\nhar en fråga som gäller busskurerna i ...\n",
       "Name: Beskrivning_Anonymized, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "certain-longer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hej, \\r\\nvarför heter en av hållplatserna i ludvigsborg kvarndamms gatan i hörby kommun, skåne? dels så finns det ingen väg som heter så där, den heter kvarndamsvägen. dessutom är hållplatsen på ludvigsborgsvägen. xxxx ni vidarebefordra detta till rätt avdelning så det blir ändrat för att inte göra det förvirrat för resenärerna?\\r\\nhälsningar fredrik\\r\\r\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "expressed-movement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avvikelse</th>\n",
       "      <th>Beröm</th>\n",
       "      <th>Fråga</th>\n",
       "      <th>Förseningsersättning</th>\n",
       "      <th>Klagomål</th>\n",
       "      <th>Skada</th>\n",
       "      <th>Synpunkt/Önskemål</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Avvikelse  Beröm  Fråga  Förseningsersättning  Klagomål  Skada  \\\n",
       "0          0      0      0                     0         1      0   \n",
       "1          0      0      0                     0         0      0   \n",
       "2          0      0      0                     0         0      1   \n",
       "3          0      0      0                     0         1      0   \n",
       "4          0      0      1                     0         0      0   \n",
       "\n",
       "   Synpunkt/Önskemål  \n",
       "0                  0  \n",
       "1                  1  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "duplicate-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tok('hej, Har nu fått tag i föraren som är', return_tensors=\"pt\", padding='max_length', max_length = 512, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sublime-cherry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2,  8819,    19,  1177,   346,   902,  1326,    31, 15367,    67,\n",
       "            54,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "variable-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "exceptional-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "copyrighted-cliff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "sophisticated-basket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avvikelse</th>\n",
       "      <th>Beröm</th>\n",
       "      <th>Fråga</th>\n",
       "      <th>Förseningsersättning</th>\n",
       "      <th>Klagomål</th>\n",
       "      <th>Skada</th>\n",
       "      <th>Synpunkt/Önskemål</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1186887</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136802</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380656</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125757</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381602</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Avvikelse  Beröm  Fråga  Förseningsersättning  Klagomål  Skada  \\\n",
       "1186887          0      0      0                     1         0      0   \n",
       "136802           0      0      0                     1         0      0   \n",
       "1380656          0      0      0                     0         0      1   \n",
       "1125757          0      0      0                     1         0      0   \n",
       "381602           0      0      0                     1         0      0   \n",
       "\n",
       "         Synpunkt/Önskemål  \n",
       "1186887                  0  \n",
       "136802                   0  \n",
       "1380656                  0  \n",
       "1125757                  0  \n",
       "381602                   0  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "catholic-auckland",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniBatcher():\n",
    "    def __init__(self, X, Y, batch_size=100, max_epochs=1):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.batch_size = batch_size\n",
    "        self.max_epochs = max_epochs\n",
    "        self.batchId = 0\n",
    "        self.epochId = 0\n",
    "        \n",
    "    def getBatchIterator(self):\n",
    "        self.batchId = 0\n",
    "        self.epochId = 0\n",
    "        \n",
    "        while True:\n",
    "            X_mini = self.X[self.batchId * self.batch_size:(self.batchId + 1) * self.batch_size]\n",
    "            Y_mini = self.Y[self.batchId * self.batch_size:(self.batchId + 1) * self.batch_size]\n",
    "            self.batchId += 1\n",
    "            print(self.batchId, self.epochId)\n",
    "            print(len(X_mini))\n",
    "            if len(X_mini) < self.batch_size:\n",
    "                self.epochId += 1\n",
    "                self.batchId = 0\n",
    "                if self.epochId <= self.max_epochs:\n",
    "                    print('will break')\n",
    "                    break\n",
    "            \n",
    "            yield X_mini, Y_mini\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "turkish-knight",
   "metadata": {},
   "outputs": [],
   "source": [
    "mMiniBatcher = MiniBatcher(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dimensional-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchIterator = mMiniBatcher.getBatchIterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "popular-wagner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit called\n",
      "Transform Called\n",
      "Running batch 1/800\n",
      "output shape: (10, 768)\n",
      "Running batch 2/800\n",
      "output shape: (10, 768)\n",
      "Running batch 3/800\n",
      "output shape: (10, 768)\n",
      "Running batch 4/800\n",
      "output shape: (10, 768)\n",
      "Running batch 5/800\n",
      "output shape: (10, 768)\n",
      "Running batch 6/800\n",
      "output shape: (10, 768)\n",
      "Running batch 7/800\n",
      "output shape: (10, 768)\n",
      "Running batch 8/800\n",
      "output shape: (10, 768)\n",
      "Running batch 9/800\n",
      "output shape: (10, 768)\n",
      "Running batch 10/800\n",
      "output shape: (10, 768)\n",
      "Running batch 11/800\n",
      "output shape: (10, 768)\n",
      "Running batch 12/800\n",
      "output shape: (10, 768)\n",
      "Running batch 13/800\n",
      "output shape: (10, 768)\n",
      "Running batch 14/800\n",
      "output shape: (10, 768)\n",
      "Running batch 15/800\n",
      "output shape: (10, 768)\n",
      "Running batch 16/800\n",
      "output shape: (10, 768)\n",
      "Running batch 17/800\n",
      "output shape: (10, 768)\n",
      "Running batch 18/800\n",
      "output shape: (10, 768)\n",
      "Running batch 19/800\n",
      "output shape: (10, 768)\n",
      "Running batch 20/800\n",
      "output shape: (10, 768)\n",
      "Running batch 21/800\n",
      "output shape: (10, 768)\n",
      "Running batch 22/800\n",
      "output shape: (10, 768)\n",
      "Running batch 23/800\n",
      "output shape: (10, 768)\n",
      "Running batch 24/800\n",
      "output shape: (10, 768)\n",
      "Running batch 25/800\n",
      "output shape: (10, 768)\n",
      "Running batch 26/800\n",
      "output shape: (10, 768)\n",
      "Running batch 27/800\n",
      "output shape: (10, 768)\n",
      "Running batch 28/800\n",
      "output shape: (10, 768)\n",
      "Running batch 29/800\n",
      "output shape: (10, 768)\n",
      "Running batch 30/800\n",
      "output shape: (10, 768)\n",
      "Running batch 31/800\n",
      "output shape: (10, 768)\n",
      "Running batch 32/800\n",
      "output shape: (10, 768)\n",
      "Running batch 33/800\n",
      "output shape: (10, 768)\n",
      "Running batch 34/800\n",
      "output shape: (10, 768)\n",
      "Running batch 35/800\n",
      "output shape: (10, 768)\n",
      "Running batch 36/800\n",
      "output shape: (10, 768)\n",
      "Running batch 37/800\n",
      "output shape: (10, 768)\n",
      "Running batch 38/800\n",
      "output shape: (10, 768)\n",
      "Running batch 39/800\n",
      "output shape: (10, 768)\n",
      "Running batch 40/800\n",
      "output shape: (10, 768)\n",
      "Running batch 41/800\n",
      "output shape: (10, 768)\n",
      "Running batch 42/800\n",
      "output shape: (10, 768)\n",
      "Running batch 43/800\n",
      "output shape: (10, 768)\n",
      "Running batch 44/800\n",
      "output shape: (10, 768)\n",
      "Running batch 45/800\n",
      "output shape: (10, 768)\n",
      "Running batch 46/800\n",
      "output shape: (10, 768)\n",
      "Running batch 47/800\n",
      "output shape: (10, 768)\n",
      "Running batch 48/800\n",
      "output shape: (10, 768)\n",
      "Running batch 49/800\n",
      "output shape: (10, 768)\n",
      "Running batch 50/800\n",
      "output shape: (10, 768)\n",
      "Running batch 51/800\n",
      "output shape: (10, 768)\n",
      "Running batch 52/800\n",
      "output shape: (10, 768)\n",
      "Running batch 53/800\n",
      "output shape: (10, 768)\n",
      "Running batch 54/800\n",
      "output shape: (10, 768)\n",
      "Running batch 55/800\n",
      "output shape: (10, 768)\n",
      "Running batch 56/800\n",
      "output shape: (10, 768)\n",
      "Running batch 57/800\n",
      "output shape: (10, 768)\n",
      "Running batch 58/800\n",
      "output shape: (10, 768)\n",
      "Running batch 59/800\n",
      "output shape: (10, 768)\n",
      "Running batch 60/800\n",
      "output shape: (10, 768)\n",
      "Running batch 61/800\n",
      "output shape: (10, 768)\n",
      "Running batch 62/800\n",
      "output shape: (10, 768)\n",
      "Running batch 63/800\n",
      "output shape: (10, 768)\n",
      "Running batch 64/800\n",
      "output shape: (10, 768)\n",
      "Running batch 65/800\n",
      "output shape: (10, 768)\n",
      "Running batch 66/800\n",
      "output shape: (10, 768)\n",
      "Running batch 67/800\n",
      "output shape: (10, 768)\n",
      "Running batch 68/800\n",
      "output shape: (10, 768)\n",
      "Running batch 69/800\n",
      "output shape: (10, 768)\n",
      "Running batch 70/800\n",
      "output shape: (10, 768)\n",
      "Running batch 71/800\n",
      "output shape: (10, 768)\n",
      "Running batch 72/800\n",
      "output shape: (10, 768)\n",
      "Running batch 73/800\n",
      "output shape: (10, 768)\n",
      "Running batch 74/800\n",
      "output shape: (10, 768)\n",
      "Running batch 75/800\n",
      "output shape: (10, 768)\n",
      "Running batch 76/800\n",
      "output shape: (10, 768)\n",
      "Running batch 77/800\n",
      "output shape: (10, 768)\n",
      "Running batch 78/800\n",
      "output shape: (10, 768)\n",
      "Running batch 79/800\n",
      "output shape: (10, 768)\n",
      "Running batch 80/800\n",
      "output shape: (10, 768)\n",
      "Running batch 81/800\n",
      "output shape: (10, 768)\n",
      "Running batch 82/800\n",
      "output shape: (10, 768)\n",
      "Running batch 83/800\n",
      "output shape: (10, 768)\n",
      "Running batch 84/800\n",
      "output shape: (10, 768)\n",
      "Running batch 85/800\n",
      "output shape: (10, 768)\n",
      "Running batch 86/800\n",
      "output shape: (10, 768)\n",
      "Running batch 87/800\n",
      "output shape: (10, 768)\n",
      "Running batch 88/800\n",
      "output shape: (10, 768)\n",
      "Running batch 89/800\n",
      "output shape: (10, 768)\n",
      "Running batch 90/800\n",
      "output shape: (10, 768)\n",
      "Running batch 91/800\n",
      "output shape: (10, 768)\n",
      "Running batch 92/800\n",
      "output shape: (10, 768)\n",
      "Running batch 93/800\n",
      "output shape: (10, 768)\n",
      "Running batch 94/800\n",
      "output shape: (10, 768)\n",
      "Running batch 95/800\n",
      "output shape: (10, 768)\n",
      "Running batch 96/800\n",
      "output shape: (10, 768)\n",
      "Running batch 97/800\n",
      "output shape: (10, 768)\n",
      "Running batch 98/800\n",
      "output shape: (10, 768)\n",
      "Running batch 99/800\n",
      "output shape: (10, 768)\n",
      "Running batch 100/800\n",
      "output shape: (10, 768)\n",
      "Running batch 101/800\n",
      "output shape: (10, 768)\n",
      "Running batch 102/800\n",
      "output shape: (10, 768)\n",
      "Running batch 103/800\n",
      "output shape: (10, 768)\n",
      "Running batch 104/800\n",
      "output shape: (10, 768)\n",
      "Running batch 105/800\n",
      "output shape: (10, 768)\n",
      "Running batch 106/800\n",
      "output shape: (10, 768)\n",
      "Running batch 107/800\n",
      "output shape: (10, 768)\n",
      "Running batch 108/800\n",
      "output shape: (10, 768)\n",
      "Running batch 109/800\n",
      "output shape: (10, 768)\n",
      "Running batch 110/800\n",
      "output shape: (10, 768)\n",
      "Running batch 111/800\n",
      "output shape: (10, 768)\n",
      "Running batch 112/800\n",
      "output shape: (10, 768)\n",
      "Running batch 113/800\n",
      "output shape: (10, 768)\n",
      "Running batch 114/800\n",
      "output shape: (10, 768)\n",
      "Running batch 115/800\n",
      "output shape: (10, 768)\n",
      "Running batch 116/800\n",
      "output shape: (10, 768)\n",
      "Running batch 117/800\n",
      "output shape: (10, 768)\n",
      "Running batch 118/800\n",
      "output shape: (10, 768)\n",
      "Running batch 119/800\n",
      "output shape: (10, 768)\n",
      "Running batch 120/800\n",
      "output shape: (10, 768)\n",
      "Running batch 121/800\n",
      "output shape: (10, 768)\n",
      "Running batch 122/800\n",
      "output shape: (10, 768)\n",
      "Running batch 123/800\n",
      "output shape: (10, 768)\n",
      "Running batch 124/800\n",
      "output shape: (10, 768)\n",
      "Running batch 125/800\n",
      "output shape: (10, 768)\n",
      "Running batch 126/800\n",
      "output shape: (10, 768)\n",
      "Running batch 127/800\n",
      "output shape: (10, 768)\n",
      "Running batch 128/800\n",
      "output shape: (10, 768)\n",
      "Running batch 129/800\n",
      "output shape: (10, 768)\n",
      "Running batch 130/800\n",
      "output shape: (10, 768)\n",
      "Running batch 131/800\n",
      "output shape: (10, 768)\n",
      "Running batch 132/800\n",
      "output shape: (10, 768)\n",
      "Running batch 133/800\n",
      "output shape: (10, 768)\n",
      "Running batch 134/800\n",
      "output shape: (10, 768)\n",
      "Running batch 135/800\n",
      "output shape: (10, 768)\n",
      "Running batch 136/800\n",
      "output shape: (10, 768)\n",
      "Running batch 137/800\n",
      "output shape: (10, 768)\n",
      "Running batch 138/800\n",
      "output shape: (10, 768)\n",
      "Running batch 139/800\n",
      "output shape: (10, 768)\n",
      "Running batch 140/800\n",
      "output shape: (10, 768)\n",
      "Running batch 141/800\n",
      "output shape: (10, 768)\n",
      "Running batch 142/800\n",
      "output shape: (10, 768)\n",
      "Running batch 143/800\n",
      "output shape: (10, 768)\n",
      "Running batch 144/800\n",
      "output shape: (10, 768)\n",
      "Running batch 145/800\n",
      "output shape: (10, 768)\n",
      "Running batch 146/800\n",
      "output shape: (10, 768)\n",
      "Running batch 147/800\n",
      "output shape: (10, 768)\n",
      "Running batch 148/800\n",
      "output shape: (10, 768)\n",
      "Running batch 149/800\n",
      "output shape: (10, 768)\n",
      "Running batch 150/800\n",
      "output shape: (10, 768)\n",
      "Running batch 151/800\n",
      "output shape: (10, 768)\n",
      "Running batch 152/800\n",
      "output shape: (10, 768)\n",
      "Running batch 153/800\n",
      "output shape: (10, 768)\n",
      "Running batch 154/800\n",
      "output shape: (10, 768)\n",
      "Running batch 155/800\n",
      "output shape: (10, 768)\n",
      "Running batch 156/800\n",
      "output shape: (10, 768)\n",
      "Running batch 157/800\n",
      "output shape: (10, 768)\n",
      "Running batch 158/800\n",
      "output shape: (10, 768)\n",
      "Running batch 159/800\n",
      "output shape: (10, 768)\n",
      "Running batch 160/800\n",
      "output shape: (10, 768)\n",
      "Running batch 161/800\n",
      "output shape: (10, 768)\n",
      "Running batch 162/800\n",
      "output shape: (10, 768)\n",
      "Running batch 163/800\n",
      "output shape: (10, 768)\n",
      "Running batch 164/800\n",
      "output shape: (10, 768)\n",
      "Running batch 165/800\n",
      "output shape: (10, 768)\n",
      "Running batch 166/800\n",
      "output shape: (10, 768)\n",
      "Running batch 167/800\n",
      "output shape: (10, 768)\n",
      "Running batch 168/800\n",
      "output shape: (10, 768)\n",
      "Running batch 169/800\n",
      "output shape: (10, 768)\n",
      "Running batch 170/800\n",
      "output shape: (10, 768)\n",
      "Running batch 171/800\n",
      "output shape: (10, 768)\n",
      "Running batch 172/800\n",
      "output shape: (10, 768)\n",
      "Running batch 173/800\n",
      "output shape: (10, 768)\n",
      "Running batch 174/800\n",
      "output shape: (10, 768)\n",
      "Running batch 175/800\n",
      "output shape: (10, 768)\n",
      "Running batch 176/800\n",
      "output shape: (10, 768)\n",
      "Running batch 177/800\n",
      "output shape: (10, 768)\n",
      "Running batch 178/800\n",
      "output shape: (10, 768)\n",
      "Running batch 179/800\n",
      "output shape: (10, 768)\n",
      "Running batch 180/800\n",
      "output shape: (10, 768)\n",
      "Running batch 181/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: (10, 768)\n",
      "Running batch 182/800\n",
      "output shape: (10, 768)\n",
      "Running batch 183/800\n",
      "output shape: (10, 768)\n",
      "Running batch 184/800\n",
      "output shape: (10, 768)\n",
      "Running batch 185/800\n",
      "output shape: (10, 768)\n",
      "Running batch 186/800\n",
      "output shape: (10, 768)\n",
      "Running batch 187/800\n",
      "output shape: (10, 768)\n",
      "Running batch 188/800\n",
      "output shape: (10, 768)\n",
      "Running batch 189/800\n",
      "output shape: (10, 768)\n",
      "Running batch 190/800\n",
      "output shape: (10, 768)\n",
      "Running batch 191/800\n",
      "output shape: (10, 768)\n",
      "Running batch 192/800\n",
      "output shape: (10, 768)\n",
      "Running batch 193/800\n",
      "output shape: (10, 768)\n",
      "Running batch 194/800\n",
      "output shape: (10, 768)\n",
      "Running batch 195/800\n",
      "output shape: (10, 768)\n",
      "Running batch 196/800\n",
      "output shape: (10, 768)\n",
      "Running batch 197/800\n",
      "output shape: (10, 768)\n",
      "Running batch 198/800\n",
      "output shape: (10, 768)\n",
      "Running batch 199/800\n",
      "output shape: (10, 768)\n",
      "Running batch 200/800\n",
      "output shape: (10, 768)\n",
      "Running batch 201/800\n",
      "output shape: (10, 768)\n",
      "Running batch 202/800\n",
      "output shape: (10, 768)\n",
      "Running batch 203/800\n",
      "output shape: (10, 768)\n",
      "Running batch 204/800\n",
      "output shape: (10, 768)\n",
      "Running batch 205/800\n",
      "output shape: (10, 768)\n",
      "Running batch 206/800\n",
      "output shape: (10, 768)\n",
      "Running batch 207/800\n",
      "output shape: (10, 768)\n",
      "Running batch 208/800\n",
      "output shape: (10, 768)\n",
      "Running batch 209/800\n",
      "output shape: (10, 768)\n",
      "Running batch 210/800\n",
      "output shape: (10, 768)\n",
      "Running batch 211/800\n",
      "output shape: (10, 768)\n",
      "Running batch 212/800\n",
      "output shape: (10, 768)\n",
      "Running batch 213/800\n",
      "output shape: (10, 768)\n",
      "Running batch 214/800\n",
      "output shape: (10, 768)\n",
      "Running batch 215/800\n",
      "output shape: (10, 768)\n",
      "Running batch 216/800\n",
      "output shape: (10, 768)\n",
      "Running batch 217/800\n",
      "output shape: (10, 768)\n",
      "Running batch 218/800\n",
      "output shape: (10, 768)\n",
      "Running batch 219/800\n",
      "output shape: (10, 768)\n",
      "Running batch 220/800\n",
      "output shape: (10, 768)\n",
      "Running batch 221/800\n",
      "output shape: (10, 768)\n",
      "Running batch 222/800\n",
      "output shape: (10, 768)\n",
      "Running batch 223/800\n",
      "output shape: (10, 768)\n",
      "Running batch 224/800\n",
      "output shape: (10, 768)\n",
      "Running batch 225/800\n",
      "output shape: (10, 768)\n",
      "Running batch 226/800\n",
      "output shape: (10, 768)\n",
      "Running batch 227/800\n",
      "output shape: (10, 768)\n",
      "Running batch 228/800\n",
      "output shape: (10, 768)\n",
      "Running batch 229/800\n",
      "output shape: (10, 768)\n",
      "Running batch 230/800\n",
      "output shape: (10, 768)\n",
      "Running batch 231/800\n",
      "output shape: (10, 768)\n",
      "Running batch 232/800\n",
      "output shape: (10, 768)\n",
      "Running batch 233/800\n",
      "output shape: (10, 768)\n",
      "Running batch 234/800\n",
      "output shape: (10, 768)\n",
      "Running batch 235/800\n",
      "output shape: (10, 768)\n",
      "Running batch 236/800\n",
      "output shape: (10, 768)\n",
      "Running batch 237/800\n",
      "output shape: (10, 768)\n",
      "Running batch 238/800\n",
      "output shape: (10, 768)\n",
      "Running batch 239/800\n",
      "output shape: (10, 768)\n",
      "Running batch 240/800\n",
      "output shape: (10, 768)\n",
      "Running batch 241/800\n",
      "output shape: (10, 768)\n",
      "Running batch 242/800\n",
      "output shape: (10, 768)\n",
      "Running batch 243/800\n",
      "output shape: (10, 768)\n",
      "Running batch 244/800\n",
      "output shape: (10, 768)\n",
      "Running batch 245/800\n",
      "output shape: (10, 768)\n",
      "Running batch 246/800\n",
      "output shape: (10, 768)\n",
      "Running batch 247/800\n",
      "output shape: (10, 768)\n",
      "Running batch 248/800\n",
      "output shape: (10, 768)\n",
      "Running batch 249/800\n",
      "output shape: (10, 768)\n",
      "Running batch 250/800\n",
      "output shape: (10, 768)\n",
      "Running batch 251/800\n",
      "output shape: (10, 768)\n",
      "Running batch 252/800\n",
      "output shape: (10, 768)\n",
      "Running batch 253/800\n",
      "output shape: (10, 768)\n",
      "Running batch 254/800\n",
      "output shape: (10, 768)\n",
      "Running batch 255/800\n",
      "output shape: (10, 768)\n",
      "Running batch 256/800\n",
      "output shape: (10, 768)\n",
      "Running batch 257/800\n",
      "output shape: (10, 768)\n",
      "Running batch 258/800\n",
      "output shape: (10, 768)\n",
      "Running batch 259/800\n",
      "output shape: (10, 768)\n",
      "Running batch 260/800\n",
      "output shape: (10, 768)\n",
      "Running batch 261/800\n",
      "output shape: (10, 768)\n",
      "Running batch 262/800\n",
      "output shape: (10, 768)\n",
      "Running batch 263/800\n",
      "output shape: (10, 768)\n",
      "Running batch 264/800\n",
      "output shape: (10, 768)\n",
      "Running batch 265/800\n",
      "output shape: (10, 768)\n",
      "Running batch 266/800\n",
      "output shape: (10, 768)\n",
      "Running batch 267/800\n",
      "output shape: (10, 768)\n",
      "Running batch 268/800\n",
      "output shape: (10, 768)\n",
      "Running batch 269/800\n",
      "output shape: (10, 768)\n",
      "Running batch 270/800\n",
      "output shape: (10, 768)\n",
      "Running batch 271/800\n",
      "output shape: (10, 768)\n",
      "Running batch 272/800\n",
      "output shape: (10, 768)\n",
      "Running batch 273/800\n",
      "output shape: (10, 768)\n",
      "Running batch 274/800\n",
      "output shape: (10, 768)\n",
      "Running batch 275/800\n",
      "output shape: (10, 768)\n",
      "Running batch 276/800\n",
      "output shape: (10, 768)\n",
      "Running batch 277/800\n",
      "output shape: (10, 768)\n",
      "Running batch 278/800\n",
      "output shape: (10, 768)\n",
      "Running batch 279/800\n",
      "output shape: (10, 768)\n",
      "Running batch 280/800\n",
      "output shape: (10, 768)\n",
      "Running batch 281/800\n",
      "output shape: (10, 768)\n",
      "Running batch 282/800\n",
      "output shape: (10, 768)\n",
      "Running batch 283/800\n",
      "output shape: (10, 768)\n",
      "Running batch 284/800\n",
      "output shape: (10, 768)\n",
      "Running batch 285/800\n",
      "output shape: (10, 768)\n",
      "Running batch 286/800\n",
      "output shape: (10, 768)\n",
      "Running batch 287/800\n",
      "output shape: (10, 768)\n",
      "Running batch 288/800\n",
      "output shape: (10, 768)\n",
      "Running batch 289/800\n",
      "output shape: (10, 768)\n",
      "Running batch 290/800\n",
      "output shape: (10, 768)\n",
      "Running batch 291/800\n",
      "output shape: (10, 768)\n",
      "Running batch 292/800\n",
      "output shape: (10, 768)\n",
      "Running batch 293/800\n",
      "output shape: (10, 768)\n",
      "Running batch 294/800\n",
      "output shape: (10, 768)\n",
      "Running batch 295/800\n",
      "output shape: (10, 768)\n",
      "Running batch 296/800\n",
      "output shape: (10, 768)\n",
      "Running batch 297/800\n",
      "output shape: (10, 768)\n",
      "Running batch 298/800\n",
      "output shape: (10, 768)\n",
      "Running batch 299/800\n",
      "output shape: (10, 768)\n",
      "Running batch 300/800\n",
      "output shape: (10, 768)\n",
      "Running batch 301/800\n",
      "output shape: (10, 768)\n",
      "Running batch 302/800\n",
      "output shape: (10, 768)\n",
      "Running batch 303/800\n",
      "output shape: (10, 768)\n",
      "Running batch 304/800\n",
      "output shape: (10, 768)\n",
      "Running batch 305/800\n",
      "output shape: (10, 768)\n",
      "Running batch 306/800\n",
      "output shape: (10, 768)\n",
      "Running batch 307/800\n",
      "output shape: (10, 768)\n",
      "Running batch 308/800\n",
      "output shape: (10, 768)\n",
      "Running batch 309/800\n",
      "output shape: (10, 768)\n",
      "Running batch 310/800\n",
      "output shape: (10, 768)\n",
      "Running batch 311/800\n",
      "output shape: (10, 768)\n",
      "Running batch 312/800\n",
      "output shape: (10, 768)\n",
      "Running batch 313/800\n",
      "output shape: (10, 768)\n",
      "Running batch 314/800\n",
      "output shape: (10, 768)\n",
      "Running batch 315/800\n",
      "output shape: (10, 768)\n",
      "Running batch 316/800\n",
      "output shape: (10, 768)\n",
      "Running batch 317/800\n",
      "output shape: (10, 768)\n",
      "Running batch 318/800\n",
      "output shape: (10, 768)\n",
      "Running batch 319/800\n",
      "output shape: (10, 768)\n",
      "Running batch 320/800\n",
      "output shape: (10, 768)\n",
      "Running batch 321/800\n",
      "output shape: (10, 768)\n",
      "Running batch 322/800\n",
      "output shape: (10, 768)\n",
      "Running batch 323/800\n",
      "output shape: (10, 768)\n",
      "Running batch 324/800\n",
      "output shape: (10, 768)\n",
      "Running batch 325/800\n",
      "output shape: (10, 768)\n",
      "Running batch 326/800\n",
      "output shape: (10, 768)\n",
      "Running batch 327/800\n",
      "output shape: (10, 768)\n",
      "Running batch 328/800\n",
      "output shape: (10, 768)\n",
      "Running batch 329/800\n",
      "output shape: (10, 768)\n",
      "Running batch 330/800\n",
      "output shape: (10, 768)\n",
      "Running batch 331/800\n",
      "output shape: (10, 768)\n",
      "Running batch 332/800\n",
      "output shape: (10, 768)\n",
      "Running batch 333/800\n",
      "output shape: (10, 768)\n",
      "Running batch 334/800\n",
      "output shape: (10, 768)\n",
      "Running batch 335/800\n",
      "output shape: (10, 768)\n",
      "Running batch 336/800\n",
      "output shape: (10, 768)\n",
      "Running batch 337/800\n",
      "output shape: (10, 768)\n",
      "Running batch 338/800\n",
      "output shape: (10, 768)\n",
      "Running batch 339/800\n",
      "output shape: (10, 768)\n",
      "Running batch 340/800\n",
      "output shape: (10, 768)\n",
      "Running batch 341/800\n",
      "output shape: (10, 768)\n",
      "Running batch 342/800\n",
      "output shape: (10, 768)\n",
      "Running batch 343/800\n",
      "output shape: (10, 768)\n",
      "Running batch 344/800\n",
      "output shape: (10, 768)\n",
      "Running batch 345/800\n",
      "output shape: (10, 768)\n",
      "Running batch 346/800\n",
      "output shape: (10, 768)\n",
      "Running batch 347/800\n",
      "output shape: (10, 768)\n",
      "Running batch 348/800\n",
      "output shape: (10, 768)\n",
      "Running batch 349/800\n",
      "output shape: (10, 768)\n",
      "Running batch 350/800\n",
      "output shape: (10, 768)\n",
      "Running batch 351/800\n",
      "output shape: (10, 768)\n",
      "Running batch 352/800\n",
      "output shape: (10, 768)\n",
      "Running batch 353/800\n",
      "output shape: (10, 768)\n",
      "Running batch 354/800\n",
      "output shape: (10, 768)\n",
      "Running batch 355/800\n",
      "output shape: (10, 768)\n",
      "Running batch 356/800\n",
      "output shape: (10, 768)\n",
      "Running batch 357/800\n",
      "output shape: (10, 768)\n",
      "Running batch 358/800\n",
      "output shape: (10, 768)\n",
      "Running batch 359/800\n",
      "output shape: (10, 768)\n",
      "Running batch 360/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: (10, 768)\n",
      "Running batch 361/800\n",
      "output shape: (10, 768)\n",
      "Running batch 362/800\n",
      "output shape: (10, 768)\n",
      "Running batch 363/800\n",
      "output shape: (10, 768)\n",
      "Running batch 364/800\n",
      "output shape: (10, 768)\n",
      "Running batch 365/800\n",
      "output shape: (10, 768)\n",
      "Running batch 366/800\n",
      "output shape: (10, 768)\n",
      "Running batch 367/800\n",
      "output shape: (10, 768)\n",
      "Running batch 368/800\n",
      "output shape: (10, 768)\n",
      "Running batch 369/800\n",
      "output shape: (10, 768)\n",
      "Running batch 370/800\n",
      "output shape: (10, 768)\n",
      "Running batch 371/800\n",
      "output shape: (10, 768)\n",
      "Running batch 372/800\n",
      "output shape: (10, 768)\n",
      "Running batch 373/800\n",
      "output shape: (10, 768)\n",
      "Running batch 374/800\n",
      "output shape: (10, 768)\n",
      "Running batch 375/800\n",
      "output shape: (10, 768)\n",
      "Running batch 376/800\n",
      "output shape: (10, 768)\n",
      "Running batch 377/800\n",
      "output shape: (10, 768)\n",
      "Running batch 378/800\n",
      "output shape: (10, 768)\n",
      "Running batch 379/800\n",
      "output shape: (10, 768)\n",
      "Running batch 380/800\n",
      "output shape: (10, 768)\n",
      "Running batch 381/800\n",
      "output shape: (10, 768)\n",
      "Running batch 382/800\n",
      "output shape: (10, 768)\n",
      "Running batch 383/800\n",
      "output shape: (10, 768)\n",
      "Running batch 384/800\n",
      "output shape: (10, 768)\n",
      "Running batch 385/800\n",
      "output shape: (10, 768)\n",
      "Running batch 386/800\n",
      "output shape: (10, 768)\n",
      "Running batch 387/800\n",
      "output shape: (10, 768)\n",
      "Running batch 388/800\n",
      "output shape: (10, 768)\n",
      "Running batch 389/800\n",
      "output shape: (10, 768)\n",
      "Running batch 390/800\n",
      "output shape: (10, 768)\n",
      "Running batch 391/800\n",
      "output shape: (10, 768)\n",
      "Running batch 392/800\n",
      "output shape: (10, 768)\n",
      "Running batch 393/800\n",
      "output shape: (10, 768)\n",
      "Running batch 394/800\n",
      "output shape: (10, 768)\n",
      "Running batch 395/800\n",
      "output shape: (10, 768)\n",
      "Running batch 396/800\n",
      "output shape: (10, 768)\n",
      "Running batch 397/800\n",
      "output shape: (10, 768)\n",
      "Running batch 398/800\n",
      "output shape: (10, 768)\n",
      "Running batch 399/800\n",
      "output shape: (10, 768)\n",
      "Running batch 400/800\n",
      "output shape: (10, 768)\n",
      "Running batch 401/800\n",
      "output shape: (10, 768)\n",
      "Running batch 402/800\n",
      "output shape: (10, 768)\n",
      "Running batch 403/800\n",
      "output shape: (10, 768)\n",
      "Running batch 404/800\n",
      "output shape: (10, 768)\n",
      "Running batch 405/800\n",
      "output shape: (10, 768)\n",
      "Running batch 406/800\n",
      "output shape: (10, 768)\n",
      "Running batch 407/800\n",
      "output shape: (10, 768)\n",
      "Running batch 408/800\n",
      "output shape: (10, 768)\n",
      "Running batch 409/800\n",
      "output shape: (10, 768)\n",
      "Running batch 410/800\n",
      "output shape: (10, 768)\n",
      "Running batch 411/800\n",
      "output shape: (10, 768)\n",
      "Running batch 412/800\n",
      "output shape: (10, 768)\n",
      "Running batch 413/800\n",
      "output shape: (10, 768)\n",
      "Running batch 414/800\n",
      "output shape: (10, 768)\n",
      "Running batch 415/800\n",
      "output shape: (10, 768)\n",
      "Running batch 416/800\n",
      "output shape: (10, 768)\n",
      "Running batch 417/800\n",
      "output shape: (10, 768)\n",
      "Running batch 418/800\n",
      "output shape: (10, 768)\n",
      "Running batch 419/800\n",
      "output shape: (10, 768)\n",
      "Running batch 420/800\n",
      "output shape: (10, 768)\n",
      "Running batch 421/800\n",
      "output shape: (10, 768)\n",
      "Running batch 422/800\n",
      "output shape: (10, 768)\n",
      "Running batch 423/800\n",
      "output shape: (10, 768)\n",
      "Running batch 424/800\n",
      "output shape: (10, 768)\n",
      "Running batch 425/800\n",
      "output shape: (10, 768)\n",
      "Running batch 426/800\n",
      "output shape: (10, 768)\n",
      "Running batch 427/800\n",
      "output shape: (10, 768)\n",
      "Running batch 428/800\n",
      "output shape: (10, 768)\n",
      "Running batch 429/800\n",
      "output shape: (10, 768)\n",
      "Running batch 430/800\n",
      "output shape: (10, 768)\n",
      "Running batch 431/800\n",
      "output shape: (10, 768)\n",
      "Running batch 432/800\n",
      "output shape: (10, 768)\n",
      "Running batch 433/800\n",
      "output shape: (10, 768)\n",
      "Running batch 434/800\n",
      "output shape: (10, 768)\n",
      "Running batch 435/800\n",
      "output shape: (10, 768)\n",
      "Running batch 436/800\n",
      "output shape: (10, 768)\n",
      "Running batch 437/800\n",
      "output shape: (10, 768)\n",
      "Running batch 438/800\n",
      "output shape: (10, 768)\n",
      "Running batch 439/800\n",
      "output shape: (10, 768)\n",
      "Running batch 440/800\n",
      "output shape: (10, 768)\n",
      "Running batch 441/800\n",
      "output shape: (10, 768)\n",
      "Running batch 442/800\n",
      "output shape: (10, 768)\n",
      "Running batch 443/800\n",
      "output shape: (10, 768)\n",
      "Running batch 444/800\n",
      "output shape: (10, 768)\n",
      "Running batch 445/800\n",
      "output shape: (10, 768)\n",
      "Running batch 446/800\n",
      "output shape: (10, 768)\n",
      "Running batch 447/800\n",
      "output shape: (10, 768)\n",
      "Running batch 448/800\n",
      "output shape: (10, 768)\n",
      "Running batch 449/800\n",
      "output shape: (10, 768)\n",
      "Running batch 450/800\n",
      "output shape: (10, 768)\n",
      "Running batch 451/800\n",
      "output shape: (10, 768)\n",
      "Running batch 452/800\n",
      "output shape: (10, 768)\n",
      "Running batch 453/800\n",
      "output shape: (10, 768)\n",
      "Running batch 454/800\n",
      "output shape: (10, 768)\n",
      "Running batch 455/800\n",
      "output shape: (10, 768)\n",
      "Running batch 456/800\n",
      "output shape: (10, 768)\n",
      "Running batch 457/800\n",
      "output shape: (10, 768)\n",
      "Running batch 458/800\n",
      "output shape: (10, 768)\n",
      "Running batch 459/800\n",
      "output shape: (10, 768)\n",
      "Running batch 460/800\n",
      "output shape: (10, 768)\n",
      "Running batch 461/800\n",
      "output shape: (10, 768)\n",
      "Running batch 462/800\n",
      "output shape: (10, 768)\n",
      "Running batch 463/800\n",
      "output shape: (10, 768)\n",
      "Running batch 464/800\n",
      "output shape: (10, 768)\n",
      "Running batch 465/800\n",
      "output shape: (10, 768)\n",
      "Running batch 466/800\n",
      "output shape: (10, 768)\n",
      "Running batch 467/800\n",
      "output shape: (10, 768)\n",
      "Running batch 468/800\n",
      "output shape: (10, 768)\n",
      "Running batch 469/800\n",
      "output shape: (10, 768)\n",
      "Running batch 470/800\n",
      "output shape: (10, 768)\n",
      "Running batch 471/800\n",
      "output shape: (10, 768)\n",
      "Running batch 472/800\n",
      "output shape: (10, 768)\n",
      "Running batch 473/800\n",
      "output shape: (10, 768)\n",
      "Running batch 474/800\n",
      "output shape: (10, 768)\n",
      "Running batch 475/800\n",
      "output shape: (10, 768)\n",
      "Running batch 476/800\n",
      "output shape: (10, 768)\n",
      "Running batch 477/800\n",
      "output shape: (10, 768)\n",
      "Running batch 478/800\n",
      "output shape: (10, 768)\n",
      "Running batch 479/800\n",
      "output shape: (10, 768)\n",
      "Running batch 480/800\n",
      "output shape: (10, 768)\n",
      "Running batch 481/800\n",
      "output shape: (10, 768)\n",
      "Running batch 482/800\n",
      "output shape: (10, 768)\n",
      "Running batch 483/800\n",
      "output shape: (10, 768)\n",
      "Running batch 484/800\n",
      "output shape: (10, 768)\n",
      "Running batch 485/800\n",
      "output shape: (10, 768)\n",
      "Running batch 486/800\n",
      "output shape: (10, 768)\n",
      "Running batch 487/800\n",
      "output shape: (10, 768)\n",
      "Running batch 488/800\n",
      "output shape: (10, 768)\n",
      "Running batch 489/800\n",
      "output shape: (10, 768)\n",
      "Running batch 490/800\n",
      "output shape: (10, 768)\n",
      "Running batch 491/800\n",
      "output shape: (10, 768)\n",
      "Running batch 492/800\n",
      "output shape: (10, 768)\n",
      "Running batch 493/800\n",
      "output shape: (10, 768)\n",
      "Running batch 494/800\n",
      "output shape: (10, 768)\n",
      "Running batch 495/800\n",
      "output shape: (10, 768)\n",
      "Running batch 496/800\n",
      "output shape: (10, 768)\n",
      "Running batch 497/800\n",
      "output shape: (10, 768)\n",
      "Running batch 498/800\n",
      "output shape: (10, 768)\n",
      "Running batch 499/800\n",
      "output shape: (10, 768)\n",
      "Running batch 500/800\n",
      "output shape: (10, 768)\n",
      "Running batch 501/800\n",
      "output shape: (10, 768)\n",
      "Running batch 502/800\n",
      "output shape: (10, 768)\n",
      "Running batch 503/800\n",
      "output shape: (10, 768)\n",
      "Running batch 504/800\n",
      "output shape: (10, 768)\n",
      "Running batch 505/800\n",
      "output shape: (10, 768)\n",
      "Running batch 506/800\n",
      "output shape: (10, 768)\n",
      "Running batch 507/800\n",
      "output shape: (10, 768)\n",
      "Running batch 508/800\n",
      "output shape: (10, 768)\n",
      "Running batch 509/800\n",
      "output shape: (10, 768)\n",
      "Running batch 510/800\n",
      "output shape: (10, 768)\n",
      "Running batch 511/800\n",
      "output shape: (10, 768)\n",
      "Running batch 512/800\n",
      "output shape: (10, 768)\n",
      "Running batch 513/800\n",
      "output shape: (10, 768)\n",
      "Running batch 514/800\n",
      "output shape: (10, 768)\n",
      "Running batch 515/800\n",
      "output shape: (10, 768)\n",
      "Running batch 516/800\n",
      "output shape: (10, 768)\n",
      "Running batch 517/800\n",
      "output shape: (10, 768)\n",
      "Running batch 518/800\n",
      "output shape: (10, 768)\n",
      "Running batch 519/800\n",
      "output shape: (10, 768)\n",
      "Running batch 520/800\n",
      "output shape: (10, 768)\n",
      "Running batch 521/800\n",
      "output shape: (10, 768)\n",
      "Running batch 522/800\n",
      "output shape: (10, 768)\n",
      "Running batch 523/800\n",
      "output shape: (10, 768)\n",
      "Running batch 524/800\n",
      "output shape: (10, 768)\n",
      "Running batch 525/800\n",
      "output shape: (10, 768)\n",
      "Running batch 526/800\n",
      "output shape: (10, 768)\n",
      "Running batch 527/800\n",
      "output shape: (10, 768)\n",
      "Running batch 528/800\n",
      "output shape: (10, 768)\n",
      "Running batch 529/800\n",
      "output shape: (10, 768)\n",
      "Running batch 530/800\n",
      "output shape: (10, 768)\n",
      "Running batch 531/800\n",
      "output shape: (10, 768)\n",
      "Running batch 532/800\n",
      "output shape: (10, 768)\n",
      "Running batch 533/800\n",
      "output shape: (10, 768)\n",
      "Running batch 534/800\n",
      "output shape: (10, 768)\n",
      "Running batch 535/800\n",
      "output shape: (10, 768)\n",
      "Running batch 536/800\n",
      "output shape: (10, 768)\n",
      "Running batch 537/800\n",
      "output shape: (10, 768)\n",
      "Running batch 538/800\n",
      "output shape: (10, 768)\n",
      "Running batch 539/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: (10, 768)\n",
      "Running batch 540/800\n",
      "output shape: (10, 768)\n",
      "Running batch 541/800\n",
      "output shape: (10, 768)\n",
      "Running batch 542/800\n",
      "output shape: (10, 768)\n",
      "Running batch 543/800\n",
      "output shape: (10, 768)\n",
      "Running batch 544/800\n",
      "output shape: (10, 768)\n",
      "Running batch 545/800\n",
      "output shape: (10, 768)\n",
      "Running batch 546/800\n",
      "output shape: (10, 768)\n",
      "Running batch 547/800\n",
      "output shape: (10, 768)\n",
      "Running batch 548/800\n",
      "output shape: (10, 768)\n",
      "Running batch 549/800\n",
      "output shape: (10, 768)\n",
      "Running batch 550/800\n",
      "output shape: (10, 768)\n",
      "Running batch 551/800\n",
      "output shape: (10, 768)\n",
      "Running batch 552/800\n",
      "output shape: (10, 768)\n",
      "Running batch 553/800\n",
      "output shape: (10, 768)\n",
      "Running batch 554/800\n",
      "output shape: (10, 768)\n",
      "Running batch 555/800\n",
      "output shape: (10, 768)\n",
      "Running batch 556/800\n",
      "output shape: (10, 768)\n",
      "Running batch 557/800\n",
      "output shape: (10, 768)\n",
      "Running batch 558/800\n",
      "output shape: (10, 768)\n",
      "Running batch 559/800\n",
      "output shape: (10, 768)\n",
      "Running batch 560/800\n",
      "output shape: (10, 768)\n",
      "Running batch 561/800\n",
      "output shape: (10, 768)\n",
      "Running batch 562/800\n",
      "output shape: (10, 768)\n",
      "Running batch 563/800\n",
      "output shape: (10, 768)\n",
      "Running batch 564/800\n",
      "output shape: (10, 768)\n",
      "Running batch 565/800\n",
      "output shape: (10, 768)\n",
      "Running batch 566/800\n",
      "output shape: (10, 768)\n",
      "Running batch 567/800\n",
      "output shape: (10, 768)\n",
      "Running batch 568/800\n",
      "output shape: (10, 768)\n",
      "Running batch 569/800\n",
      "output shape: (10, 768)\n",
      "Running batch 570/800\n",
      "output shape: (10, 768)\n",
      "Running batch 571/800\n",
      "output shape: (10, 768)\n",
      "Running batch 572/800\n",
      "output shape: (10, 768)\n",
      "Running batch 573/800\n",
      "output shape: (10, 768)\n",
      "Running batch 574/800\n",
      "output shape: (10, 768)\n",
      "Running batch 575/800\n",
      "output shape: (10, 768)\n",
      "Running batch 576/800\n",
      "output shape: (10, 768)\n",
      "Running batch 577/800\n",
      "output shape: (10, 768)\n",
      "Running batch 578/800\n",
      "output shape: (10, 768)\n",
      "Running batch 579/800\n",
      "output shape: (10, 768)\n",
      "Running batch 580/800\n",
      "output shape: (10, 768)\n",
      "Running batch 581/800\n",
      "output shape: (10, 768)\n",
      "Running batch 582/800\n",
      "output shape: (10, 768)\n",
      "Running batch 583/800\n",
      "output shape: (10, 768)\n",
      "Running batch 584/800\n",
      "output shape: (10, 768)\n",
      "Running batch 585/800\n",
      "output shape: (10, 768)\n",
      "Running batch 586/800\n",
      "output shape: (10, 768)\n",
      "Running batch 587/800\n",
      "output shape: (10, 768)\n",
      "Running batch 588/800\n",
      "output shape: (10, 768)\n",
      "Running batch 589/800\n",
      "output shape: (10, 768)\n",
      "Running batch 590/800\n",
      "output shape: (10, 768)\n",
      "Running batch 591/800\n",
      "output shape: (10, 768)\n",
      "Running batch 592/800\n",
      "output shape: (10, 768)\n",
      "Running batch 593/800\n",
      "output shape: (10, 768)\n",
      "Running batch 594/800\n",
      "output shape: (10, 768)\n",
      "Running batch 595/800\n",
      "output shape: (10, 768)\n",
      "Running batch 596/800\n",
      "output shape: (10, 768)\n",
      "Running batch 597/800\n",
      "output shape: (10, 768)\n",
      "Running batch 598/800\n",
      "output shape: (10, 768)\n",
      "Running batch 599/800\n",
      "output shape: (10, 768)\n",
      "Running batch 600/800\n",
      "output shape: (10, 768)\n",
      "Running batch 601/800\n",
      "output shape: (10, 768)\n",
      "Running batch 602/800\n",
      "output shape: (10, 768)\n",
      "Running batch 603/800\n",
      "output shape: (10, 768)\n",
      "Running batch 604/800\n",
      "output shape: (10, 768)\n",
      "Running batch 605/800\n",
      "output shape: (10, 768)\n",
      "Running batch 606/800\n",
      "output shape: (10, 768)\n",
      "Running batch 607/800\n",
      "output shape: (10, 768)\n",
      "Running batch 608/800\n",
      "output shape: (10, 768)\n",
      "Running batch 609/800\n",
      "output shape: (10, 768)\n",
      "Running batch 610/800\n",
      "output shape: (10, 768)\n",
      "Running batch 611/800\n",
      "output shape: (10, 768)\n",
      "Running batch 612/800\n",
      "output shape: (10, 768)\n",
      "Running batch 613/800\n",
      "output shape: (10, 768)\n",
      "Running batch 614/800\n",
      "output shape: (10, 768)\n",
      "Running batch 615/800\n",
      "output shape: (10, 768)\n",
      "Running batch 616/800\n",
      "output shape: (10, 768)\n",
      "Running batch 617/800\n",
      "output shape: (10, 768)\n",
      "Running batch 618/800\n",
      "output shape: (10, 768)\n",
      "Running batch 619/800\n",
      "output shape: (10, 768)\n",
      "Running batch 620/800\n",
      "output shape: (10, 768)\n",
      "Running batch 621/800\n",
      "output shape: (10, 768)\n",
      "Running batch 622/800\n",
      "output shape: (10, 768)\n",
      "Running batch 623/800\n",
      "output shape: (10, 768)\n",
      "Running batch 624/800\n",
      "output shape: (10, 768)\n",
      "Running batch 625/800\n",
      "output shape: (10, 768)\n",
      "Running batch 626/800\n",
      "output shape: (10, 768)\n",
      "Running batch 627/800\n",
      "output shape: (10, 768)\n",
      "Running batch 628/800\n",
      "output shape: (10, 768)\n",
      "Running batch 629/800\n",
      "output shape: (10, 768)\n",
      "Running batch 630/800\n",
      "output shape: (10, 768)\n",
      "Running batch 631/800\n",
      "output shape: (10, 768)\n",
      "Running batch 632/800\n",
      "output shape: (10, 768)\n",
      "Running batch 633/800\n",
      "output shape: (10, 768)\n",
      "Running batch 634/800\n",
      "output shape: (10, 768)\n",
      "Running batch 635/800\n",
      "output shape: (10, 768)\n",
      "Running batch 636/800\n",
      "output shape: (10, 768)\n",
      "Running batch 637/800\n",
      "output shape: (10, 768)\n",
      "Running batch 638/800\n",
      "output shape: (10, 768)\n",
      "Running batch 639/800\n",
      "output shape: (10, 768)\n",
      "Running batch 640/800\n",
      "output shape: (10, 768)\n",
      "Running batch 641/800\n",
      "output shape: (10, 768)\n",
      "Running batch 642/800\n",
      "output shape: (10, 768)\n",
      "Running batch 643/800\n",
      "output shape: (10, 768)\n",
      "Running batch 644/800\n",
      "output shape: (10, 768)\n",
      "Running batch 645/800\n",
      "output shape: (10, 768)\n",
      "Running batch 646/800\n",
      "output shape: (10, 768)\n",
      "Running batch 647/800\n",
      "output shape: (10, 768)\n",
      "Running batch 648/800\n",
      "output shape: (10, 768)\n",
      "Running batch 649/800\n",
      "output shape: (10, 768)\n",
      "Running batch 650/800\n",
      "output shape: (10, 768)\n",
      "Running batch 651/800\n",
      "output shape: (10, 768)\n",
      "Running batch 652/800\n",
      "output shape: (10, 768)\n",
      "Running batch 653/800\n",
      "output shape: (10, 768)\n",
      "Running batch 654/800\n",
      "output shape: (10, 768)\n",
      "Running batch 655/800\n",
      "output shape: (10, 768)\n",
      "Running batch 656/800\n",
      "output shape: (10, 768)\n",
      "Running batch 657/800\n",
      "output shape: (10, 768)\n",
      "Running batch 658/800\n",
      "output shape: (10, 768)\n",
      "Running batch 659/800\n",
      "output shape: (10, 768)\n",
      "Running batch 660/800\n",
      "output shape: (10, 768)\n",
      "Running batch 661/800\n",
      "output shape: (10, 768)\n",
      "Running batch 662/800\n",
      "output shape: (10, 768)\n",
      "Running batch 663/800\n",
      "output shape: (10, 768)\n",
      "Running batch 664/800\n",
      "output shape: (10, 768)\n",
      "Running batch 665/800\n",
      "output shape: (10, 768)\n",
      "Running batch 666/800\n",
      "output shape: (10, 768)\n",
      "Running batch 667/800\n",
      "output shape: (10, 768)\n",
      "Running batch 668/800\n",
      "output shape: (10, 768)\n",
      "Running batch 669/800\n",
      "output shape: (10, 768)\n",
      "Running batch 670/800\n",
      "output shape: (10, 768)\n",
      "Running batch 671/800\n",
      "output shape: (10, 768)\n",
      "Running batch 672/800\n",
      "output shape: (10, 768)\n",
      "Running batch 673/800\n",
      "output shape: (10, 768)\n",
      "Running batch 674/800\n",
      "output shape: (10, 768)\n",
      "Running batch 675/800\n",
      "output shape: (10, 768)\n",
      "Running batch 676/800\n",
      "output shape: (10, 768)\n",
      "Running batch 677/800\n",
      "output shape: (10, 768)\n",
      "Running batch 678/800\n",
      "output shape: (10, 768)\n",
      "Running batch 679/800\n",
      "output shape: (10, 768)\n",
      "Running batch 680/800\n",
      "output shape: (10, 768)\n",
      "Running batch 681/800\n",
      "output shape: (10, 768)\n",
      "Running batch 682/800\n",
      "output shape: (10, 768)\n",
      "Running batch 683/800\n",
      "output shape: (10, 768)\n",
      "Running batch 684/800\n",
      "output shape: (10, 768)\n",
      "Running batch 685/800\n",
      "output shape: (10, 768)\n",
      "Running batch 686/800\n",
      "output shape: (10, 768)\n",
      "Running batch 687/800\n",
      "output shape: (10, 768)\n",
      "Running batch 688/800\n",
      "output shape: (10, 768)\n",
      "Running batch 689/800\n",
      "output shape: (10, 768)\n",
      "Running batch 690/800\n",
      "output shape: (10, 768)\n",
      "Running batch 691/800\n",
      "output shape: (10, 768)\n",
      "Running batch 692/800\n",
      "output shape: (10, 768)\n",
      "Running batch 693/800\n",
      "output shape: (10, 768)\n",
      "Running batch 694/800\n",
      "output shape: (10, 768)\n",
      "Running batch 695/800\n",
      "output shape: (10, 768)\n",
      "Running batch 696/800\n",
      "output shape: (10, 768)\n",
      "Running batch 697/800\n",
      "output shape: (10, 768)\n",
      "Running batch 698/800\n",
      "output shape: (10, 768)\n",
      "Running batch 699/800\n",
      "output shape: (10, 768)\n",
      "Running batch 700/800\n",
      "output shape: (10, 768)\n",
      "Running batch 701/800\n",
      "output shape: (10, 768)\n",
      "Running batch 702/800\n",
      "output shape: (10, 768)\n",
      "Running batch 703/800\n",
      "output shape: (10, 768)\n",
      "Running batch 704/800\n",
      "output shape: (10, 768)\n",
      "Running batch 705/800\n",
      "output shape: (10, 768)\n",
      "Running batch 706/800\n",
      "output shape: (10, 768)\n",
      "Running batch 707/800\n",
      "output shape: (10, 768)\n",
      "Running batch 708/800\n",
      "output shape: (10, 768)\n",
      "Running batch 709/800\n",
      "output shape: (10, 768)\n",
      "Running batch 710/800\n",
      "output shape: (10, 768)\n",
      "Running batch 711/800\n",
      "output shape: (10, 768)\n",
      "Running batch 712/800\n",
      "output shape: (10, 768)\n",
      "Running batch 713/800\n",
      "output shape: (10, 768)\n",
      "Running batch 714/800\n",
      "output shape: (10, 768)\n",
      "Running batch 715/800\n",
      "output shape: (10, 768)\n",
      "Running batch 716/800\n",
      "output shape: (10, 768)\n",
      "Running batch 717/800\n",
      "output shape: (10, 768)\n",
      "Running batch 718/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: (10, 768)\n",
      "Running batch 719/800\n",
      "output shape: (10, 768)\n",
      "Running batch 720/800\n",
      "output shape: (10, 768)\n",
      "Running batch 721/800\n",
      "output shape: (10, 768)\n",
      "Running batch 722/800\n",
      "output shape: (10, 768)\n",
      "Running batch 723/800\n",
      "output shape: (10, 768)\n",
      "Running batch 724/800\n",
      "output shape: (10, 768)\n",
      "Running batch 725/800\n",
      "output shape: (10, 768)\n",
      "Running batch 726/800\n",
      "output shape: (10, 768)\n",
      "Running batch 727/800\n",
      "output shape: (10, 768)\n",
      "Running batch 728/800\n",
      "output shape: (10, 768)\n",
      "Running batch 729/800\n",
      "output shape: (10, 768)\n",
      "Running batch 730/800\n",
      "output shape: (10, 768)\n",
      "Running batch 731/800\n",
      "output shape: (10, 768)\n",
      "Running batch 732/800\n",
      "output shape: (10, 768)\n",
      "Running batch 733/800\n",
      "output shape: (10, 768)\n",
      "Running batch 734/800\n",
      "output shape: (10, 768)\n",
      "Running batch 735/800\n",
      "output shape: (10, 768)\n",
      "Running batch 736/800\n",
      "output shape: (10, 768)\n",
      "Running batch 737/800\n",
      "output shape: (10, 768)\n",
      "Running batch 738/800\n",
      "output shape: (10, 768)\n",
      "Running batch 739/800\n",
      "output shape: (10, 768)\n",
      "Running batch 740/800\n",
      "output shape: (10, 768)\n",
      "Running batch 741/800\n",
      "output shape: (10, 768)\n",
      "Running batch 742/800\n",
      "output shape: (10, 768)\n",
      "Running batch 743/800\n",
      "output shape: (10, 768)\n",
      "Running batch 744/800\n",
      "output shape: (10, 768)\n",
      "Running batch 745/800\n",
      "output shape: (10, 768)\n",
      "Running batch 746/800\n",
      "output shape: (10, 768)\n",
      "Running batch 747/800\n",
      "output shape: (10, 768)\n",
      "Running batch 748/800\n",
      "output shape: (10, 768)\n",
      "Running batch 749/800\n",
      "output shape: (10, 768)\n",
      "Running batch 750/800\n",
      "output shape: (10, 768)\n",
      "Running batch 751/800\n",
      "output shape: (10, 768)\n",
      "Running batch 752/800\n",
      "output shape: (10, 768)\n",
      "Running batch 753/800\n",
      "output shape: (10, 768)\n",
      "Running batch 754/800\n",
      "output shape: (10, 768)\n",
      "Running batch 755/800\n",
      "output shape: (10, 768)\n",
      "Running batch 756/800\n",
      "output shape: (10, 768)\n",
      "Running batch 757/800\n",
      "output shape: (10, 768)\n",
      "Running batch 758/800\n",
      "output shape: (10, 768)\n",
      "Running batch 759/800\n",
      "output shape: (10, 768)\n",
      "Running batch 760/800\n",
      "output shape: (10, 768)\n",
      "Running batch 761/800\n",
      "output shape: (10, 768)\n",
      "Running batch 762/800\n",
      "output shape: (10, 768)\n",
      "Running batch 763/800\n",
      "output shape: (10, 768)\n",
      "Running batch 764/800\n",
      "output shape: (10, 768)\n",
      "Running batch 765/800\n",
      "output shape: (10, 768)\n",
      "Running batch 766/800\n",
      "output shape: (10, 768)\n",
      "Running batch 767/800\n",
      "output shape: (10, 768)\n",
      "Running batch 768/800\n",
      "output shape: (10, 768)\n",
      "Running batch 769/800\n",
      "output shape: (10, 768)\n",
      "Running batch 770/800\n",
      "output shape: (10, 768)\n",
      "Running batch 771/800\n",
      "output shape: (10, 768)\n",
      "Running batch 772/800\n",
      "output shape: (10, 768)\n",
      "Running batch 773/800\n",
      "output shape: (10, 768)\n",
      "Running batch 774/800\n",
      "output shape: (10, 768)\n",
      "Running batch 775/800\n",
      "output shape: (10, 768)\n",
      "Running batch 776/800\n",
      "output shape: (10, 768)\n",
      "Running batch 777/800\n",
      "output shape: (10, 768)\n",
      "Running batch 778/800\n",
      "output shape: (10, 768)\n",
      "Running batch 779/800\n",
      "output shape: (10, 768)\n",
      "Running batch 780/800\n",
      "output shape: (10, 768)\n",
      "Running batch 781/800\n",
      "output shape: (10, 768)\n",
      "Running batch 782/800\n",
      "output shape: (10, 768)\n",
      "Running batch 783/800\n",
      "output shape: (10, 768)\n",
      "Running batch 784/800\n",
      "output shape: (10, 768)\n",
      "Running batch 785/800\n",
      "output shape: (10, 768)\n",
      "Running batch 786/800\n",
      "output shape: (10, 768)\n",
      "Running batch 787/800\n",
      "output shape: (10, 768)\n",
      "Running batch 788/800\n",
      "output shape: (10, 768)\n",
      "Running batch 789/800\n",
      "output shape: (10, 768)\n",
      "Running batch 790/800\n",
      "output shape: (10, 768)\n",
      "Running batch 791/800\n",
      "output shape: (10, 768)\n",
      "Running batch 792/800\n",
      "output shape: (10, 768)\n",
      "Running batch 793/800\n",
      "output shape: (10, 768)\n",
      "Running batch 794/800\n",
      "output shape: (10, 768)\n",
      "Running batch 795/800\n",
      "output shape: (10, 768)\n",
      "Running batch 796/800\n",
      "output shape: (10, 768)\n",
      "Running batch 797/800\n",
      "output shape: (10, 768)\n",
      "Running batch 798/800\n",
      "output shape: (10, 768)\n",
      "Running batch 799/800\n",
      "output shape: (10, 768)\n",
      "Running batch 800/800\n",
      "output shape: (10, 768)\n",
      "transformed.shape: (8000, 768)\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "#output = pipeline.fit(X_train[:25], Y_train[:25].values)\n",
    "#output = pipeline.fit(X_train[:1500], Y_train[:1500].values)\n",
    "output = pipeline.fit(X_train, Y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hungry-serve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform Called\n",
      "Running batch 1/1\n",
      "output shape: (10, 768)\n",
      "transformed.shape: (10, 768)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "distributed-increase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform Called\n",
      "Running batch 1/2\n",
      "output shape: (10, 768)\n",
      "Running batch 2/2\n",
      "output shape: (5, 768)\n",
      "transformed.shape: (15, 768)\n"
     ]
    }
   ],
   "source": [
    "probs = output.predict_proba(X_test[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "efficient-display",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eight-ballet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avvikelse</th>\n",
       "      <th>Beröm</th>\n",
       "      <th>Fråga</th>\n",
       "      <th>Förseningsersättning</th>\n",
       "      <th>Klagomål</th>\n",
       "      <th>Skada</th>\n",
       "      <th>Synpunkt/Önskemål</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Avvikelse  Beröm  Fråga  Förseningsersättning  Klagomål  Skada  \\\n",
       "521          0      0      1                     0         0      0   \n",
       "941          0      0      0                     0         0      0   \n",
       "741          0      0      1                     0         0      0   \n",
       "980          0      0      0                     0         0      0   \n",
       "411          0      0      0                     0         0      0   \n",
       "679          0      0      1                     0         0      0   \n",
       "673          0      0      0                     0         0      0   \n",
       "513          0      0      0                     0         1      0   \n",
       "773          0      0      0                     0         1      0   \n",
       "136          0      0      0                     0         0      0   \n",
       "889          0      0      1                     0         0      0   \n",
       "76           0      0      0                     1         0      0   \n",
       "739          0      0      0                     0         0      0   \n",
       "806          0      0      0                     0         0      0   \n",
       "939          0      0      0                     0         0      0   \n",
       "\n",
       "     Synpunkt/Önskemål  \n",
       "521                  0  \n",
       "941                  1  \n",
       "741                  0  \n",
       "980                  1  \n",
       "411                  1  \n",
       "679                  0  \n",
       "673                  1  \n",
       "513                  0  \n",
       "773                  0  \n",
       "136                  1  \n",
       "889                  0  \n",
       "76                   0  \n",
       "739                  1  \n",
       "806                  1  \n",
       "939                  1  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "honey-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will predict the classes for each row. The class with the highest probability is selected\n",
    "def PredictClasses(model, X):\n",
    "    probs = model.predict_proba(X)\n",
    "    probs = np.array(probs) #List to (N, num_classes, 2)\n",
    "    predictedClasses = np.argmax(probs[:,:,1].T, axis=1) #First index classifies it as 0, second as 1, Then get the max index for each row\n",
    "    \n",
    "    return predictedClasses\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "spread-cambodia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hej, \\r\\nvarför heter en av hållplatserna i ludvigsborg kvarndamms gatan i hörby kommun, skåne? dels så finns det ingen väg som heter så där, den heter kvarndamsvägen. dessutom är hållplatsen på ludvigsborgsvägen. xxxx ni vidarebefordra detta till rätt avdelning så det blir ändrat för att inte göra det förvirrat för resenärerna?\\r\\nhälsningar fredrik\\r\\r\\n'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "right-water",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform Called\n",
      "Running batch 1/1\n",
      "output shape: (10, 768)\n",
      "transformed.shape: (10, 768)\n"
     ]
    }
   ],
   "source": [
    "result = PredictClasses(pipeline, X_test[10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "hearing-onion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 3, 3, 6, 3, 3, 2], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "wooden-formula",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avvikelse</th>\n",
       "      <th>Beröm</th>\n",
       "      <th>Fråga</th>\n",
       "      <th>Förseningsersättning</th>\n",
       "      <th>Klagomål</th>\n",
       "      <th>Skada</th>\n",
       "      <th>Synpunkt/Önskemål</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7487</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5272</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5653</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6033</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9930</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7051</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8158</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Avvikelse  Beröm  Fråga  Förseningsersättning  Klagomål  Skada  \\\n",
       "2750          0      0      0                     1         0      0   \n",
       "7487          0      0      0                     1         0      0   \n",
       "5272          0      0      0                     1         0      0   \n",
       "5653          0      0      0                     1         0      0   \n",
       "3999          0      0      0                     1         0      0   \n",
       "6033          0      0      0                     1         0      0   \n",
       "582           0      0      0                     0         1      0   \n",
       "9930          0      0      0                     1         0      0   \n",
       "7051          0      0      0                     1         0      0   \n",
       "8158          0      0      0                     1         0      0   \n",
       "\n",
       "      Synpunkt/Önskemål  \n",
       "2750                  0  \n",
       "7487                  0  \n",
       "5272                  0  \n",
       "5653                  0  \n",
       "3999                  0  \n",
       "6033                  0  \n",
       "582                   0  \n",
       "9930                  0  \n",
       "7051                  0  \n",
       "8158                  0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "directed-beatles",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 3, 3, 6, 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "outer-ebony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 3, 3, 4, 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ost = Y_test[10:20].to_numpy().argmax(axis=1)\n",
    "ost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "republican-variety",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "delayed-retreat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(ost, result,normalize='true')\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "isolated-initial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1ae8f022d00>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix=cm,).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "artificial-passion",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'ConfusionMatrixDisplay'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-c4a25fee7a5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0most\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2755\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2756\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2757\u001b[1;33m     return gca().plot(\n\u001b[0m\u001b[0;32m   2758\u001b[0m         \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2759\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1632\u001b[0m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1633\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1634\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1635\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request_autoscale_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1636\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36madd_line\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m   2281\u001b[0m             \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2283\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_line_limits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2284\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2285\u001b[0m             \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'_child{len(self._children)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_update_line_limits\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m   2304\u001b[0m         \u001b[0mFigures\u001b[0m \u001b[0mout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdating\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2305\u001b[0m         \"\"\"\n\u001b[1;32m-> 2306\u001b[1;33m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2307\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2308\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\matplotlib\\lines.py\u001b[0m in \u001b[0;36mget_path\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    995\u001b[0m         \u001b[1;34m\"\"\"Return the `~matplotlib.path.Path` associated with this line.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invalidy\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 997\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    998\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\matplotlib\\lines.py\u001b[0m in \u001b[0;36mrecache\u001b[1;34m(self, always)\u001b[0m\n\u001b[0;32m    653\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0malways\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invalidy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m             \u001b[0myconv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_yunits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_yorig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_to_unmasked_float_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myconv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\matplotlib\\cbook\\__init__.py\u001b[0m in \u001b[0;36m_to_unmasked_float_array\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1296\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1298\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'ConfusionMatrixDisplay'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.(ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(ost, result)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "level-condition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ost, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "spare-engine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform Called\n",
      "Running batch 1/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-d119748ae7af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#results = PredictClasses(pipeline, X_test[:15])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPredictClasses\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-d220fc1fb3d3>\u001b[0m in \u001b[0;36mPredictClasses\u001b[1;34m(model, X)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#This will predict the classes for each row. The class with the highest probability is selected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mPredictClasses\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#List to (N, num_classes, 2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpredictedClasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#First index classifies it as 0, second as 1, Then get the max index for each row\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X, **predict_proba_params)\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 535\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredict_proba_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-b00c47e656f5>\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0minputs_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatchId\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatchId\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0minputs_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pooler_output'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'output shape: {outputs.shape}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1020\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m         )\n\u001b[1;32m-> 1022\u001b[1;33m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[0;32m   1023\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    609\u001b[0m                 )\n\u001b[0;32m    610\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m    612\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    495\u001b[0m         \u001b[1;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[0;32m    498\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    425\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[1;32m--> 427\u001b[1;33m         self_outputs = self.self(\n\u001b[0m\u001b[0;32m    428\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;31m# Normalize the attention scores to probabilities.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m         \u001b[0mattention_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;31m# This is actually dropping out entire tokens to attend to, which might\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1832\u001b[0m         \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"softmax\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1833\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1834\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1835\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1836\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#results = PredictClasses(pipeline, X_test[:15])\n",
    "results = PredictClasses(pipeline, X_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "incorporate-lecture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 6, 4, 6, 6, 6, 4, 4, 6, 4, 6, 4, 6, 6, 6, 6, 6, 2, 4, 6, 6, 2,\n",
       "       2, 4, 4, 4, 4, 6, 2, 4, 4, 6, 6, 6, 4, 4, 6, 2, 6, 4, 4, 4, 3, 6,\n",
       "       4, 6, 2, 6, 2, 6, 6, 2, 6, 6, 4, 6, 4, 4, 4, 6, 4, 4, 4, 6, 6, 6,\n",
       "       6, 2, 4, 6, 6, 6, 6, 6, 4, 4, 2, 4, 6, 4, 6, 4, 2, 6, 4, 2, 6, 6,\n",
       "       2, 2, 4, 4, 4, 4, 6, 4, 4, 4, 4, 6, 6, 4, 4, 2, 2, 6, 4, 4, 3, 6,\n",
       "       6, 4, 6, 6, 4, 4, 6, 6, 6, 4, 6, 6, 6, 2, 4, 6, 6, 4, 6, 6, 6, 6,\n",
       "       6, 6, 6, 4, 4, 4, 6, 4, 4, 6, 6, 4, 6, 2, 6, 4, 2, 4, 4, 2, 6, 2,\n",
       "       6, 6, 2, 6, 4, 6, 6, 4, 6, 6, 2, 6, 4, 6, 3, 4, 4, 4, 2, 6, 4, 4,\n",
       "       6, 2, 6, 2, 4, 6, 4, 2, 6, 2, 4, 6, 6, 6, 4, 6, 6, 4, 2, 6, 6, 2,\n",
       "       6, 2, 6], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "raising-beast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 6, 5, ..., 4, 4, 2], dtype=int64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = np.argmax(np.array(Y), axis=1)\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "human-standard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Avvikelse', 'Beröm', 'Fråga', 'Förseningsersättning', 'Klagomål',\n",
       "       'Skada', 'Synpunkt/Önskemål'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "grateful-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluateModelUsingProbs(model, X_test, Y_test):\n",
    "    Y_pred = PredictClasses(model, X_test) #1D-array with classes\n",
    "    targets = np.argmax(np.array(Y_test), axis=1) #1D-array with classes\n",
    "    \n",
    "    total_hits = np.sum(np.sum(Y_pred == targets))\n",
    "    total_misses = np.sum(np.sum(Y_pred != targets))\n",
    "    total_accuracy = total_hits/(total_hits + total_misses)\n",
    "    print(f'Total Accuracy: {total_accuracy}')\n",
    "    cm = confusion_matrix(targets, Y_pred, normalize='true')\n",
    "    ConfusionMatrixDisplay(confusion_matrix=cm,).plot()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "existing-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model and print the accuracy\n",
    "\n",
    "def EvaluateModel(model, X_test, Y_test):\n",
    "    Y_pred = model.predict(X_test)\n",
    "    \n",
    "    total_hits = np.sum(np.sum(Y_pred == Y_test))\n",
    "    total_misses = np.sum(np.sum(Y_pred != Y_test))\n",
    "    total_accuracy = total_hits/(total_hits + total_misses)\n",
    "       \n",
    "    target_names = [name for name in Y.columns]\n",
    "\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1scores = []\n",
    "    for (name, col) in zip(target_names, range(len(target_names))):\n",
    "        y_test = Y_test[name].values\n",
    "        y_pred = Y_pred[:, col]\n",
    "        \n",
    "        if(np.max(y_test) <= 1):\n",
    "            #Only one category\n",
    "            precisions.append(precision_score(y_test, y_pred))\n",
    "            recalls.append(recall_score(y_test, y_pred))\n",
    "            f1scores.append(f1_score(y_test, y_pred))\n",
    "        print(f'Category: {name}')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print('-'*42)\n",
    "     \n",
    "    \n",
    "    print(f'Total Accuracy: {total_accuracy}')\n",
    "    print(f'Average Precission: {np.average(precisions)}')\n",
    "    print(f'Average Recall: {np.average(recalls)}')\n",
    "    print(f'Average F1 Score: {np.average(f1scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "buried-butter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform Called\n",
      "Running batch 1/10\n",
      "output shape: (10, 768)\n",
      "Running batch 2/10\n",
      "output shape: (10, 768)\n",
      "Running batch 3/10\n",
      "output shape: (10, 768)\n",
      "Running batch 4/10\n",
      "output shape: (10, 768)\n",
      "Running batch 5/10\n",
      "output shape: (10, 768)\n",
      "Running batch 6/10\n",
      "output shape: (10, 768)\n",
      "Running batch 7/10\n",
      "output shape: (10, 768)\n",
      "Running batch 8/10\n",
      "output shape: (10, 768)\n",
      "Running batch 9/10\n",
      "output shape: (10, 768)\n",
      "Running batch 10/10\n",
      "output shape: (10, 768)\n",
      "transformed.shape: (100, 768)\n",
      "Category: Avvikelse\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       100\n",
      "\n",
      "    accuracy                           1.00       100\n",
      "   macro avg       1.00      1.00      1.00       100\n",
      "weighted avg       1.00      1.00      1.00       100\n",
      "\n",
      "------------------------------------------\n",
      "Category: Beröm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        99\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.99       100\n",
      "   macro avg       0.49      0.50      0.50       100\n",
      "weighted avg       0.98      0.99      0.99       100\n",
      "\n",
      "------------------------------------------\n",
      "Category: Fråga\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86        76\n",
      "           1       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.76       100\n",
      "   macro avg       0.38      0.50      0.43       100\n",
      "weighted avg       0.58      0.76      0.66       100\n",
      "\n",
      "------------------------------------------\n",
      "Category: Förseningsersättning\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97        94\n",
      "           1       1.00      0.17      0.29         6\n",
      "\n",
      "    accuracy                           0.95       100\n",
      "   macro avg       0.97      0.58      0.63       100\n",
      "weighted avg       0.95      0.95      0.93       100\n",
      "\n",
      "------------------------------------------\n",
      "Category: Klagomål\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.94      0.78        67\n",
      "           1       0.33      0.06      0.10        33\n",
      "\n",
      "    accuracy                           0.65       100\n",
      "   macro avg       0.50      0.50      0.44       100\n",
      "weighted avg       0.56      0.65      0.56       100\n",
      "\n",
      "------------------------------------------\n",
      "Category: Skada\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        99\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.99       100\n",
      "   macro avg       0.49      0.50      0.50       100\n",
      "weighted avg       0.98      0.99      0.99       100\n",
      "\n",
      "------------------------------------------\n",
      "Category: Synpunkt/Önskemål\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.95      0.82        65\n",
      "           1       0.79      0.31      0.45        35\n",
      "\n",
      "    accuracy                           0.73       100\n",
      "   macro avg       0.75      0.63      0.64       100\n",
      "weighted avg       0.74      0.73      0.69       100\n",
      "\n",
      "------------------------------------------\n",
      "Total Accuracy: 0.8671428571428571\n",
      "Average Precission: 0.30272108843537415\n",
      "Average Recall: 0.07736549165120594\n",
      "Average F1 Score: 0.11960828287358898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\dataScience\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "EvaluateModel(pipeline, X_test[:100], Y_test[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "vital-guard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform Called\n",
      "Running batch 1/60\n",
      "output shape: (10, 768)\n",
      "Running batch 2/60\n",
      "output shape: (10, 768)\n",
      "Running batch 3/60\n",
      "output shape: (10, 768)\n",
      "Running batch 4/60\n",
      "output shape: (10, 768)\n",
      "Running batch 5/60\n",
      "output shape: (10, 768)\n",
      "Running batch 6/60\n",
      "output shape: (10, 768)\n",
      "Running batch 7/60\n",
      "output shape: (10, 768)\n",
      "Running batch 8/60\n",
      "output shape: (10, 768)\n",
      "Running batch 9/60\n",
      "output shape: (10, 768)\n",
      "Running batch 10/60\n",
      "output shape: (10, 768)\n",
      "Running batch 11/60\n",
      "output shape: (10, 768)\n",
      "Running batch 12/60\n",
      "output shape: (10, 768)\n",
      "Running batch 13/60\n",
      "output shape: (10, 768)\n",
      "Running batch 14/60\n",
      "output shape: (10, 768)\n",
      "Running batch 15/60\n",
      "output shape: (10, 768)\n",
      "Running batch 16/60\n",
      "output shape: (10, 768)\n",
      "Running batch 17/60\n",
      "output shape: (10, 768)\n",
      "Running batch 18/60\n",
      "output shape: (10, 768)\n",
      "Running batch 19/60\n",
      "output shape: (10, 768)\n",
      "Running batch 20/60\n",
      "output shape: (10, 768)\n",
      "Running batch 21/60\n",
      "output shape: (10, 768)\n",
      "Running batch 22/60\n",
      "output shape: (10, 768)\n",
      "Running batch 23/60\n",
      "output shape: (10, 768)\n",
      "Running batch 24/60\n",
      "output shape: (10, 768)\n",
      "Running batch 25/60\n",
      "output shape: (10, 768)\n",
      "Running batch 26/60\n",
      "output shape: (10, 768)\n",
      "Running batch 27/60\n",
      "output shape: (10, 768)\n",
      "Running batch 28/60\n",
      "output shape: (10, 768)\n",
      "Running batch 29/60\n",
      "output shape: (10, 768)\n",
      "Running batch 30/60\n",
      "output shape: (10, 768)\n",
      "Running batch 31/60\n",
      "output shape: (10, 768)\n",
      "Running batch 32/60\n",
      "output shape: (10, 768)\n",
      "Running batch 33/60\n",
      "output shape: (10, 768)\n",
      "Running batch 34/60\n",
      "output shape: (10, 768)\n",
      "Running batch 35/60\n",
      "output shape: (10, 768)\n",
      "Running batch 36/60\n",
      "output shape: (10, 768)\n",
      "Running batch 37/60\n",
      "output shape: (10, 768)\n",
      "Running batch 38/60\n",
      "output shape: (10, 768)\n",
      "Running batch 39/60\n",
      "output shape: (10, 768)\n",
      "Running batch 40/60\n",
      "output shape: (10, 768)\n",
      "Running batch 41/60\n",
      "output shape: (10, 768)\n",
      "Running batch 42/60\n",
      "output shape: (10, 768)\n",
      "Running batch 43/60\n",
      "output shape: (10, 768)\n",
      "Running batch 44/60\n",
      "output shape: (10, 768)\n",
      "Running batch 45/60\n",
      "output shape: (10, 768)\n",
      "Running batch 46/60\n",
      "output shape: (10, 768)\n",
      "Running batch 47/60\n",
      "output shape: (10, 768)\n",
      "Running batch 48/60\n",
      "output shape: (10, 768)\n",
      "Running batch 49/60\n",
      "output shape: (10, 768)\n",
      "Running batch 50/60\n",
      "output shape: (10, 768)\n",
      "Running batch 51/60\n",
      "output shape: (10, 768)\n",
      "Running batch 52/60\n",
      "output shape: (10, 768)\n",
      "Running batch 53/60\n",
      "output shape: (10, 768)\n",
      "Running batch 54/60\n",
      "output shape: (10, 768)\n",
      "Running batch 55/60\n",
      "output shape: (10, 768)\n",
      "Running batch 56/60\n",
      "output shape: (10, 768)\n",
      "Running batch 57/60\n",
      "output shape: (10, 768)\n",
      "Running batch 58/60\n",
      "output shape: (10, 768)\n",
      "Running batch 59/60\n",
      "output shape: (10, 768)\n",
      "Running batch 60/60\n",
      "output shape: (10, 768)\n",
      "transformed.shape: (600, 768)\n",
      "Total Accuracy: 0.9183333333333333\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "EvaluateModelUsingProbs(pipeline, X_test[:600], Y_test[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "killing-cameroon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform Called\n",
      "Running batch 1/80\n",
      "output shape: (10, 768)\n",
      "Running batch 2/80\n",
      "output shape: (10, 768)\n",
      "Running batch 3/80\n",
      "output shape: (10, 768)\n",
      "Running batch 4/80\n",
      "output shape: (10, 768)\n",
      "Running batch 5/80\n",
      "output shape: (10, 768)\n",
      "Running batch 6/80\n",
      "output shape: (10, 768)\n",
      "Running batch 7/80\n",
      "output shape: (10, 768)\n",
      "Running batch 8/80\n",
      "output shape: (10, 768)\n",
      "Running batch 9/80\n",
      "output shape: (10, 768)\n",
      "Running batch 10/80\n",
      "output shape: (10, 768)\n",
      "Running batch 11/80\n",
      "output shape: (10, 768)\n",
      "Running batch 12/80\n",
      "output shape: (10, 768)\n",
      "Running batch 13/80\n",
      "output shape: (10, 768)\n",
      "Running batch 14/80\n",
      "output shape: (10, 768)\n",
      "Running batch 15/80\n",
      "output shape: (10, 768)\n",
      "Running batch 16/80\n",
      "output shape: (10, 768)\n",
      "Running batch 17/80\n",
      "output shape: (10, 768)\n",
      "Running batch 18/80\n",
      "output shape: (10, 768)\n",
      "Running batch 19/80\n",
      "output shape: (10, 768)\n",
      "Running batch 20/80\n",
      "output shape: (10, 768)\n",
      "Running batch 21/80\n",
      "output shape: (10, 768)\n",
      "Running batch 22/80\n",
      "output shape: (10, 768)\n",
      "Running batch 23/80\n",
      "output shape: (10, 768)\n",
      "Running batch 24/80\n",
      "output shape: (10, 768)\n",
      "Running batch 25/80\n",
      "output shape: (10, 768)\n",
      "Running batch 26/80\n",
      "output shape: (10, 768)\n",
      "Running batch 27/80\n",
      "output shape: (10, 768)\n",
      "Running batch 28/80\n",
      "output shape: (10, 768)\n",
      "Running batch 29/80\n",
      "output shape: (10, 768)\n",
      "Running batch 30/80\n",
      "output shape: (10, 768)\n",
      "Running batch 31/80\n",
      "output shape: (10, 768)\n",
      "Running batch 32/80\n",
      "output shape: (10, 768)\n",
      "Running batch 33/80\n",
      "output shape: (10, 768)\n",
      "Running batch 34/80\n",
      "output shape: (10, 768)\n",
      "Running batch 35/80\n",
      "output shape: (10, 768)\n",
      "Running batch 36/80\n",
      "output shape: (10, 768)\n",
      "Running batch 37/80\n",
      "output shape: (10, 768)\n",
      "Running batch 38/80\n",
      "output shape: (10, 768)\n",
      "Running batch 39/80\n",
      "output shape: (10, 768)\n",
      "Running batch 40/80\n",
      "output shape: (10, 768)\n",
      "Running batch 41/80\n",
      "output shape: (10, 768)\n",
      "Running batch 42/80\n",
      "output shape: (10, 768)\n",
      "Running batch 43/80\n",
      "output shape: (10, 768)\n",
      "Running batch 44/80\n",
      "output shape: (10, 768)\n",
      "Running batch 45/80\n",
      "output shape: (10, 768)\n",
      "Running batch 46/80\n",
      "output shape: (10, 768)\n",
      "Running batch 47/80\n",
      "output shape: (10, 768)\n",
      "Running batch 48/80\n",
      "output shape: (10, 768)\n",
      "Running batch 49/80\n",
      "output shape: (10, 768)\n",
      "Running batch 50/80\n",
      "output shape: (10, 768)\n",
      "Running batch 51/80\n",
      "output shape: (10, 768)\n",
      "Running batch 52/80\n",
      "output shape: (10, 768)\n",
      "Running batch 53/80\n",
      "output shape: (10, 768)\n",
      "Running batch 54/80\n",
      "output shape: (10, 768)\n",
      "Running batch 55/80\n",
      "output shape: (10, 768)\n",
      "Running batch 56/80\n",
      "output shape: (10, 768)\n",
      "Running batch 57/80\n",
      "output shape: (10, 768)\n",
      "Running batch 58/80\n",
      "output shape: (10, 768)\n",
      "Running batch 59/80\n",
      "output shape: (10, 768)\n",
      "Running batch 60/80\n",
      "output shape: (10, 768)\n",
      "Running batch 61/80\n",
      "output shape: (10, 768)\n",
      "Running batch 62/80\n",
      "output shape: (10, 768)\n",
      "Running batch 63/80\n",
      "output shape: (10, 768)\n",
      "Running batch 64/80\n",
      "output shape: (10, 768)\n",
      "Running batch 65/80\n",
      "output shape: (10, 768)\n",
      "Running batch 66/80\n",
      "output shape: (10, 768)\n",
      "Running batch 67/80\n",
      "output shape: (10, 768)\n",
      "Running batch 68/80\n",
      "output shape: (10, 768)\n",
      "Running batch 69/80\n",
      "output shape: (10, 768)\n",
      "Running batch 70/80\n",
      "output shape: (10, 768)\n",
      "Running batch 71/80\n",
      "output shape: (10, 768)\n",
      "Running batch 72/80\n",
      "output shape: (10, 768)\n",
      "Running batch 73/80\n",
      "output shape: (10, 768)\n",
      "Running batch 74/80\n",
      "output shape: (10, 768)\n",
      "Running batch 75/80\n",
      "output shape: (10, 768)\n",
      "Running batch 76/80\n",
      "output shape: (10, 768)\n",
      "Running batch 77/80\n",
      "output shape: (10, 768)\n",
      "Running batch 78/80\n",
      "output shape: (10, 768)\n",
      "Running batch 79/80\n",
      "output shape: (10, 768)\n",
      "Running batch 80/80\n",
      "output shape: (10, 768)\n",
      "transformed.shape: (800, 768)\n",
      "Total Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "EvaluateModelUsingProbs(pipeline, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dense-wholesale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.iloc[0:10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "humanitarian-place",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save, Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "supreme-perth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fifteen-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'BertModel.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "electric-patrol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BertModel.joblib']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dump(pipeline, modelName ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "allied-measurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadedModel = load(modelName) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "antique-melbourne",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform Called\n",
      "Running batch 1/2\n",
      "output shape: (10, 768)\n",
      "Running batch 2/2\n",
      "output shape: (10, 768)\n",
      "transformed.shape: (20, 768)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadedModel.predict(X_test[100:120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "studied-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deep learning using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "vocational-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TorchNLP(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        print('Init called')\n",
    "        self.model_name = 'KB/bert-base-swedish-cased'\n",
    "        self.Bert = AutoModel.from_pretrained(self.model_name)\n",
    "        self.Tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.n_classes = n_classes\n",
    "        self.TorchModel = nn.Sequential(nn.Linear(768, 128),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Dropout(p=0.2),\n",
    "                          nn.Linear(128, 64),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Dropout(p=0.2),              \n",
    "                          nn.Linear(64, n_classes))\n",
    "                          #nn.Softmax(dim=1)) Cannot use softmax here since nn.CrossEntropyLoss expects scores!\n",
    "        \n",
    "        #Freeze the Bert model layers\n",
    "        for param in self.Bert.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    def forward(self, X):\n",
    "        print('Forward Called')\n",
    "       \n",
    "        #Check device\n",
    "        device = self.Bert.device\n",
    "        \n",
    "        # Transform input tokens. This is most efficient if done in one batch \n",
    "        X = self.Tokenizer(X.values.tolist(), return_tensors=\"pt\", padding='max_length', max_length = 512, truncation=True).to(device)\n",
    "        \n",
    "        X = self.Bert(**X)\n",
    "        X = X['pooler_output']\n",
    "        X = self.TorchModel(X)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def predict(self, X):\n",
    "        with torch.no_grad():\n",
    "            self.eval()\n",
    "            output = torchModel(X)\n",
    "            top_p, top_class = output.topk(1, dim=1)\n",
    "            top_class = top_class.to('cpu').numpy().reshape(-1,)\n",
    "            self.train()\n",
    "            return top_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "functional-chile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchModel.Bert.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "organic-currency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "engaging-hammer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init called\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at KB/bert-base-swedish-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#n_classes = Y.shape[1] #In case of one hot encoded, which we don't have anymore\n",
    "n_classes = Y.max() + 1\n",
    "torchModel = TorchNLP(n_classes = n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "center-amateur",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Called\n"
     ]
    }
   ],
   "source": [
    "output = torchModel(X_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "horizontal-hindu",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1394, 0.1599, 0.1548, 0.1324, 0.1248, 0.1408, 0.1479],\n",
       "        [0.1428, 0.1565, 0.1440, 0.1306, 0.1277, 0.1471, 0.1513],\n",
       "        [0.1410, 0.1569, 0.1521, 0.1396, 0.1235, 0.1379, 0.1489],\n",
       "        [0.1318, 0.1499, 0.1585, 0.1312, 0.1373, 0.1510, 0.1404],\n",
       "        [0.1423, 0.1517, 0.1463, 0.1242, 0.1348, 0.1532, 0.1476]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "municipal-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "mMiniBatcherTrain = MiniBatcher(X_train[:100000], Y_train[:100000], batch_size=100)\n",
    "mMiniBatcherTest = MiniBatcher(X_test[:1000], Y_test[:1000], batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "extensive-milwaukee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([50325, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([512, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([2, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([3072]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([3072]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([3072]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([3072]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([3072]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([3072]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([3072]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([3072]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([3072]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([3072]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([3072]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([3072, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([3072]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 3072]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768, 768]) False\n",
      "<class 'torch.Tensor'> torch.Size([768]) False\n",
      "<class 'torch.Tensor'> torch.Size([128, 768]) True\n",
      "<class 'torch.Tensor'> torch.Size([128]) True\n",
      "<class 'torch.Tensor'> torch.Size([64, 128]) True\n",
      "<class 'torch.Tensor'> torch.Size([64]) True\n",
      "<class 'torch.Tensor'> torch.Size([7, 64]) True\n",
      "<class 'torch.Tensor'> torch.Size([7]) True\n"
     ]
    }
   ],
   "source": [
    "for param in torchModel.parameters():\n",
    "    print(type(param.data), param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "rational-healing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are running on device: cuda\n"
     ]
    }
   ],
   "source": [
    "cuda_enabled = torch.cuda.is_available()\n",
    "if cuda_enabled:\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(f'We are running on device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "dangerous-inventory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15683671832084656\n",
      "2 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2217974215745926\n",
      "3 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.19648633897304535\n",
      "4 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.25303879380226135\n",
      "5 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.19613531231880188\n",
      "6 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2111758440732956\n",
      "7 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.20248013734817505\n",
      "8 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.31272584199905396\n",
      "9 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2641376256942749\n",
      "10 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.23575878143310547\n",
      "11 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1532815545797348\n",
      "12 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.16240137815475464\n",
      "13 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15497572720050812\n",
      "14 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.21748991310596466\n",
      "15 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.21952922642230988\n",
      "16 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1588875651359558\n",
      "17 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.22708506882190704\n",
      "18 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1686527132987976\n",
      "19 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2727667987346649\n",
      "20 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.17807795107364655\n",
      "21 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.19098858535289764\n",
      "22 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.20616842806339264\n",
      "23 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2246120572090149\n",
      "24 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1653774380683899\n",
      "25 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.27247583866119385\n",
      "26 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.26068925857543945\n",
      "27 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.23994682729244232\n",
      "28 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.20407924056053162\n",
      "29 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.19284377992153168\n",
      "30 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1796897053718567\n",
      "31 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1382620930671692\n",
      "32 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.21586328744888306\n",
      "33 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1711437851190567\n",
      "34 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2549492120742798\n",
      "35 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1450187861919403\n",
      "36 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2070540189743042\n",
      "37 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2232712209224701\n",
      "38 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.18221037089824677\n",
      "39 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2474910318851471\n",
      "40 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1642078161239624\n",
      "41 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.12916307151317596\n",
      "42 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15886986255645752\n",
      "43 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14422990381717682\n",
      "44 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.17217247188091278\n",
      "45 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.16804391145706177\n",
      "46 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.19671949744224548\n",
      "47 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1820860356092453\n",
      "48 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.21139906346797943\n",
      "49 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.16161705553531647\n",
      "50 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15788327157497406\n",
      "51 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14650395512580872\n",
      "52 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.20595385134220123\n",
      "53 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.13108600676059723\n",
      "54 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15125522017478943\n",
      "55 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.19850805401802063\n",
      "56 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.17980659008026123\n",
      "57 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.17130519449710846\n",
      "58 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.19390466809272766\n",
      "59 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.17827042937278748\n",
      "60 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15374523401260376\n",
      "61 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.134881854057312\n",
      "62 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.17862211167812347\n",
      "63 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.16932308673858643\n",
      "64 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.24924440681934357\n",
      "65 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.3722032606601715\n",
      "66 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2271832674741745\n",
      "67 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.21833793818950653\n",
      "68 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.11907806247472763\n",
      "69 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1528652161359787\n",
      "70 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.22494760155677795\n",
      "71 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14900144934654236\n",
      "72 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1278861165046692\n",
      "73 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1585579216480255\n",
      "74 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.18018272519111633\n",
      "75 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15512138605117798\n",
      "76 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.18921500444412231\n",
      "77 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.218963623046875\n",
      "78 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.13905704021453857\n",
      "79 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14507991075515747\n",
      "80 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.24753156304359436\n",
      "81 0\n",
      "0\n",
      "will break\n",
      "1 0\n",
      "100\n",
      "Validation batch...\n",
      "Forward Called\n",
      "tensor([[ 9.2222],\n",
      "        [ 9.0368],\n",
      "        [10.0003],\n",
      "        [10.1390],\n",
      "        [11.6613],\n",
      "        [ 8.9510],\n",
      "        [ 1.5286],\n",
      "        [ 9.8840],\n",
      "        [ 8.4392],\n",
      "        [ 1.3175],\n",
      "        [ 9.7700],\n",
      "        [ 9.9266],\n",
      "        [ 8.9065],\n",
      "        [ 8.9453],\n",
      "        [10.4702],\n",
      "        [ 9.1663],\n",
      "        [ 1.6918],\n",
      "        [10.1153],\n",
      "        [ 9.5414],\n",
      "        [10.9422],\n",
      "        [10.3182],\n",
      "        [ 9.6658],\n",
      "        [ 9.9103],\n",
      "        [10.1525],\n",
      "        [ 8.9379],\n",
      "        [10.1691],\n",
      "        [ 4.1649],\n",
      "        [10.3072],\n",
      "        [ 8.2662],\n",
      "        [ 8.0261],\n",
      "        [ 1.1802],\n",
      "        [10.6212],\n",
      "        [ 9.6533],\n",
      "        [ 8.1126],\n",
      "        [10.3527],\n",
      "        [ 9.6332],\n",
      "        [ 9.5492],\n",
      "        [ 2.1654],\n",
      "        [11.0761],\n",
      "        [ 8.9914],\n",
      "        [ 9.8736],\n",
      "        [ 1.9123],\n",
      "        [11.7996],\n",
      "        [11.4068],\n",
      "        [10.4293],\n",
      "        [ 1.7045],\n",
      "        [10.5567],\n",
      "        [10.2284],\n",
      "        [ 9.2586],\n",
      "        [10.1686],\n",
      "        [10.2880],\n",
      "        [10.2442],\n",
      "        [10.4113],\n",
      "        [11.1131],\n",
      "        [10.3014],\n",
      "        [10.8534],\n",
      "        [ 9.6190],\n",
      "        [11.3316],\n",
      "        [11.3333],\n",
      "        [ 9.9370],\n",
      "        [ 1.2026],\n",
      "        [11.4191],\n",
      "        [ 9.6419],\n",
      "        [ 2.1967],\n",
      "        [ 1.1918],\n",
      "        [10.0823],\n",
      "        [10.8982],\n",
      "        [11.1730],\n",
      "        [10.6352],\n",
      "        [ 8.6641],\n",
      "        [ 9.3998],\n",
      "        [ 1.0847],\n",
      "        [10.2090],\n",
      "        [10.3101],\n",
      "        [ 9.8553],\n",
      "        [10.7160],\n",
      "        [ 1.9592],\n",
      "        [ 9.6185],\n",
      "        [10.6995],\n",
      "        [11.1649],\n",
      "        [10.5137],\n",
      "        [ 2.2205],\n",
      "        [ 8.3558],\n",
      "        [10.3429],\n",
      "        [ 8.5902],\n",
      "        [ 8.3477],\n",
      "        [ 9.6926],\n",
      "        [ 9.2196],\n",
      "        [10.5441],\n",
      "        [10.7003],\n",
      "        [ 9.5440],\n",
      "        [10.6488],\n",
      "        [10.6854],\n",
      "        [ 1.3239],\n",
      "        [10.1917],\n",
      "        [ 9.8908],\n",
      "        [10.4921],\n",
      "        [11.4703],\n",
      "        [10.8314],\n",
      "        [ 8.4922]], device='cuda:0')\n",
      "2 0\n",
      "100\n",
      "Validation batch...\n",
      "Forward Called\n",
      "tensor([[ 1.2838],\n",
      "        [ 9.5892],\n",
      "        [ 9.8973],\n",
      "        [10.4529],\n",
      "        [ 9.8638],\n",
      "        [ 9.9010],\n",
      "        [10.7229],\n",
      "        [11.0960],\n",
      "        [ 9.4273],\n",
      "        [10.3373],\n",
      "        [ 9.4461],\n",
      "        [ 8.4476],\n",
      "        [10.0038],\n",
      "        [ 2.1965],\n",
      "        [10.4971],\n",
      "        [10.7130],\n",
      "        [10.1343],\n",
      "        [ 1.1469],\n",
      "        [10.1954],\n",
      "        [10.0212],\n",
      "        [ 5.5599],\n",
      "        [ 9.7843],\n",
      "        [11.7184],\n",
      "        [ 8.3488],\n",
      "        [ 9.7701],\n",
      "        [11.2383],\n",
      "        [10.8018],\n",
      "        [10.2712],\n",
      "        [ 9.6135],\n",
      "        [ 1.3025],\n",
      "        [ 9.3020],\n",
      "        [10.5236],\n",
      "        [ 1.1873],\n",
      "        [ 8.6483],\n",
      "        [10.6337],\n",
      "        [ 8.7951],\n",
      "        [ 1.7585],\n",
      "        [ 9.7429],\n",
      "        [10.4096],\n",
      "        [10.2089],\n",
      "        [ 1.6104],\n",
      "        [11.3532],\n",
      "        [ 8.9551],\n",
      "        [ 1.8410],\n",
      "        [11.1793],\n",
      "        [ 9.5878],\n",
      "        [ 9.2031],\n",
      "        [ 1.4243],\n",
      "        [ 1.2928],\n",
      "        [10.3323],\n",
      "        [ 9.1579],\n",
      "        [ 9.0278],\n",
      "        [10.6450],\n",
      "        [10.6210],\n",
      "        [ 9.0072],\n",
      "        [ 9.4229],\n",
      "        [ 9.3407],\n",
      "        [ 1.7152],\n",
      "        [ 9.5563],\n",
      "        [10.5176],\n",
      "        [ 1.4440],\n",
      "        [11.3079],\n",
      "        [10.0491],\n",
      "        [ 1.7683],\n",
      "        [ 9.9233],\n",
      "        [ 1.4987],\n",
      "        [10.8515],\n",
      "        [ 9.5735],\n",
      "        [10.4771],\n",
      "        [ 8.4859],\n",
      "        [ 1.2591],\n",
      "        [ 9.6449],\n",
      "        [ 9.1625],\n",
      "        [ 9.2388],\n",
      "        [ 1.9551],\n",
      "        [ 2.1383],\n",
      "        [10.3381],\n",
      "        [11.0815],\n",
      "        [10.3071],\n",
      "        [ 8.9494],\n",
      "        [10.7335],\n",
      "        [ 8.5952],\n",
      "        [10.7420],\n",
      "        [ 9.3536],\n",
      "        [ 8.9641],\n",
      "        [11.4949],\n",
      "        [ 1.1930],\n",
      "        [ 8.7890],\n",
      "        [10.2288],\n",
      "        [ 1.6619],\n",
      "        [ 9.8601],\n",
      "        [10.0259],\n",
      "        [10.0450],\n",
      "        [10.6644],\n",
      "        [10.8846],\n",
      "        [10.2823],\n",
      "        [ 1.4886],\n",
      "        [10.4351],\n",
      "        [ 1.4141],\n",
      "        [ 9.7323]], device='cuda:0')\n",
      "3 0\n",
      "100\n",
      "Validation batch...\n",
      "Forward Called\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9.7564],\n",
      "        [10.5399],\n",
      "        [ 1.2794],\n",
      "        [11.0927],\n",
      "        [ 9.6398],\n",
      "        [ 1.9084],\n",
      "        [10.8276],\n",
      "        [ 1.3299],\n",
      "        [11.0903],\n",
      "        [ 1.5787],\n",
      "        [10.2449],\n",
      "        [10.2301],\n",
      "        [ 9.4843],\n",
      "        [11.0724],\n",
      "        [ 8.1438],\n",
      "        [10.9037],\n",
      "        [ 8.8865],\n",
      "        [10.1176],\n",
      "        [11.1396],\n",
      "        [10.8018],\n",
      "        [11.6596],\n",
      "        [10.6456],\n",
      "        [11.4584],\n",
      "        [ 1.5406],\n",
      "        [10.2384],\n",
      "        [11.2376],\n",
      "        [11.8635],\n",
      "        [ 9.2857],\n",
      "        [10.8275],\n",
      "        [10.5733],\n",
      "        [ 1.3649],\n",
      "        [ 1.9594],\n",
      "        [ 2.5324],\n",
      "        [ 8.4910],\n",
      "        [10.4563],\n",
      "        [10.9542],\n",
      "        [ 1.1452],\n",
      "        [10.0919],\n",
      "        [ 9.6086],\n",
      "        [ 9.4721],\n",
      "        [11.4864],\n",
      "        [11.0382],\n",
      "        [ 0.9958],\n",
      "        [10.2029],\n",
      "        [ 1.3004],\n",
      "        [10.9102],\n",
      "        [ 8.8624],\n",
      "        [10.7170],\n",
      "        [ 9.6367],\n",
      "        [ 9.7293],\n",
      "        [10.7444],\n",
      "        [ 1.6972],\n",
      "        [ 9.9527],\n",
      "        [ 8.5730],\n",
      "        [ 9.4051],\n",
      "        [ 9.7130],\n",
      "        [10.2688],\n",
      "        [11.4980],\n",
      "        [ 9.0992],\n",
      "        [ 9.4775],\n",
      "        [10.4753],\n",
      "        [ 8.9765],\n",
      "        [ 9.9016],\n",
      "        [ 9.1460],\n",
      "        [ 1.0227],\n",
      "        [ 9.1868],\n",
      "        [11.4762],\n",
      "        [ 8.4615],\n",
      "        [11.1569],\n",
      "        [ 9.7522],\n",
      "        [10.6012],\n",
      "        [ 8.7167],\n",
      "        [ 8.7682],\n",
      "        [ 9.2045],\n",
      "        [ 2.2020],\n",
      "        [ 9.2307],\n",
      "        [ 9.8109],\n",
      "        [ 9.1174],\n",
      "        [10.0305],\n",
      "        [ 9.0290],\n",
      "        [ 8.5709],\n",
      "        [ 1.3303],\n",
      "        [10.9528],\n",
      "        [11.4764],\n",
      "        [10.2901],\n",
      "        [ 8.9885],\n",
      "        [ 9.3942],\n",
      "        [ 9.9663],\n",
      "        [10.3322],\n",
      "        [10.2937],\n",
      "        [10.0469],\n",
      "        [ 9.6418],\n",
      "        [10.9058],\n",
      "        [ 8.2674],\n",
      "        [10.3585],\n",
      "        [ 9.3607],\n",
      "        [10.6324],\n",
      "        [ 8.5125],\n",
      "        [ 9.1450],\n",
      "        [10.4388]], device='cuda:0')\n",
      "4 0\n",
      "100\n",
      "Validation batch...\n",
      "Forward Called\n",
      "tensor([[ 9.9064],\n",
      "        [ 2.0305],\n",
      "        [ 9.8705],\n",
      "        [11.3336],\n",
      "        [ 2.0264],\n",
      "        [10.0167],\n",
      "        [10.0377],\n",
      "        [ 8.5625],\n",
      "        [ 1.1147],\n",
      "        [ 9.0850],\n",
      "        [ 9.5102],\n",
      "        [10.2701],\n",
      "        [10.0763],\n",
      "        [ 8.5388],\n",
      "        [ 1.3702],\n",
      "        [ 9.8945],\n",
      "        [10.3593],\n",
      "        [ 8.0409],\n",
      "        [10.8582],\n",
      "        [ 9.3214],\n",
      "        [ 9.6957],\n",
      "        [11.0537],\n",
      "        [ 8.7543],\n",
      "        [10.6021],\n",
      "        [ 9.7905],\n",
      "        [10.7597],\n",
      "        [10.5681],\n",
      "        [11.8105],\n",
      "        [10.2596],\n",
      "        [10.2995],\n",
      "        [10.3897],\n",
      "        [10.7903],\n",
      "        [ 9.1115],\n",
      "        [10.5979],\n",
      "        [11.5575],\n",
      "        [10.0087],\n",
      "        [ 9.5672],\n",
      "        [10.3620],\n",
      "        [10.1309],\n",
      "        [10.3355],\n",
      "        [ 8.2953],\n",
      "        [10.6098],\n",
      "        [11.2334],\n",
      "        [10.8413],\n",
      "        [10.6773],\n",
      "        [10.2934],\n",
      "        [10.2118],\n",
      "        [11.3774],\n",
      "        [10.5164],\n",
      "        [ 9.3281],\n",
      "        [11.4590],\n",
      "        [ 8.7290],\n",
      "        [ 1.5092],\n",
      "        [ 9.7219],\n",
      "        [ 9.6457],\n",
      "        [ 8.1768],\n",
      "        [ 9.4288],\n",
      "        [ 9.0718],\n",
      "        [10.1471],\n",
      "        [ 9.3461],\n",
      "        [10.6759],\n",
      "        [ 8.4606],\n",
      "        [ 8.4637],\n",
      "        [10.7548],\n",
      "        [ 8.5516],\n",
      "        [ 8.5914],\n",
      "        [ 9.5432],\n",
      "        [10.1298],\n",
      "        [10.0116],\n",
      "        [10.4310],\n",
      "        [10.4098],\n",
      "        [ 9.5759],\n",
      "        [10.7408],\n",
      "        [ 1.5887],\n",
      "        [10.5385],\n",
      "        [10.8295],\n",
      "        [ 8.7899],\n",
      "        [ 9.7335],\n",
      "        [ 1.4621],\n",
      "        [ 9.7522],\n",
      "        [ 9.5068],\n",
      "        [10.6356],\n",
      "        [10.4312],\n",
      "        [10.4207],\n",
      "        [ 1.5758],\n",
      "        [ 9.9312],\n",
      "        [10.2876],\n",
      "        [10.3124],\n",
      "        [10.3759],\n",
      "        [10.8489],\n",
      "        [ 9.0700],\n",
      "        [10.7882],\n",
      "        [ 8.4912],\n",
      "        [ 8.8677],\n",
      "        [10.1524],\n",
      "        [ 9.2643],\n",
      "        [ 9.0021],\n",
      "        [ 9.8440],\n",
      "        [ 9.4807],\n",
      "        [ 1.2348]], device='cuda:0')\n",
      "5 0\n",
      "100\n",
      "Validation batch...\n",
      "Forward Called\n",
      "tensor([[ 9.7201],\n",
      "        [10.6842],\n",
      "        [ 8.8121],\n",
      "        [10.0359],\n",
      "        [10.3868],\n",
      "        [ 1.5635],\n",
      "        [ 9.0109],\n",
      "        [ 9.2234],\n",
      "        [ 9.6915],\n",
      "        [ 1.1166],\n",
      "        [ 8.6428],\n",
      "        [11.1100],\n",
      "        [10.0644],\n",
      "        [ 9.3717],\n",
      "        [10.0233],\n",
      "        [10.2821],\n",
      "        [ 1.1607],\n",
      "        [10.2685],\n",
      "        [ 9.7654],\n",
      "        [11.1321],\n",
      "        [ 9.4263],\n",
      "        [ 9.1405],\n",
      "        [10.1352],\n",
      "        [10.1365],\n",
      "        [11.4570],\n",
      "        [10.0191],\n",
      "        [10.2276],\n",
      "        [ 1.8976],\n",
      "        [ 9.6951],\n",
      "        [10.2865],\n",
      "        [ 9.9673],\n",
      "        [10.5026],\n",
      "        [ 1.3492],\n",
      "        [10.8372],\n",
      "        [11.0326],\n",
      "        [11.0678],\n",
      "        [ 9.4233],\n",
      "        [ 9.9539],\n",
      "        [ 1.9023],\n",
      "        [ 9.1267],\n",
      "        [10.3295],\n",
      "        [10.1807],\n",
      "        [10.4999],\n",
      "        [10.0031],\n",
      "        [ 1.0308],\n",
      "        [ 9.1534],\n",
      "        [ 8.7436],\n",
      "        [ 8.5808],\n",
      "        [ 1.2622],\n",
      "        [10.5016],\n",
      "        [ 1.8026],\n",
      "        [ 9.5765],\n",
      "        [10.2087],\n",
      "        [10.2728],\n",
      "        [ 8.8899],\n",
      "        [ 1.5566],\n",
      "        [10.1868],\n",
      "        [ 8.3086],\n",
      "        [ 1.6918],\n",
      "        [ 1.3411],\n",
      "        [ 8.5160],\n",
      "        [ 9.8024],\n",
      "        [ 1.4880],\n",
      "        [10.3703],\n",
      "        [11.2303],\n",
      "        [10.1924],\n",
      "        [10.4841],\n",
      "        [ 9.5681],\n",
      "        [11.1386],\n",
      "        [ 1.3150],\n",
      "        [ 9.2374],\n",
      "        [ 1.5670],\n",
      "        [ 8.9726],\n",
      "        [10.9401],\n",
      "        [ 0.6613],\n",
      "        [ 8.3935],\n",
      "        [ 8.9451],\n",
      "        [10.2804],\n",
      "        [ 8.3591],\n",
      "        [ 9.0187],\n",
      "        [ 9.9148],\n",
      "        [ 1.3846],\n",
      "        [ 9.4847],\n",
      "        [11.1384],\n",
      "        [ 1.2667],\n",
      "        [11.3457],\n",
      "        [ 8.7731],\n",
      "        [ 1.7858],\n",
      "        [ 1.3194],\n",
      "        [10.6121],\n",
      "        [ 1.3659],\n",
      "        [11.1012],\n",
      "        [10.9808],\n",
      "        [10.3595],\n",
      "        [10.9272],\n",
      "        [ 9.6645],\n",
      "        [ 9.0514],\n",
      "        [10.0951],\n",
      "        [ 8.9492],\n",
      "        [10.6784]], device='cuda:0')\n",
      "6 0\n",
      "0\n",
      "will break\n",
      "Epoch: 1/5..  Training Loss: 0.002..  Test Loss: 0.002..  Test Accuracy: 0.914\n",
      "1 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.158529594540596\n",
      "2 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.16121335327625275\n",
      "3 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15091226994991302\n",
      "4 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.21767780184745789\n",
      "5 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.13783957064151764\n",
      "6 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.18968017399311066\n",
      "7 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1956508308649063\n",
      "8 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2531493604183197\n",
      "9 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.23564758896827698\n",
      "10 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2721024453639984\n",
      "11 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14131446182727814\n",
      "12 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.12701863050460815\n",
      "13 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15019963681697845\n",
      "14 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.2451598197221756\n",
      "15 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.25054001808166504\n",
      "16 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15993493795394897\n",
      "17 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1952572762966156\n",
      "18 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15919971466064453\n",
      "19 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2786884307861328\n",
      "20 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.17020778357982635\n",
      "21 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1934177726507187\n",
      "22 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1855613738298416\n",
      "23 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2204001545906067\n",
      "24 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14102645218372345\n",
      "25 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.291541188955307\n",
      "26 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.24863997101783752\n",
      "27 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2221255749464035\n",
      "28 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.18365275859832764\n",
      "29 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.16021482646465302\n",
      "30 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.18519245088100433\n",
      "31 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.13971176743507385\n",
      "32 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.18210989236831665\n",
      "33 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1738778054714203\n",
      "34 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2272498905658722\n",
      "35 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14579777419567108\n",
      "36 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.19240760803222656\n",
      "37 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2217293381690979\n",
      "38 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1526406854391098\n",
      "39 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.20854873955249786\n",
      "40 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14530177414417267\n",
      "41 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.13906331360340118\n",
      "42 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.12437675148248672\n",
      "43 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.12624332308769226\n",
      "44 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.165517657995224\n",
      "45 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.16432307660579681\n",
      "46 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.21947750449180603\n",
      "47 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.16595663130283356\n",
      "48 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.19545526802539825\n",
      "49 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.11031485348939896\n",
      "50 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1387510448694229\n",
      "51 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.13350935280323029\n",
      "52 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.22314684092998505\n",
      "53 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.13497395813465118\n",
      "54 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.16220508515834808\n",
      "55 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1761292666196823\n",
      "56 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14909759163856506\n",
      "57 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.17738327383995056\n",
      "58 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.18515057861804962\n",
      "59 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.19325119256973267\n",
      "60 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14471735060214996\n",
      "61 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14015676081180573\n",
      "62 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.16676458716392517\n",
      "63 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.17163720726966858\n",
      "64 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1971406787633896\n",
      "65 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.36766424775123596\n",
      "66 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.23180203139781952\n",
      "67 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.23829664289951324\n",
      "68 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.12957137823104858\n",
      "69 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15768887102603912\n",
      "70 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.32052338123321533\n",
      "71 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.13443410396575928\n",
      "72 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1240549087524414\n",
      "73 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15035685896873474\n",
      "74 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1664423942565918\n",
      "75 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1633458137512207\n",
      "76 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1916549801826477\n",
      "77 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.21734800934791565\n",
      "78 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15013357996940613\n",
      "79 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1442478746175766\n",
      "80 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2317417860031128\n",
      "81 0\n",
      "0\n",
      "will break\n",
      "1 0\n",
      "100\n",
      "Validation batch...\n",
      "Forward Called\n",
      "tensor([[ 8.8425],\n",
      "        [ 8.4419],\n",
      "        [ 9.1090],\n",
      "        [ 9.4501],\n",
      "        [10.9609],\n",
      "        [ 8.3954],\n",
      "        [ 1.9057],\n",
      "        [ 9.1462],\n",
      "        [ 7.3108],\n",
      "        [ 1.2380],\n",
      "        [ 8.9940],\n",
      "        [ 9.3463],\n",
      "        [ 8.1149],\n",
      "        [ 8.1070],\n",
      "        [ 9.8359],\n",
      "        [ 8.4733],\n",
      "        [ 1.7783],\n",
      "        [ 9.7972],\n",
      "        [ 8.8932],\n",
      "        [10.5660],\n",
      "        [ 9.9475],\n",
      "        [ 9.1781],\n",
      "        [ 9.3652],\n",
      "        [ 9.7084],\n",
      "        [ 8.1371],\n",
      "        [ 9.8836],\n",
      "        [ 3.6341],\n",
      "        [ 9.4857],\n",
      "        [ 7.5385],\n",
      "        [ 7.5470],\n",
      "        [ 1.0591],\n",
      "        [10.0223],\n",
      "        [ 9.0769],\n",
      "        [ 7.3929],\n",
      "        [ 9.6842],\n",
      "        [ 9.1476],\n",
      "        [ 8.7247],\n",
      "        [ 2.4989],\n",
      "        [10.6397],\n",
      "        [ 8.3342],\n",
      "        [ 9.2437],\n",
      "        [ 2.1535],\n",
      "        [10.9575],\n",
      "        [10.7709],\n",
      "        [ 9.8903],\n",
      "        [ 1.7871],\n",
      "        [10.0820],\n",
      "        [ 9.6847],\n",
      "        [ 8.2447],\n",
      "        [ 9.7266],\n",
      "        [ 9.6034],\n",
      "        [ 9.7722],\n",
      "        [ 9.5174],\n",
      "        [10.6234],\n",
      "        [ 9.9851],\n",
      "        [10.5096],\n",
      "        [ 8.8947],\n",
      "        [10.7524],\n",
      "        [10.4431],\n",
      "        [ 9.3727],\n",
      "        [ 1.1914],\n",
      "        [11.0388],\n",
      "        [ 9.1195],\n",
      "        [ 2.0813],\n",
      "        [ 1.1498],\n",
      "        [ 9.7048],\n",
      "        [10.2685],\n",
      "        [10.5337],\n",
      "        [ 9.8815],\n",
      "        [ 7.7572],\n",
      "        [ 8.6965],\n",
      "        [ 1.0603],\n",
      "        [ 9.5741],\n",
      "        [ 9.5664],\n",
      "        [ 9.0222],\n",
      "        [10.3005],\n",
      "        [ 2.1572],\n",
      "        [ 9.0544],\n",
      "        [10.3084],\n",
      "        [10.4047],\n",
      "        [ 9.9226],\n",
      "        [ 2.3926],\n",
      "        [ 7.6000],\n",
      "        [ 9.2115],\n",
      "        [ 8.0532],\n",
      "        [ 7.7392],\n",
      "        [ 9.0757],\n",
      "        [ 8.2883],\n",
      "        [10.0515],\n",
      "        [ 9.7634],\n",
      "        [ 8.9713],\n",
      "        [10.2252],\n",
      "        [ 9.8801],\n",
      "        [ 1.2260],\n",
      "        [ 9.1384],\n",
      "        [ 9.2488],\n",
      "        [10.0314],\n",
      "        [10.9764],\n",
      "        [10.4072],\n",
      "        [ 7.9675]], device='cuda:0')\n",
      "2 0\n",
      "100\n",
      "Validation batch...\n",
      "Forward Called\n",
      "tensor([[ 1.0998],\n",
      "        [ 9.0619],\n",
      "        [ 9.4570],\n",
      "        [ 9.8439],\n",
      "        [ 8.9350],\n",
      "        [ 9.2057],\n",
      "        [10.0357],\n",
      "        [10.5308],\n",
      "        [ 8.5495],\n",
      "        [ 9.8088],\n",
      "        [ 8.7413],\n",
      "        [ 7.8310],\n",
      "        [ 9.4686],\n",
      "        [ 2.2002],\n",
      "        [ 9.6061],\n",
      "        [10.1060],\n",
      "        [ 9.7534],\n",
      "        [ 1.1162],\n",
      "        [ 9.6983],\n",
      "        [ 9.4519],\n",
      "        [ 4.9830],\n",
      "        [ 9.2043],\n",
      "        [11.1042],\n",
      "        [ 7.8497],\n",
      "        [ 9.0141],\n",
      "        [10.6606],\n",
      "        [10.3725],\n",
      "        [ 9.5263],\n",
      "        [ 9.1568],\n",
      "        [ 1.1028],\n",
      "        [ 8.5154],\n",
      "        [ 9.9629],\n",
      "        [ 1.0824],\n",
      "        [ 8.2793],\n",
      "        [10.1021],\n",
      "        [ 7.7827],\n",
      "        [ 1.7347],\n",
      "        [ 8.9361],\n",
      "        [ 9.8891],\n",
      "        [ 9.6493],\n",
      "        [ 1.7213],\n",
      "        [10.8477],\n",
      "        [ 8.4518],\n",
      "        [ 2.1149],\n",
      "        [10.6505],\n",
      "        [ 9.1756],\n",
      "        [ 8.3055],\n",
      "        [ 1.0757],\n",
      "        [ 1.1761],\n",
      "        [ 9.7873],\n",
      "        [ 8.3619],\n",
      "        [ 8.2327],\n",
      "        [ 9.9060],\n",
      "        [10.2362],\n",
      "        [ 8.1326],\n",
      "        [ 8.7769],\n",
      "        [ 8.6220],\n",
      "        [ 1.7799],\n",
      "        [ 8.7314],\n",
      "        [10.0679],\n",
      "        [ 1.0501],\n",
      "        [10.6848],\n",
      "        [ 9.6284],\n",
      "        [ 1.6775],\n",
      "        [ 9.2244],\n",
      "        [ 1.4641],\n",
      "        [10.2235],\n",
      "        [ 8.9186],\n",
      "        [10.0481],\n",
      "        [ 7.7516],\n",
      "        [ 1.0981],\n",
      "        [ 8.9009],\n",
      "        [ 8.3989],\n",
      "        [ 8.6130],\n",
      "        [ 2.1249],\n",
      "        [ 2.4746],\n",
      "        [ 9.9037],\n",
      "        [10.5654],\n",
      "        [ 9.7089],\n",
      "        [ 8.5221],\n",
      "        [10.0247],\n",
      "        [ 7.9662],\n",
      "        [ 9.9848],\n",
      "        [ 8.4743],\n",
      "        [ 8.1949],\n",
      "        [10.9777],\n",
      "        [ 0.9477],\n",
      "        [ 8.2644],\n",
      "        [ 9.5553],\n",
      "        [ 1.6310],\n",
      "        [ 9.1412],\n",
      "        [ 9.2384],\n",
      "        [ 9.5774],\n",
      "        [10.1138],\n",
      "        [10.5241],\n",
      "        [ 9.5639],\n",
      "        [ 1.6138],\n",
      "        [ 9.8825],\n",
      "        [ 1.3997],\n",
      "        [ 9.0390]], device='cuda:0')\n",
      "3 0\n",
      "100\n",
      "Validation batch...\n",
      "Forward Called\n",
      "tensor([[ 8.9861],\n",
      "        [10.0222],\n",
      "        [ 1.1548],\n",
      "        [10.4618],\n",
      "        [ 8.9529],\n",
      "        [ 2.1657],\n",
      "        [10.4383],\n",
      "        [ 1.2875],\n",
      "        [10.5804],\n",
      "        [ 1.5068],\n",
      "        [ 9.3318],\n",
      "        [ 9.8513],\n",
      "        [ 8.8805],\n",
      "        [10.4550],\n",
      "        [ 7.6925],\n",
      "        [10.4978],\n",
      "        [ 8.1827],\n",
      "        [ 9.3323],\n",
      "        [10.4635],\n",
      "        [ 9.8834],\n",
      "        [11.2220],\n",
      "        [ 9.8271],\n",
      "        [10.6930],\n",
      "        [ 1.2344],\n",
      "        [ 9.6353],\n",
      "        [10.7535],\n",
      "        [11.3922],\n",
      "        [ 8.6810],\n",
      "        [10.4140],\n",
      "        [ 9.6005],\n",
      "        [ 1.4271],\n",
      "        [ 2.1471],\n",
      "        [ 2.0104],\n",
      "        [ 7.8620],\n",
      "        [ 9.9404],\n",
      "        [ 9.9656],\n",
      "        [ 1.0258],\n",
      "        [ 9.6456],\n",
      "        [ 9.0597],\n",
      "        [ 8.7673],\n",
      "        [10.8266],\n",
      "        [10.5625],\n",
      "        [ 0.7873],\n",
      "        [ 9.9340],\n",
      "        [ 1.3145],\n",
      "        [10.2569],\n",
      "        [ 8.0685],\n",
      "        [ 9.8351],\n",
      "        [ 8.9082],\n",
      "        [ 9.1901],\n",
      "        [10.3224],\n",
      "        [ 1.8022],\n",
      "        [ 9.2743],\n",
      "        [ 7.8715],\n",
      "        [ 8.8276],\n",
      "        [ 9.1122],\n",
      "        [ 9.4277],\n",
      "        [10.9223],\n",
      "        [ 8.1910],\n",
      "        [ 8.7355],\n",
      "        [ 9.8466],\n",
      "        [ 8.1599],\n",
      "        [ 9.5266],\n",
      "        [ 8.5680],\n",
      "        [ 0.8172],\n",
      "        [ 8.5048],\n",
      "        [10.8574],\n",
      "        [ 7.8503],\n",
      "        [10.4649],\n",
      "        [ 8.8634],\n",
      "        [ 9.9088],\n",
      "        [ 8.0456],\n",
      "        [ 7.8081],\n",
      "        [ 8.3214],\n",
      "        [ 2.0395],\n",
      "        [ 8.4236],\n",
      "        [ 9.2290],\n",
      "        [ 8.3298],\n",
      "        [ 9.1124],\n",
      "        [ 8.2202],\n",
      "        [ 7.9432],\n",
      "        [ 1.2605],\n",
      "        [10.1694],\n",
      "        [10.9023],\n",
      "        [ 9.7523],\n",
      "        [ 8.2269],\n",
      "        [ 8.5975],\n",
      "        [ 9.4591],\n",
      "        [ 9.9209],\n",
      "        [ 9.4819],\n",
      "        [ 9.1101],\n",
      "        [ 8.9994],\n",
      "        [10.2835],\n",
      "        [ 7.6279],\n",
      "        [ 9.7097],\n",
      "        [ 8.6970],\n",
      "        [10.2217],\n",
      "        [ 7.9900],\n",
      "        [ 8.2860],\n",
      "        [10.0037]], device='cuda:0')\n",
      "4 0\n",
      "100\n",
      "Validation batch...\n",
      "Forward Called\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9.5740],\n",
      "        [ 2.1886],\n",
      "        [ 9.2789],\n",
      "        [10.7749],\n",
      "        [ 2.1665],\n",
      "        [ 9.1512],\n",
      "        [ 9.5769],\n",
      "        [ 7.9203],\n",
      "        [ 0.9760],\n",
      "        [ 8.4799],\n",
      "        [ 9.0416],\n",
      "        [ 9.8877],\n",
      "        [ 9.3276],\n",
      "        [ 7.7827],\n",
      "        [ 1.2818],\n",
      "        [ 8.9695],\n",
      "        [ 9.5340],\n",
      "        [ 7.5915],\n",
      "        [10.1631],\n",
      "        [ 8.5994],\n",
      "        [ 9.1022],\n",
      "        [10.3390],\n",
      "        [ 8.2903],\n",
      "        [10.1939],\n",
      "        [ 8.9934],\n",
      "        [ 9.9336],\n",
      "        [ 9.9046],\n",
      "        [11.0120],\n",
      "        [ 9.8269],\n",
      "        [ 9.6524],\n",
      "        [ 9.6522],\n",
      "        [10.1048],\n",
      "        [ 8.0066],\n",
      "        [ 9.6447],\n",
      "        [11.0936],\n",
      "        [ 9.3160],\n",
      "        [ 8.9411],\n",
      "        [ 9.7046],\n",
      "        [ 9.5123],\n",
      "        [ 9.4705],\n",
      "        [ 7.6692],\n",
      "        [10.2322],\n",
      "        [10.7334],\n",
      "        [10.4159],\n",
      "        [10.3145],\n",
      "        [ 9.2662],\n",
      "        [ 9.5268],\n",
      "        [10.8852],\n",
      "        [ 9.3784],\n",
      "        [ 8.8394],\n",
      "        [10.9743],\n",
      "        [ 7.7103],\n",
      "        [ 1.4023],\n",
      "        [ 9.0246],\n",
      "        [ 8.6402],\n",
      "        [ 7.5468],\n",
      "        [ 8.6872],\n",
      "        [ 8.1785],\n",
      "        [ 9.4591],\n",
      "        [ 8.8263],\n",
      "        [10.2288],\n",
      "        [ 7.7296],\n",
      "        [ 7.7435],\n",
      "        [ 9.8747],\n",
      "        [ 7.6374],\n",
      "        [ 7.8800],\n",
      "        [ 9.0970],\n",
      "        [ 9.3623],\n",
      "        [ 9.3026],\n",
      "        [ 9.5243],\n",
      "        [ 9.5205],\n",
      "        [ 8.8304],\n",
      "        [ 9.9711],\n",
      "        [ 1.5249],\n",
      "        [ 9.6935],\n",
      "        [10.4112],\n",
      "        [ 8.2334],\n",
      "        [ 9.0172],\n",
      "        [ 1.4400],\n",
      "        [ 8.8634],\n",
      "        [ 8.7694],\n",
      "        [10.1060],\n",
      "        [ 9.8899],\n",
      "        [ 9.8112],\n",
      "        [ 1.4846],\n",
      "        [ 9.1650],\n",
      "        [ 9.7404],\n",
      "        [ 9.6659],\n",
      "        [ 9.7875],\n",
      "        [ 9.8887],\n",
      "        [ 8.4765],\n",
      "        [10.4395],\n",
      "        [ 8.0271],\n",
      "        [ 8.0005],\n",
      "        [ 9.6438],\n",
      "        [ 8.7678],\n",
      "        [ 8.5127],\n",
      "        [ 9.0159],\n",
      "        [ 8.4906],\n",
      "        [ 1.1204]], device='cuda:0')\n",
      "5 0\n",
      "100\n",
      "Validation batch...\n",
      "Forward Called\n",
      "tensor([[ 9.2734],\n",
      "        [ 9.8388],\n",
      "        [ 8.2354],\n",
      "        [ 9.2296],\n",
      "        [ 9.9449],\n",
      "        [ 1.3829],\n",
      "        [ 8.2615],\n",
      "        [ 8.6715],\n",
      "        [ 8.9336],\n",
      "        [ 0.8888],\n",
      "        [ 8.0835],\n",
      "        [10.1619],\n",
      "        [ 9.6180],\n",
      "        [ 8.9179],\n",
      "        [ 9.4127],\n",
      "        [ 9.7672],\n",
      "        [ 1.0018],\n",
      "        [ 9.6048],\n",
      "        [ 9.3423],\n",
      "        [10.3391],\n",
      "        [ 8.7136],\n",
      "        [ 8.3351],\n",
      "        [ 9.7417],\n",
      "        [ 9.3602],\n",
      "        [10.8751],\n",
      "        [ 9.4017],\n",
      "        [ 9.5521],\n",
      "        [ 1.9751],\n",
      "        [ 9.1484],\n",
      "        [ 9.5436],\n",
      "        [ 9.1493],\n",
      "        [ 9.9582],\n",
      "        [ 1.3893],\n",
      "        [ 9.9181],\n",
      "        [10.7482],\n",
      "        [10.5461],\n",
      "        [ 8.7545],\n",
      "        [ 9.4746],\n",
      "        [ 2.1040],\n",
      "        [ 8.5546],\n",
      "        [ 9.7427],\n",
      "        [ 9.3486],\n",
      "        [ 9.8067],\n",
      "        [ 8.8545],\n",
      "        [ 0.8632],\n",
      "        [ 8.4336],\n",
      "        [ 8.2560],\n",
      "        [ 7.9964],\n",
      "        [ 1.1035],\n",
      "        [10.0098],\n",
      "        [ 1.9196],\n",
      "        [ 8.9022],\n",
      "        [ 9.3571],\n",
      "        [ 9.9028],\n",
      "        [ 8.0989],\n",
      "        [ 1.5243],\n",
      "        [ 9.6852],\n",
      "        [ 7.9068],\n",
      "        [ 1.7122],\n",
      "        [ 1.0498],\n",
      "        [ 7.7828],\n",
      "        [ 9.4316],\n",
      "        [ 1.6043],\n",
      "        [ 9.9352],\n",
      "        [10.7033],\n",
      "        [ 9.7293],\n",
      "        [ 9.8702],\n",
      "        [ 8.4909],\n",
      "        [10.4143],\n",
      "        [ 1.4688],\n",
      "        [ 8.4713],\n",
      "        [ 1.5063],\n",
      "        [ 8.2645],\n",
      "        [10.2575],\n",
      "        [ 0.7024],\n",
      "        [ 7.8427],\n",
      "        [ 8.3550],\n",
      "        [ 9.9181],\n",
      "        [ 7.7806],\n",
      "        [ 8.2500],\n",
      "        [ 9.4172],\n",
      "        [ 1.2647],\n",
      "        [ 8.7713],\n",
      "        [10.3938],\n",
      "        [ 0.9990],\n",
      "        [10.4719],\n",
      "        [ 8.3113],\n",
      "        [ 1.8656],\n",
      "        [ 1.3090],\n",
      "        [ 9.5870],\n",
      "        [ 1.3310],\n",
      "        [10.3185],\n",
      "        [10.5651],\n",
      "        [ 9.6737],\n",
      "        [10.1636],\n",
      "        [ 8.9383],\n",
      "        [ 8.5619],\n",
      "        [ 9.0498],\n",
      "        [ 8.3333],\n",
      "        [ 9.8939]], device='cuda:0')\n",
      "6 0\n",
      "0\n",
      "will break\n",
      "Epoch: 2/5..  Training Loss: 0.002..  Test Loss: 0.002..  Test Accuracy: 0.918\n",
      "1 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1690567582845688\n",
      "2 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.16401447355747223\n",
      "3 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1399630606174469\n",
      "4 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2207571417093277\n",
      "5 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14027422666549683\n",
      "6 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.16945278644561768\n",
      "7 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.20480400323867798\n",
      "8 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.30785998702049255\n",
      "9 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.21900223195552826\n",
      "10 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.24472366273403168\n",
      "11 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.16389015316963196\n",
      "12 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1314648985862732\n",
      "13 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.12719449400901794\n",
      "14 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2150098830461502\n",
      "15 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.22050341963768005\n",
      "16 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.17514534294605255\n",
      "17 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.18185676634311676\n",
      "18 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1681126058101654\n",
      "19 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2756732106208801\n",
      "20 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.17699375748634338\n",
      "21 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.20069299638271332\n",
      "22 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.19444309175014496\n",
      "23 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2270861566066742\n",
      "24 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14808693528175354\n",
      "25 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.2647680342197418\n",
      "26 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2523740530014038\n",
      "27 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.23974712193012238\n",
      "28 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.18570318818092346\n",
      "29 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.18680624663829803\n",
      "30 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.16594171524047852\n",
      "31 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.13922889530658722\n",
      "32 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1777179092168808\n",
      "33 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.19786310195922852\n",
      "34 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.21754814684391022\n",
      "35 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14505337178707123\n",
      "36 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2101239711046219\n",
      "37 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.20127539336681366\n",
      "38 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1351933628320694\n",
      "39 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.23389774560928345\n",
      "40 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1677216738462448\n",
      "41 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.11888245493173599\n",
      "42 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14023378491401672\n",
      "43 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.11322713643312454\n",
      "44 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.13216006755828857\n",
      "45 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15583008527755737\n",
      "46 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.20177175104618073\n",
      "47 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.17533592879772186\n",
      "48 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.21629689633846283\n",
      "49 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.12006697058677673\n",
      "50 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.13063034415245056\n",
      "51 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.12763622403144836\n",
      "52 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2192901223897934\n",
      "53 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.13369043171405792\n",
      "54 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.155249685049057\n",
      "55 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1904640644788742\n",
      "56 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.13118082284927368\n",
      "57 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.16517598927021027\n",
      "58 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.16155070066452026\n",
      "59 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.20280878245830536\n",
      "60 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.137506365776062\n",
      "61 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15654565393924713\n",
      "62 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1669381856918335\n",
      "63 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1873018592596054\n",
      "64 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.23588448762893677\n",
      "65 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.373130202293396\n",
      "66 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.27190276980400085\n",
      "67 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.20804588496685028\n",
      "68 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.12393051385879517\n",
      "69 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15527507662773132\n",
      "70 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.28290969133377075\n",
      "71 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14958646893501282\n",
      "72 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14301908016204834\n",
      "73 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.13691474497318268\n",
      "74 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.16629083454608917\n",
      "75 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14028160274028778\n",
      "76 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1624240279197693\n",
      "77 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.19638080894947052\n",
      "78 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1291349083185196\n",
      "79 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.12843057513237\n",
      "80 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.23342853784561157\n",
      "81 0\n",
      "0\n",
      "will break\n",
      "1 0\n",
      "100\n",
      "Validation batch...\n",
      "Forward Called\n",
      "tensor([[ 8.0923],\n",
      "        [ 7.9579],\n",
      "        [ 8.2108],\n",
      "        [ 8.7245],\n",
      "        [ 9.9338],\n",
      "        [ 7.8195],\n",
      "        [ 2.1087],\n",
      "        [ 8.4713],\n",
      "        [ 6.5229],\n",
      "        [ 1.4701],\n",
      "        [ 8.2481],\n",
      "        [ 8.6890],\n",
      "        [ 7.5843],\n",
      "        [ 7.4910],\n",
      "        [ 9.0742],\n",
      "        [ 7.8321],\n",
      "        [ 1.9219],\n",
      "        [ 9.2216],\n",
      "        [ 8.0973],\n",
      "        [ 9.9065],\n",
      "        [ 9.2734],\n",
      "        [ 8.5732],\n",
      "        [ 8.6371],\n",
      "        [ 9.1456],\n",
      "        [ 7.4735],\n",
      "        [ 9.2074],\n",
      "        [ 2.7775],\n",
      "        [ 8.6001],\n",
      "        [ 6.7621],\n",
      "        [ 7.1512],\n",
      "        [ 1.1723],\n",
      "        [ 9.2521],\n",
      "        [ 8.5055],\n",
      "        [ 6.9821],\n",
      "        [ 8.8680],\n",
      "        [ 8.6680],\n",
      "        [ 8.1980],\n",
      "        [ 3.1063],\n",
      "        [ 9.9208],\n",
      "        [ 7.7060],\n",
      "        [ 8.5460],\n",
      "        [ 2.3743],\n",
      "        [10.0429],\n",
      "        [ 9.9673],\n",
      "        [ 9.1884],\n",
      "        [ 2.1990],\n",
      "        [ 9.4477],\n",
      "        [ 8.9977],\n",
      "        [ 7.4174],\n",
      "        [ 9.1474],\n",
      "        [ 8.9043],\n",
      "        [ 9.1052],\n",
      "        [ 8.6621],\n",
      "        [ 9.9427],\n",
      "        [ 9.4478],\n",
      "        [ 9.9093],\n",
      "        [ 8.2034],\n",
      "        [ 9.8838],\n",
      "        [ 9.5432],\n",
      "        [ 8.6933],\n",
      "        [ 1.4162],\n",
      "        [10.2339],\n",
      "        [ 8.2986],\n",
      "        [ 2.3319],\n",
      "        [ 1.2598],\n",
      "        [ 9.1271],\n",
      "        [ 9.6035],\n",
      "        [ 9.7280],\n",
      "        [ 9.1749],\n",
      "        [ 7.0140],\n",
      "        [ 8.0010],\n",
      "        [ 1.2270],\n",
      "        [ 8.7832],\n",
      "        [ 8.8350],\n",
      "        [ 8.2167],\n",
      "        [ 9.6914],\n",
      "        [ 2.4563],\n",
      "        [ 8.4635],\n",
      "        [ 9.6236],\n",
      "        [ 9.6453],\n",
      "        [ 9.3016],\n",
      "        [ 2.8083],\n",
      "        [ 7.0618],\n",
      "        [ 8.5296],\n",
      "        [ 7.1704],\n",
      "        [ 7.0840],\n",
      "        [ 8.4079],\n",
      "        [ 7.3921],\n",
      "        [ 9.2889],\n",
      "        [ 8.9336],\n",
      "        [ 8.2822],\n",
      "        [ 9.5214],\n",
      "        [ 8.8792],\n",
      "        [ 1.4199],\n",
      "        [ 8.2407],\n",
      "        [ 8.4792],\n",
      "        [ 9.3390],\n",
      "        [10.1426],\n",
      "        [ 9.7247],\n",
      "        [ 7.4053]], device='cuda:0')\n",
      "2 0\n",
      "100\n",
      "Validation batch...\n",
      "Forward Called\n",
      "tensor([[ 1.2038],\n",
      "        [ 8.2411],\n",
      "        [ 8.8805],\n",
      "        [ 9.1315],\n",
      "        [ 8.0321],\n",
      "        [ 8.2807],\n",
      "        [ 9.2632],\n",
      "        [ 9.7817],\n",
      "        [ 7.9052],\n",
      "        [ 9.0463],\n",
      "        [ 8.0987],\n",
      "        [ 7.2185],\n",
      "        [ 8.9230],\n",
      "        [ 2.5423],\n",
      "        [ 8.8224],\n",
      "        [ 9.2520],\n",
      "        [ 9.0380],\n",
      "        [ 1.2978],\n",
      "        [ 9.1433],\n",
      "        [ 8.8481],\n",
      "        [ 4.4218],\n",
      "        [ 8.6282],\n",
      "        [10.2121],\n",
      "        [ 7.0517],\n",
      "        [ 8.2394],\n",
      "        [ 9.6789],\n",
      "        [ 9.7292],\n",
      "        [ 8.7511],\n",
      "        [ 8.6278],\n",
      "        [ 1.2652],\n",
      "        [ 7.6508],\n",
      "        [ 9.1988],\n",
      "        [ 1.2749],\n",
      "        [ 7.5035],\n",
      "        [ 9.3744],\n",
      "        [ 6.8733],\n",
      "        [ 2.1035],\n",
      "        [ 8.0833],\n",
      "        [ 9.2253],\n",
      "        [ 9.0027],\n",
      "        [ 2.2274],\n",
      "        [10.1109],\n",
      "        [ 7.9217],\n",
      "        [ 2.5998],\n",
      "        [ 9.9733],\n",
      "        [ 8.5887],\n",
      "        [ 7.3999],\n",
      "        [ 1.1521],\n",
      "        [ 1.2918],\n",
      "        [ 9.0466],\n",
      "        [ 7.7417],\n",
      "        [ 7.5566],\n",
      "        [ 9.1333],\n",
      "        [ 9.4313],\n",
      "        [ 7.2697],\n",
      "        [ 7.9468],\n",
      "        [ 7.9426],\n",
      "        [ 2.0775],\n",
      "        [ 7.8531],\n",
      "        [ 9.3839],\n",
      "        [ 1.0159],\n",
      "        [ 9.8529],\n",
      "        [ 9.1248],\n",
      "        [ 1.9046],\n",
      "        [ 8.5345],\n",
      "        [ 1.7715],\n",
      "        [ 9.4526],\n",
      "        [ 8.1561],\n",
      "        [ 9.4383],\n",
      "        [ 7.3225],\n",
      "        [ 1.3246],\n",
      "        [ 8.1854],\n",
      "        [ 7.6236],\n",
      "        [ 7.9710],\n",
      "        [ 2.5590],\n",
      "        [ 3.0575],\n",
      "        [ 9.2293],\n",
      "        [ 9.8235],\n",
      "        [ 9.0454],\n",
      "        [ 7.7957],\n",
      "        [ 9.1017],\n",
      "        [ 7.5137],\n",
      "        [ 9.1168],\n",
      "        [ 7.7795],\n",
      "        [ 7.6564],\n",
      "        [10.1373],\n",
      "        [ 1.0338],\n",
      "        [ 7.6617],\n",
      "        [ 8.7000],\n",
      "        [ 1.8878],\n",
      "        [ 8.0865],\n",
      "        [ 8.5965],\n",
      "        [ 8.8634],\n",
      "        [ 9.2482],\n",
      "        [ 9.8187],\n",
      "        [ 8.8654],\n",
      "        [ 1.7588],\n",
      "        [ 9.2013],\n",
      "        [ 1.7243],\n",
      "        [ 8.3624]], device='cuda:0')\n",
      "3 0\n",
      "100\n",
      "Validation batch...\n",
      "Forward Called\n",
      "tensor([[ 8.0766],\n",
      "        [ 9.2391],\n",
      "        [ 1.3068],\n",
      "        [ 9.5378],\n",
      "        [ 8.2541],\n",
      "        [ 2.6621],\n",
      "        [ 9.7644],\n",
      "        [ 1.5317],\n",
      "        [ 9.8280],\n",
      "        [ 1.7172],\n",
      "        [ 8.6960],\n",
      "        [ 9.1859],\n",
      "        [ 8.2656],\n",
      "        [ 9.6825],\n",
      "        [ 7.2620],\n",
      "        [ 9.8017],\n",
      "        [ 7.3593],\n",
      "        [ 8.3649],\n",
      "        [ 9.4979],\n",
      "        [ 9.0872],\n",
      "        [10.4787],\n",
      "        [ 9.0366],\n",
      "        [ 9.9133],\n",
      "        [ 1.5519],\n",
      "        [ 8.8184],\n",
      "        [10.0285],\n",
      "        [10.5226],\n",
      "        [ 8.0165],\n",
      "        [ 9.8526],\n",
      "        [ 8.9258],\n",
      "        [ 1.7276],\n",
      "        [ 2.5866],\n",
      "        [ 1.5263],\n",
      "        [ 7.2362],\n",
      "        [ 9.2894],\n",
      "        [ 9.0720],\n",
      "        [ 1.1462],\n",
      "        [ 9.0878],\n",
      "        [ 8.4529],\n",
      "        [ 8.0692],\n",
      "        [ 9.9703],\n",
      "        [ 9.8972],\n",
      "        [ 0.9616],\n",
      "        [ 9.3556],\n",
      "        [ 1.5123],\n",
      "        [ 9.5317],\n",
      "        [ 7.3712],\n",
      "        [ 9.0687],\n",
      "        [ 8.2072],\n",
      "        [ 8.4721],\n",
      "        [ 9.6965],\n",
      "        [ 2.1725],\n",
      "        [ 8.5083],\n",
      "        [ 7.2546],\n",
      "        [ 8.1932],\n",
      "        [ 8.4142],\n",
      "        [ 8.5675],\n",
      "        [10.1080],\n",
      "        [ 7.5765],\n",
      "        [ 8.1036],\n",
      "        [ 9.1234],\n",
      "        [ 7.6208],\n",
      "        [ 8.8932],\n",
      "        [ 7.9884],\n",
      "        [ 0.9195],\n",
      "        [ 7.9220],\n",
      "        [ 9.9869],\n",
      "        [ 7.4626],\n",
      "        [ 9.6740],\n",
      "        [ 8.1840],\n",
      "        [ 9.0927],\n",
      "        [ 7.6347],\n",
      "        [ 6.9444],\n",
      "        [ 7.3666],\n",
      "        [ 2.3331],\n",
      "        [ 7.7212],\n",
      "        [ 8.4481],\n",
      "        [ 7.7265],\n",
      "        [ 8.3199],\n",
      "        [ 7.5084],\n",
      "        [ 7.2921],\n",
      "        [ 1.4417],\n",
      "        [ 9.2714],\n",
      "        [10.1135],\n",
      "        [ 9.0296],\n",
      "        [ 7.5267],\n",
      "        [ 7.9523],\n",
      "        [ 8.7565],\n",
      "        [ 9.3740],\n",
      "        [ 8.6261],\n",
      "        [ 8.0651],\n",
      "        [ 8.1886],\n",
      "        [ 9.3989],\n",
      "        [ 7.1838],\n",
      "        [ 8.8967],\n",
      "        [ 7.9553],\n",
      "        [ 9.4896],\n",
      "        [ 7.4393],\n",
      "        [ 7.7024],\n",
      "        [ 9.3906]], device='cuda:0')\n",
      "4 0\n",
      "100\n",
      "Validation batch...\n",
      "Forward Called\n",
      "tensor([[ 8.9755],\n",
      "        [ 2.4423],\n",
      "        [ 8.5897],\n",
      "        [10.0103],\n",
      "        [ 2.5332],\n",
      "        [ 8.3726],\n",
      "        [ 8.8360],\n",
      "        [ 7.3485],\n",
      "        [ 1.2052],\n",
      "        [ 7.9867],\n",
      "        [ 8.3100],\n",
      "        [ 9.2237],\n",
      "        [ 8.5315],\n",
      "        [ 7.0606],\n",
      "        [ 1.4924],\n",
      "        [ 8.0068],\n",
      "        [ 8.8152],\n",
      "        [ 7.0135],\n",
      "        [ 9.4066],\n",
      "        [ 7.8512],\n",
      "        [ 8.4539],\n",
      "        [ 9.6100],\n",
      "        [ 7.5384],\n",
      "        [ 9.5191],\n",
      "        [ 8.1667],\n",
      "        [ 9.0514],\n",
      "        [ 9.1255],\n",
      "        [10.1186],\n",
      "        [ 9.2087],\n",
      "        [ 8.9606],\n",
      "        [ 8.6730],\n",
      "        [ 9.3055],\n",
      "        [ 7.3486],\n",
      "        [ 8.8137],\n",
      "        [10.1784],\n",
      "        [ 8.6056],\n",
      "        [ 8.2514],\n",
      "        [ 8.8869],\n",
      "        [ 8.7883],\n",
      "        [ 8.7586],\n",
      "        [ 7.2178],\n",
      "        [ 9.5347],\n",
      "        [ 9.9455],\n",
      "        [ 9.7133],\n",
      "        [ 9.6609],\n",
      "        [ 8.5232],\n",
      "        [ 8.6101],\n",
      "        [10.0122],\n",
      "        [ 8.5819],\n",
      "        [ 7.9613],\n",
      "        [10.1868],\n",
      "        [ 7.0060],\n",
      "        [ 1.5737],\n",
      "        [ 8.2373],\n",
      "        [ 7.7261],\n",
      "        [ 7.1326],\n",
      "        [ 7.8914],\n",
      "        [ 7.6099],\n",
      "        [ 8.7232],\n",
      "        [ 8.2753],\n",
      "        [ 9.6245],\n",
      "        [ 7.1467],\n",
      "        [ 7.2232],\n",
      "        [ 9.0311],\n",
      "        [ 6.9329],\n",
      "        [ 7.3579],\n",
      "        [ 8.2463],\n",
      "        [ 8.6595],\n",
      "        [ 8.5694],\n",
      "        [ 8.7326],\n",
      "        [ 8.8218],\n",
      "        [ 8.1324],\n",
      "        [ 9.0906],\n",
      "        [ 1.7570],\n",
      "        [ 8.8862],\n",
      "        [ 9.7995],\n",
      "        [ 7.5877],\n",
      "        [ 8.3319],\n",
      "        [ 1.6022],\n",
      "        [ 8.1840],\n",
      "        [ 7.8148],\n",
      "        [ 9.4785],\n",
      "        [ 9.2696],\n",
      "        [ 9.0603],\n",
      "        [ 1.7002],\n",
      "        [ 8.4224],\n",
      "        [ 9.1157],\n",
      "        [ 8.8840],\n",
      "        [ 9.1952],\n",
      "        [ 8.8795],\n",
      "        [ 7.8816],\n",
      "        [ 9.8047],\n",
      "        [ 7.6716],\n",
      "        [ 7.2031],\n",
      "        [ 8.8288],\n",
      "        [ 7.9216],\n",
      "        [ 7.8713],\n",
      "        [ 8.2781],\n",
      "        [ 7.6844],\n",
      "        [ 1.2791]], device='cuda:0')\n",
      "5 0\n",
      "100\n",
      "Validation batch...\n",
      "Forward Called\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8.7705],\n",
      "        [ 9.0720],\n",
      "        [ 7.8309],\n",
      "        [ 8.3319],\n",
      "        [ 9.3775],\n",
      "        [ 1.5545],\n",
      "        [ 7.5715],\n",
      "        [ 8.1044],\n",
      "        [ 8.1196],\n",
      "        [ 1.0961],\n",
      "        [ 7.4989],\n",
      "        [ 9.3706],\n",
      "        [ 9.0178],\n",
      "        [ 8.3075],\n",
      "        [ 8.7916],\n",
      "        [ 9.1362],\n",
      "        [ 1.0120],\n",
      "        [ 8.8862],\n",
      "        [ 8.7932],\n",
      "        [ 9.5111],\n",
      "        [ 8.1237],\n",
      "        [ 7.7239],\n",
      "        [ 9.1666],\n",
      "        [ 8.5597],\n",
      "        [10.0928],\n",
      "        [ 8.7234],\n",
      "        [ 8.6993],\n",
      "        [ 2.4058],\n",
      "        [ 8.4358],\n",
      "        [ 8.8678],\n",
      "        [ 8.3498],\n",
      "        [ 9.2322],\n",
      "        [ 1.5253],\n",
      "        [ 9.0930],\n",
      "        [10.0760],\n",
      "        [ 9.6826],\n",
      "        [ 8.1538],\n",
      "        [ 8.8184],\n",
      "        [ 2.4186],\n",
      "        [ 7.8372],\n",
      "        [ 8.9947],\n",
      "        [ 8.6176],\n",
      "        [ 8.9952],\n",
      "        [ 7.7425],\n",
      "        [ 0.8429],\n",
      "        [ 7.9114],\n",
      "        [ 7.7378],\n",
      "        [ 7.5649],\n",
      "        [ 1.1497],\n",
      "        [ 9.3733],\n",
      "        [ 2.2605],\n",
      "        [ 8.1205],\n",
      "        [ 8.5619],\n",
      "        [ 9.2821],\n",
      "        [ 7.6933],\n",
      "        [ 1.8049],\n",
      "        [ 9.0744],\n",
      "        [ 7.3742],\n",
      "        [ 2.0507],\n",
      "        [ 1.1785],\n",
      "        [ 7.2013],\n",
      "        [ 8.8802],\n",
      "        [ 1.8912],\n",
      "        [ 9.2975],\n",
      "        [ 9.9216],\n",
      "        [ 9.1513],\n",
      "        [ 9.0560],\n",
      "        [ 7.8852],\n",
      "        [ 9.5631],\n",
      "        [ 1.6957],\n",
      "        [ 7.7245],\n",
      "        [ 1.7047],\n",
      "        [ 7.6658],\n",
      "        [ 9.4748],\n",
      "        [ 0.6652],\n",
      "        [ 7.4099],\n",
      "        [ 7.7759],\n",
      "        [ 9.2720],\n",
      "        [ 7.4263],\n",
      "        [ 7.4057],\n",
      "        [ 8.8190],\n",
      "        [ 1.4102],\n",
      "        [ 7.9714],\n",
      "        [ 9.4838],\n",
      "        [ 1.1345],\n",
      "        [ 9.3726],\n",
      "        [ 7.5682],\n",
      "        [ 2.0791],\n",
      "        [ 1.5168],\n",
      "        [ 8.7765],\n",
      "        [ 1.4740],\n",
      "        [ 9.5220],\n",
      "        [ 9.9398],\n",
      "        [ 8.8166],\n",
      "        [ 9.2270],\n",
      "        [ 8.1652],\n",
      "        [ 8.0516],\n",
      "        [ 8.1192],\n",
      "        [ 7.8144],\n",
      "        [ 9.1000]], device='cuda:0')\n",
      "6 0\n",
      "0\n",
      "will break\n",
      "Epoch: 3/5..  Training Loss: 0.002..  Test Loss: 0.002..  Test Accuracy: 0.916\n",
      "1 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.16351480782032013\n",
      "2 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15929993987083435\n",
      "3 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1422284096479416\n",
      "4 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.20322255790233612\n",
      "5 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.13649795949459076\n",
      "6 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.19229301810264587\n",
      "7 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1618681102991104\n",
      "8 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.26642632484436035\n",
      "9 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2387474775314331\n",
      "10 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.21425031125545502\n",
      "11 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14505663514137268\n",
      "12 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.11769352108240128\n",
      "13 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.13242973387241364\n",
      "14 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.19660072028636932\n",
      "15 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.24304963648319244\n",
      "16 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1646319180727005\n",
      "17 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.19928616285324097\n",
      "18 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15673476457595825\n",
      "19 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2354992926120758\n",
      "20 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14770139753818512\n",
      "21 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.18284942209720612\n",
      "22 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.20169812440872192\n",
      "23 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.23040537536144257\n",
      "24 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14033609628677368\n",
      "25 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2588019073009491\n",
      "26 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.23311112821102142\n",
      "27 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1997818499803543\n",
      "28 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.20008721947669983\n",
      "29 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.18944410979747772\n",
      "30 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.17639179527759552\n",
      "31 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.12565140426158905\n",
      "32 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.16936007142066956\n",
      "33 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.197603240609169\n",
      "34 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.25087714195251465\n",
      "35 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1441110372543335\n",
      "36 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1822669804096222\n",
      "37 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.226284921169281\n",
      "38 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.13683198392391205\n",
      "39 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.22220338881015778\n",
      "40 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.13787834346294403\n",
      "41 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.11810211837291718\n",
      "42 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.12820856273174286\n",
      "43 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1285911202430725\n",
      "44 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14698247611522675\n",
      "45 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15589137375354767\n",
      "46 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.17816929519176483\n",
      "47 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15933813154697418\n",
      "48 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.19537805020809174\n",
      "49 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.11228921264410019\n",
      "50 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.12573403120040894\n",
      "51 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.11733083426952362\n",
      "52 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2290579080581665\n",
      "53 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.12021370977163315\n",
      "54 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14631915092468262\n",
      "55 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.19402651488780975\n",
      "56 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1554650366306305\n",
      "57 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.17608779668807983\n",
      "58 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1637023687362671\n",
      "59 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.18520410358905792\n",
      "60 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.12892189621925354\n",
      "61 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15043911337852478\n",
      "62 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1596512645483017\n",
      "63 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15567374229431152\n",
      "64 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.19281163811683655\n",
      "65 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.334488183259964\n",
      "66 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.21935130655765533\n",
      "67 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1835121512413025\n",
      "68 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.12366652488708496\n",
      "69 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.13858875632286072\n",
      "70 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2491452842950821\n",
      "71 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1269558072090149\n",
      "72 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.10244813561439514\n",
      "73 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.13801851868629456\n",
      "74 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.16376538574695587\n",
      "75 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1387133151292801\n",
      "76 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.138438880443573\n",
      "77 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1723780483007431\n",
      "78 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.17903286218643188\n",
      "79 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15142399072647095\n",
      "80 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1997077614068985\n",
      "81 0\n",
      "0\n",
      "will break\n",
      "1 0\n",
      "100\n",
      "Validation batch...\n",
      "Forward Called\n",
      "tensor([[ 8.9415],\n",
      "        [ 8.6708],\n",
      "        [ 8.6061],\n",
      "        [ 9.2933],\n",
      "        [11.1611],\n",
      "        [ 8.5586],\n",
      "        [ 2.6393],\n",
      "        [ 9.5237],\n",
      "        [ 6.5623],\n",
      "        [ 1.7795],\n",
      "        [ 8.6795],\n",
      "        [ 9.5545],\n",
      "        [ 7.9117],\n",
      "        [ 7.6852],\n",
      "        [ 9.7718],\n",
      "        [ 8.4622],\n",
      "        [ 2.3678],\n",
      "        [10.1499],\n",
      "        [ 8.4152],\n",
      "        [10.8703],\n",
      "        [10.1522],\n",
      "        [ 9.0363],\n",
      "        [ 9.1150],\n",
      "        [ 9.8860],\n",
      "        [ 7.9029],\n",
      "        [ 9.9560],\n",
      "        [ 2.9810],\n",
      "        [ 9.4879],\n",
      "        [ 7.7109],\n",
      "        [ 7.7472],\n",
      "        [ 1.2072],\n",
      "        [10.0414],\n",
      "        [ 9.1520],\n",
      "        [ 7.4552],\n",
      "        [ 9.6932],\n",
      "        [ 9.4619],\n",
      "        [ 8.6908],\n",
      "        [ 2.9211],\n",
      "        [10.7929],\n",
      "        [ 8.4912],\n",
      "        [ 8.9728],\n",
      "        [ 2.7346],\n",
      "        [11.2252],\n",
      "        [10.8660],\n",
      "        [ 9.8406],\n",
      "        [ 1.9629],\n",
      "        [10.2849],\n",
      "        [10.1162],\n",
      "        [ 8.0514],\n",
      "        [ 9.8854],\n",
      "        [ 9.5281],\n",
      "        [ 9.9399],\n",
      "        [ 9.6587],\n",
      "        [11.0139],\n",
      "        [10.3287],\n",
      "        [10.8729],\n",
      "        [ 8.8052],\n",
      "        [10.7564],\n",
      "        [10.7186],\n",
      "        [ 9.3273],\n",
      "        [ 1.8606],\n",
      "        [11.4552],\n",
      "        [ 9.1707],\n",
      "        [ 2.5492],\n",
      "        [ 1.6243],\n",
      "        [10.0124],\n",
      "        [10.8003],\n",
      "        [10.5046],\n",
      "        [ 9.7818],\n",
      "        [ 7.2553],\n",
      "        [ 8.4300],\n",
      "        [ 1.0715],\n",
      "        [ 9.3525],\n",
      "        [ 9.9565],\n",
      "        [ 9.0733],\n",
      "        [10.7797],\n",
      "        [ 2.8282],\n",
      "        [ 9.3359],\n",
      "        [10.6494],\n",
      "        [10.8228],\n",
      "        [10.5114],\n",
      "        [ 3.2546],\n",
      "        [ 7.2535],\n",
      "        [ 9.6574],\n",
      "        [ 7.9289],\n",
      "        [ 7.8635],\n",
      "        [ 8.8742],\n",
      "        [ 7.5962],\n",
      "        [10.0404],\n",
      "        [10.1114],\n",
      "        [ 9.4145],\n",
      "        [10.3776],\n",
      "        [ 9.9895],\n",
      "        [ 1.4234],\n",
      "        [ 9.1841],\n",
      "        [ 9.0229],\n",
      "        [10.2661],\n",
      "        [11.1507],\n",
      "        [10.6231],\n",
      "        [ 8.3964]], device='cuda:0')\n",
      "2 0\n",
      "100\n",
      "Validation batch...\n",
      "Forward Called\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5831],\n",
      "        [ 9.5453],\n",
      "        [ 9.6794],\n",
      "        [10.0192],\n",
      "        [ 8.9260],\n",
      "        [ 9.4637],\n",
      "        [10.4452],\n",
      "        [11.0239],\n",
      "        [ 8.2759],\n",
      "        [ 9.7324],\n",
      "        [ 8.4553],\n",
      "        [ 7.9713],\n",
      "        [ 9.6770],\n",
      "        [ 2.7542],\n",
      "        [10.0597],\n",
      "        [10.4321],\n",
      "        [ 9.7044],\n",
      "        [ 1.6624],\n",
      "        [10.0308],\n",
      "        [ 9.4284],\n",
      "        [ 5.6343],\n",
      "        [ 9.2742],\n",
      "        [11.4835],\n",
      "        [ 7.7752],\n",
      "        [ 8.7233],\n",
      "        [10.9913],\n",
      "        [10.7013],\n",
      "        [ 9.2259],\n",
      "        [ 9.3070],\n",
      "        [ 1.6496],\n",
      "        [ 9.1341],\n",
      "        [10.3099],\n",
      "        [ 1.8025],\n",
      "        [ 8.3921],\n",
      "        [10.2592],\n",
      "        [ 6.8303],\n",
      "        [ 2.0221],\n",
      "        [ 9.1904],\n",
      "        [10.2726],\n",
      "        [ 9.7853],\n",
      "        [ 2.0185],\n",
      "        [11.0771],\n",
      "        [ 8.9083],\n",
      "        [ 2.4163],\n",
      "        [10.8630],\n",
      "        [ 9.2774],\n",
      "        [ 8.2374],\n",
      "        [ 1.4102],\n",
      "        [ 1.6849],\n",
      "        [ 9.8066],\n",
      "        [ 8.3567],\n",
      "        [ 8.1737],\n",
      "        [ 9.9444],\n",
      "        [10.8107],\n",
      "        [ 7.2882],\n",
      "        [ 8.1052],\n",
      "        [ 8.2935],\n",
      "        [ 1.7833],\n",
      "        [ 8.8986],\n",
      "        [10.0768],\n",
      "        [ 1.4084],\n",
      "        [10.6065],\n",
      "        [10.0503],\n",
      "        [ 2.0572],\n",
      "        [ 9.1883],\n",
      "        [ 1.7316],\n",
      "        [10.1265],\n",
      "        [ 8.6803],\n",
      "        [10.2199],\n",
      "        [ 7.9121],\n",
      "        [ 1.7613],\n",
      "        [ 8.5768],\n",
      "        [ 8.0549],\n",
      "        [ 8.7094],\n",
      "        [ 2.3157],\n",
      "        [ 2.8298],\n",
      "        [10.0699],\n",
      "        [11.1540],\n",
      "        [10.0609],\n",
      "        [ 8.7464],\n",
      "        [10.1731],\n",
      "        [ 8.1925],\n",
      "        [10.2174],\n",
      "        [ 8.5426],\n",
      "        [ 8.0691],\n",
      "        [11.0270],\n",
      "        [ 1.4625],\n",
      "        [ 8.4480],\n",
      "        [ 9.3779],\n",
      "        [ 2.1566],\n",
      "        [ 8.3330],\n",
      "        [ 9.3146],\n",
      "        [ 9.5673],\n",
      "        [10.3437],\n",
      "        [10.7432],\n",
      "        [ 9.3765],\n",
      "        [ 1.4691],\n",
      "        [ 9.9698],\n",
      "        [ 1.5633],\n",
      "        [ 9.2986]], device='cuda:0')\n",
      "3 0\n",
      "100\n",
      "Validation batch...\n",
      "Forward Called\n",
      "tensor([[ 9.1692],\n",
      "        [10.0080],\n",
      "        [ 1.5222],\n",
      "        [10.8200],\n",
      "        [ 8.6859],\n",
      "        [ 2.4576],\n",
      "        [10.6962],\n",
      "        [ 1.4433],\n",
      "        [10.8221],\n",
      "        [ 1.4972],\n",
      "        [ 9.6313],\n",
      "        [10.0311],\n",
      "        [ 9.0109],\n",
      "        [10.4230],\n",
      "        [ 7.9231],\n",
      "        [10.8635],\n",
      "        [ 7.8337],\n",
      "        [ 9.5694],\n",
      "        [10.8068],\n",
      "        [10.2640],\n",
      "        [11.5046],\n",
      "        [ 9.6464],\n",
      "        [11.1035],\n",
      "        [ 1.7875],\n",
      "        [10.1442],\n",
      "        [10.9546],\n",
      "        [11.5578],\n",
      "        [ 8.8838],\n",
      "        [10.8409],\n",
      "        [ 9.9843],\n",
      "        [ 1.4973],\n",
      "        [ 2.2683],\n",
      "        [ 1.8282],\n",
      "        [ 7.9423],\n",
      "        [10.0108],\n",
      "        [10.0875],\n",
      "        [ 1.5118],\n",
      "        [ 9.8618],\n",
      "        [ 9.0398],\n",
      "        [ 8.5905],\n",
      "        [10.7929],\n",
      "        [10.8234],\n",
      "        [ 1.2104],\n",
      "        [10.2592],\n",
      "        [ 1.8516],\n",
      "        [10.2568],\n",
      "        [ 7.6750],\n",
      "        [10.1099],\n",
      "        [ 8.7339],\n",
      "        [ 8.9861],\n",
      "        [10.6133],\n",
      "        [ 1.9412],\n",
      "        [ 8.9224],\n",
      "        [ 7.9115],\n",
      "        [ 8.7264],\n",
      "        [ 9.4135],\n",
      "        [ 9.7864],\n",
      "        [10.9524],\n",
      "        [ 7.9748],\n",
      "        [ 8.6455],\n",
      "        [ 9.7263],\n",
      "        [ 8.6585],\n",
      "        [ 9.6381],\n",
      "        [ 8.5214],\n",
      "        [ 1.3840],\n",
      "        [ 8.2606],\n",
      "        [11.1949],\n",
      "        [ 8.1766],\n",
      "        [10.4750],\n",
      "        [ 9.1775],\n",
      "        [ 9.7115],\n",
      "        [ 8.2839],\n",
      "        [ 7.0751],\n",
      "        [ 7.6523],\n",
      "        [ 2.6861],\n",
      "        [ 8.2944],\n",
      "        [ 8.9548],\n",
      "        [ 8.0711],\n",
      "        [ 9.3818],\n",
      "        [ 7.7930],\n",
      "        [ 8.3640],\n",
      "        [ 1.2891],\n",
      "        [10.5138],\n",
      "        [10.9473],\n",
      "        [ 9.6421],\n",
      "        [ 8.2212],\n",
      "        [ 8.6667],\n",
      "        [ 9.4652],\n",
      "        [10.2755],\n",
      "        [ 9.0680],\n",
      "        [ 8.9083],\n",
      "        [ 9.3810],\n",
      "        [10.5411],\n",
      "        [ 7.6905],\n",
      "        [ 9.7247],\n",
      "        [ 9.2646],\n",
      "        [10.3219],\n",
      "        [ 8.3444],\n",
      "        [ 8.8711],\n",
      "        [10.1581]], device='cuda:0')\n",
      "4 0\n",
      "100\n",
      "Validation batch...\n",
      "Forward Called\n",
      "tensor([[10.0015],\n",
      "        [ 2.6830],\n",
      "        [ 9.2396],\n",
      "        [10.9557],\n",
      "        [ 2.2766],\n",
      "        [ 9.1832],\n",
      "        [ 9.6915],\n",
      "        [ 8.1037],\n",
      "        [ 1.5703],\n",
      "        [ 8.4925],\n",
      "        [ 9.1960],\n",
      "        [10.0655],\n",
      "        [ 9.5589],\n",
      "        [ 7.5858],\n",
      "        [ 1.7998],\n",
      "        [ 8.1238],\n",
      "        [ 9.7081],\n",
      "        [ 7.9569],\n",
      "        [10.0784],\n",
      "        [ 8.9859],\n",
      "        [ 9.4564],\n",
      "        [10.5010],\n",
      "        [ 8.4093],\n",
      "        [10.4908],\n",
      "        [ 9.2953],\n",
      "        [ 9.5240],\n",
      "        [ 9.6707],\n",
      "        [11.3741],\n",
      "        [10.0128],\n",
      "        [ 9.5593],\n",
      "        [ 9.5570],\n",
      "        [ 9.9576],\n",
      "        [ 7.4062],\n",
      "        [10.1440],\n",
      "        [11.5103],\n",
      "        [ 9.1048],\n",
      "        [ 8.6387],\n",
      "        [ 9.6620],\n",
      "        [10.0138],\n",
      "        [ 9.8791],\n",
      "        [ 7.8137],\n",
      "        [10.3698],\n",
      "        [10.7744],\n",
      "        [10.6167],\n",
      "        [10.6290],\n",
      "        [ 8.8697],\n",
      "        [ 9.1982],\n",
      "        [11.0769],\n",
      "        [ 9.4143],\n",
      "        [ 8.8149],\n",
      "        [11.2479],\n",
      "        [ 7.5433],\n",
      "        [ 1.6040],\n",
      "        [ 8.6999],\n",
      "        [ 8.1317],\n",
      "        [ 7.6968],\n",
      "        [ 8.2499],\n",
      "        [ 8.0932],\n",
      "        [ 9.9089],\n",
      "        [ 8.7500],\n",
      "        [10.5331],\n",
      "        [ 7.3769],\n",
      "        [ 7.9569],\n",
      "        [10.1193],\n",
      "        [ 7.0065],\n",
      "        [ 7.9051],\n",
      "        [ 9.2070],\n",
      "        [ 9.5267],\n",
      "        [ 9.0206],\n",
      "        [ 9.8299],\n",
      "        [ 9.8486],\n",
      "        [ 9.0654],\n",
      "        [10.2127],\n",
      "        [ 1.4804],\n",
      "        [ 9.7631],\n",
      "        [10.6902],\n",
      "        [ 8.2586],\n",
      "        [ 8.8179],\n",
      "        [ 1.8550],\n",
      "        [ 9.1775],\n",
      "        [ 8.1187],\n",
      "        [10.3888],\n",
      "        [ 9.9512],\n",
      "        [ 9.8485],\n",
      "        [ 1.8415],\n",
      "        [ 9.3919],\n",
      "        [ 9.9334],\n",
      "        [ 9.3931],\n",
      "        [ 9.9766],\n",
      "        [ 9.6478],\n",
      "        [ 8.6087],\n",
      "        [10.7718],\n",
      "        [ 8.3738],\n",
      "        [ 7.7266],\n",
      "        [ 9.9821],\n",
      "        [ 8.7607],\n",
      "        [ 8.7022],\n",
      "        [ 9.1620],\n",
      "        [ 8.6446],\n",
      "        [ 1.7858]], device='cuda:0')\n",
      "5 0\n",
      "100\n",
      "Validation batch...\n",
      "Forward Called\n",
      "tensor([[ 9.6945],\n",
      "        [10.0518],\n",
      "        [ 8.6460],\n",
      "        [ 8.7971],\n",
      "        [10.2117],\n",
      "        [ 1.5943],\n",
      "        [ 8.0433],\n",
      "        [ 9.1367],\n",
      "        [ 8.6520],\n",
      "        [ 1.4007],\n",
      "        [ 8.4771],\n",
      "        [10.6677],\n",
      "        [ 9.8307],\n",
      "        [ 9.5114],\n",
      "        [ 9.4032],\n",
      "        [ 9.9604],\n",
      "        [ 1.1844],\n",
      "        [ 9.4682],\n",
      "        [ 9.6034],\n",
      "        [10.7487],\n",
      "        [ 8.8598],\n",
      "        [ 8.0599],\n",
      "        [ 9.8712],\n",
      "        [ 9.7664],\n",
      "        [10.9289],\n",
      "        [ 9.4391],\n",
      "        [ 9.1830],\n",
      "        [ 2.2283],\n",
      "        [ 8.8365],\n",
      "        [ 9.4515],\n",
      "        [ 8.7101],\n",
      "        [10.4141],\n",
      "        [ 1.5168],\n",
      "        [10.0922],\n",
      "        [11.1118],\n",
      "        [10.8237],\n",
      "        [ 8.8767],\n",
      "        [ 9.4763],\n",
      "        [ 2.8474],\n",
      "        [ 8.6668],\n",
      "        [10.2002],\n",
      "        [ 9.6725],\n",
      "        [ 9.6039],\n",
      "        [ 8.5775],\n",
      "        [ 1.1455],\n",
      "        [ 8.3414],\n",
      "        [ 8.5067],\n",
      "        [ 8.2071],\n",
      "        [ 1.4263],\n",
      "        [10.5305],\n",
      "        [ 2.0465],\n",
      "        [ 8.6443],\n",
      "        [ 9.0236],\n",
      "        [10.1153],\n",
      "        [ 8.3576],\n",
      "        [ 1.7203],\n",
      "        [ 9.9649],\n",
      "        [ 8.4658],\n",
      "        [ 2.2306],\n",
      "        [ 1.3199],\n",
      "        [ 7.7621],\n",
      "        [ 9.8481],\n",
      "        [ 1.7460],\n",
      "        [10.1715],\n",
      "        [10.8200],\n",
      "        [ 9.9613],\n",
      "        [10.3838],\n",
      "        [ 8.6652],\n",
      "        [10.6854],\n",
      "        [ 1.6385],\n",
      "        [ 8.8819],\n",
      "        [ 1.6250],\n",
      "        [ 8.0807],\n",
      "        [10.2111],\n",
      "        [ 0.6818],\n",
      "        [ 8.1198],\n",
      "        [ 8.3796],\n",
      "        [10.1330],\n",
      "        [ 8.1502],\n",
      "        [ 9.2559],\n",
      "        [ 9.4961],\n",
      "        [ 1.6628],\n",
      "        [ 8.3989],\n",
      "        [10.4971],\n",
      "        [ 1.0631],\n",
      "        [10.1484],\n",
      "        [ 8.4331],\n",
      "        [ 2.4177],\n",
      "        [ 2.0724],\n",
      "        [ 9.7601],\n",
      "        [ 1.4945],\n",
      "        [10.6161],\n",
      "        [10.9434],\n",
      "        [ 9.3624],\n",
      "        [ 9.9107],\n",
      "        [ 8.5505],\n",
      "        [ 9.1034],\n",
      "        [ 9.1085],\n",
      "        [ 8.4533],\n",
      "        [10.2481]], device='cuda:0')\n",
      "6 0\n",
      "0\n",
      "will break\n",
      "Epoch: 4/5..  Training Loss: 0.002..  Test Loss: 0.002..  Test Accuracy: 0.918\n",
      "1 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.17439666390419006\n",
      "2 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.16390301287174225\n",
      "3 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.12893612682819366\n",
      "4 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.18886741995811462\n",
      "5 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.13375090062618256\n",
      "6 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.19551905989646912\n",
      "7 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15885001420974731\n",
      "8 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2645756006240845\n",
      "9 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.22160868346691132\n",
      "10 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.21577642858028412\n",
      "11 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14762872457504272\n",
      "12 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.10794434696435928\n",
      "13 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.11956412345170975\n",
      "14 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1939169317483902\n",
      "15 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.19967547059059143\n",
      "16 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.18043860793113708\n",
      "17 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.18854114413261414\n",
      "18 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15042568743228912\n",
      "19 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.26521849632263184\n",
      "20 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14541995525360107\n",
      "21 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.20233938097953796\n",
      "22 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.20804962515830994\n",
      "23 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15956634283065796\n",
      "24 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.17851929366588593\n",
      "25 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.26354414224624634\n",
      "26 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.219253271818161\n",
      "27 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.20283691585063934\n",
      "28 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.175750732421875\n",
      "29 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.16394899785518646\n",
      "30 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14688917994499207\n",
      "31 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.11651173233985901\n",
      "32 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.17608749866485596\n",
      "33 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.18530182540416718\n",
      "34 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.19599197804927826\n",
      "35 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.16133879125118256\n",
      "36 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.20640872418880463\n",
      "37 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.22100570797920227\n",
      "38 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14376485347747803\n",
      "39 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.22021621465682983\n",
      "40 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1316947340965271\n",
      "41 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.12113997340202332\n",
      "42 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.11824096739292145\n",
      "43 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.12599733471870422\n",
      "44 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.16290263831615448\n",
      "45 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.15930336713790894\n",
      "46 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1835395246744156\n",
      "47 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14130569994449615\n",
      "48 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.18961627781391144\n",
      "49 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.0938001275062561\n",
      "50 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.11859460920095444\n",
      "51 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1232224777340889\n",
      "52 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.23522813618183136\n",
      "53 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.11352916806936264\n",
      "54 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14139774441719055\n",
      "55 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1526716947555542\n",
      "56 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14205732941627502\n",
      "57 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.19767992198467255\n",
      "58 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1744154989719391\n",
      "59 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.20852376520633698\n",
      "60 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1241738349199295\n",
      "61 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.16055993735790253\n",
      "62 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14470350742340088\n",
      "63 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1489650160074234\n",
      "64 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.19074228405952454\n",
      "65 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.38974517583847046\n",
      "66 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2339639514684677\n",
      "67 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.19119128584861755\n",
      "68 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.10244804620742798\n",
      "69 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14641091227531433\n",
      "70 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.2147665172815323\n",
      "71 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14658060669898987\n",
      "72 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1453189253807068\n",
      "73 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1465143859386444\n",
      "74 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.14373931288719177\n",
      "75 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.13170339167118073\n",
      "76 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.1460319459438324\n",
      "77 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.22385786473751068\n",
      "78 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.13502290844917297\n",
      "79 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.12931427359580994\n",
      "80 0\n",
      "100\n",
      "Training batch...\n",
      "labels.shape: (100,)\n",
      "Running torch\n",
      "Forward Called\n",
      "output.shape: torch.Size([100, 7])\n",
      "Calculating loss\n",
      "Back prop.\n",
      "Batch loss: 0.190629780292511\n",
      "81 0\n",
      "0\n",
      "will break\n",
      "1 0\n",
      "100\n",
      "Validation batch...\n",
      "Forward Called\n",
      "tensor([[ 9.2724],\n",
      "        [ 9.3030],\n",
      "        [ 8.9833],\n",
      "        [ 9.9767],\n",
      "        [11.2028],\n",
      "        [ 8.8089],\n",
      "        [ 2.1813],\n",
      "        [ 9.5885],\n",
      "        [ 7.1439],\n",
      "        [ 1.5973],\n",
      "        [ 9.3170],\n",
      "        [10.0616],\n",
      "        [ 8.4836],\n",
      "        [ 8.3238],\n",
      "        [10.4134],\n",
      "        [ 8.9071],\n",
      "        [ 2.0191],\n",
      "        [10.6855],\n",
      "        [ 8.9960],\n",
      "        [11.5365],\n",
      "        [10.6884],\n",
      "        [ 9.8746],\n",
      "        [ 9.8422],\n",
      "        [10.6914],\n",
      "        [ 8.3730],\n",
      "        [10.7510],\n",
      "        [ 3.2974],\n",
      "        [ 9.5068],\n",
      "        [ 7.7226],\n",
      "        [ 8.5129],\n",
      "        [ 0.8868],\n",
      "        [10.6739],\n",
      "        [ 9.7008],\n",
      "        [ 8.0760],\n",
      "        [10.0225],\n",
      "        [10.1055],\n",
      "        [ 9.2015],\n",
      "        [ 2.9593],\n",
      "        [11.4098],\n",
      "        [ 8.8841],\n",
      "        [ 9.8050],\n",
      "        [ 2.1958],\n",
      "        [11.3066],\n",
      "        [11.2314],\n",
      "        [10.6641],\n",
      "        [ 1.7206],\n",
      "        [11.0226],\n",
      "        [10.4237],\n",
      "        [ 7.8511],\n",
      "        [10.6712],\n",
      "        [10.0163],\n",
      "        [10.5247],\n",
      "        [ 9.5309],\n",
      "        [11.3456],\n",
      "        [11.0851],\n",
      "        [11.5038],\n",
      "        [ 9.4212],\n",
      "        [11.3067],\n",
      "        [10.9134],\n",
      "        [10.0757],\n",
      "        [ 1.6958],\n",
      "        [12.0193],\n",
      "        [ 9.5315],\n",
      "        [ 2.4173],\n",
      "        [ 1.2658],\n",
      "        [10.7118],\n",
      "        [10.9502],\n",
      "        [11.0648],\n",
      "        [10.2978],\n",
      "        [ 7.7210],\n",
      "        [ 9.0594],\n",
      "        [ 0.8508],\n",
      "        [ 9.9230],\n",
      "        [ 9.9689],\n",
      "        [ 9.0386],\n",
      "        [11.1393],\n",
      "        [ 2.3734],\n",
      "        [ 9.6925],\n",
      "        [11.2482],\n",
      "        [11.0632],\n",
      "        [10.8827],\n",
      "        [ 2.8834],\n",
      "        [ 8.0607],\n",
      "        [ 9.6714],\n",
      "        [ 8.3562],\n",
      "        [ 8.4491],\n",
      "        [ 9.5711],\n",
      "        [ 8.0191],\n",
      "        [10.7342],\n",
      "        [10.0427],\n",
      "        [ 9.4988],\n",
      "        [11.1946],\n",
      "        [ 9.9387],\n",
      "        [ 0.9885],\n",
      "        [ 8.8556],\n",
      "        [ 9.6142],\n",
      "        [10.9039],\n",
      "        [11.7019],\n",
      "        [11.2314],\n",
      "        [ 8.5842]], device='cuda:0')\n",
      "2 0\n",
      "100\n",
      "Validation batch...\n",
      "Forward Called\n",
      "tensor([[ 1.3922],\n",
      "        [ 9.6160],\n",
      "        [10.2389],\n",
      "        [10.4479],\n",
      "        [ 8.8337],\n",
      "        [ 9.3272],\n",
      "        [10.3826],\n",
      "        [11.2263],\n",
      "        [ 8.8093],\n",
      "        [10.4996],\n",
      "        [ 9.1542],\n",
      "        [ 8.4623],\n",
      "        [10.2880],\n",
      "        [ 2.6405],\n",
      "        [10.0139],\n",
      "        [10.4992],\n",
      "        [10.4267],\n",
      "        [ 1.4473],\n",
      "        [10.6566],\n",
      "        [10.1469],\n",
      "        [ 5.4089],\n",
      "        [ 9.8696],\n",
      "        [11.5194],\n",
      "        [ 8.2735],\n",
      "        [ 9.3382],\n",
      "        [10.9553],\n",
      "        [11.2676],\n",
      "        [ 9.9468],\n",
      "        [10.1373],\n",
      "        [ 1.5127],\n",
      "        [ 8.6311],\n",
      "        [10.6547],\n",
      "        [ 1.6244],\n",
      "        [ 8.7202],\n",
      "        [10.7871],\n",
      "        [ 7.7164],\n",
      "        [ 2.0263],\n",
      "        [ 9.0243],\n",
      "        [10.7016],\n",
      "        [10.4202],\n",
      "        [ 1.8050],\n",
      "        [11.7048],\n",
      "        [ 9.0774],\n",
      "        [ 2.3306],\n",
      "        [11.5582],\n",
      "        [10.0965],\n",
      "        [ 7.9725],\n",
      "        [ 1.1028],\n",
      "        [ 1.3088],\n",
      "        [10.3905],\n",
      "        [ 8.6764],\n",
      "        [ 8.3745],\n",
      "        [10.2166],\n",
      "        [11.0870],\n",
      "        [ 8.0973],\n",
      "        [ 8.9076],\n",
      "        [ 8.9471],\n",
      "        [ 1.4940],\n",
      "        [ 8.6390],\n",
      "        [10.8104],\n",
      "        [ 1.1284],\n",
      "        [11.2960],\n",
      "        [10.5057],\n",
      "        [ 2.0434],\n",
      "        [ 9.8012],\n",
      "        [ 1.6402],\n",
      "        [10.7008],\n",
      "        [ 9.2620],\n",
      "        [11.0599],\n",
      "        [ 8.3744],\n",
      "        [ 1.6618],\n",
      "        [ 9.3419],\n",
      "        [ 8.5822],\n",
      "        [ 9.2409],\n",
      "        [ 2.1811],\n",
      "        [ 2.7705],\n",
      "        [10.6685],\n",
      "        [11.2192],\n",
      "        [10.4843],\n",
      "        [ 9.0963],\n",
      "        [10.3952],\n",
      "        [ 8.8723],\n",
      "        [10.2880],\n",
      "        [ 8.7288],\n",
      "        [ 8.6821],\n",
      "        [11.7140],\n",
      "        [ 1.1399],\n",
      "        [ 8.8963],\n",
      "        [ 9.8773],\n",
      "        [ 1.9109],\n",
      "        [ 9.1629],\n",
      "        [ 9.8821],\n",
      "        [10.3192],\n",
      "        [10.6866],\n",
      "        [11.4284],\n",
      "        [10.0682],\n",
      "        [ 0.9808],\n",
      "        [10.4941],\n",
      "        [ 1.4022],\n",
      "        [ 9.5682]], device='cuda:0')\n",
      "3 0\n",
      "100\n",
      "Validation batch...\n",
      "Forward Called\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9.0516],\n",
      "        [10.8068],\n",
      "        [ 1.4009],\n",
      "        [10.7986],\n",
      "        [ 9.4712],\n",
      "        [ 2.3288],\n",
      "        [11.4690],\n",
      "        [ 1.0607],\n",
      "        [11.3359],\n",
      "        [ 1.2063],\n",
      "        [ 9.7977],\n",
      "        [10.7718],\n",
      "        [ 9.5271],\n",
      "        [10.9932],\n",
      "        [ 8.5167],\n",
      "        [11.4982],\n",
      "        [ 8.4056],\n",
      "        [ 9.2413],\n",
      "        [10.7575],\n",
      "        [10.3229],\n",
      "        [12.0320],\n",
      "        [10.0070],\n",
      "        [11.0608],\n",
      "        [ 1.6975],\n",
      "        [10.1270],\n",
      "        [11.4766],\n",
      "        [12.1439],\n",
      "        [ 9.0380],\n",
      "        [11.4270],\n",
      "        [10.2053],\n",
      "        [ 1.2409],\n",
      "        [ 2.1674],\n",
      "        [ 2.3477],\n",
      "        [ 8.4029],\n",
      "        [10.8198],\n",
      "        [10.1883],\n",
      "        [ 1.2521],\n",
      "        [10.6623],\n",
      "        [ 9.7023],\n",
      "        [ 9.3217],\n",
      "        [11.1509],\n",
      "        [11.5251],\n",
      "        [ 0.7859],\n",
      "        [10.8997],\n",
      "        [ 1.5020],\n",
      "        [10.7435],\n",
      "        [ 8.3190],\n",
      "        [10.0289],\n",
      "        [ 9.4193],\n",
      "        [ 9.6556],\n",
      "        [11.3011],\n",
      "        [ 1.6949],\n",
      "        [ 9.8142],\n",
      "        [ 8.4103],\n",
      "        [ 9.3655],\n",
      "        [ 9.7199],\n",
      "        [ 9.8468],\n",
      "        [11.5518],\n",
      "        [ 8.2862],\n",
      "        [ 9.2170],\n",
      "        [10.3353],\n",
      "        [ 8.5776],\n",
      "        [10.5398],\n",
      "        [ 9.3329],\n",
      "        [ 1.0065],\n",
      "        [ 9.0419],\n",
      "        [11.4561],\n",
      "        [ 8.6972],\n",
      "        [11.0045],\n",
      "        [ 9.0720],\n",
      "        [10.2684],\n",
      "        [ 8.8993],\n",
      "        [ 7.6546],\n",
      "        [ 8.2273],\n",
      "        [ 2.5380],\n",
      "        [ 8.5883],\n",
      "        [ 9.4833],\n",
      "        [ 8.5782],\n",
      "        [ 9.3265],\n",
      "        [ 8.4347],\n",
      "        [ 8.2743],\n",
      "        [ 0.9572],\n",
      "        [10.3348],\n",
      "        [11.5442],\n",
      "        [10.5318],\n",
      "        [ 8.6866],\n",
      "        [ 9.1036],\n",
      "        [10.2528],\n",
      "        [10.9063],\n",
      "        [ 9.6564],\n",
      "        [ 8.5911],\n",
      "        [ 9.2205],\n",
      "        [10.7089],\n",
      "        [ 8.2707],\n",
      "        [10.0463],\n",
      "        [ 9.0131],\n",
      "        [10.8882],\n",
      "        [ 8.5003],\n",
      "        [ 8.6317],\n",
      "        [11.0103]], device='cuda:0')\n",
      "4 0\n",
      "100\n",
      "Validation batch...\n",
      "Forward Called\n",
      "tensor([[10.3339],\n",
      "        [ 2.3088],\n",
      "        [ 9.8066],\n",
      "        [11.4608],\n",
      "        [ 2.1635],\n",
      "        [ 9.2263],\n",
      "        [10.2972],\n",
      "        [ 8.3114],\n",
      "        [ 1.2906],\n",
      "        [ 9.1763],\n",
      "        [ 9.6654],\n",
      "        [10.8414],\n",
      "        [ 9.6707],\n",
      "        [ 8.0968],\n",
      "        [ 1.6441],\n",
      "        [ 8.7643],\n",
      "        [ 9.7665],\n",
      "        [ 8.1076],\n",
      "        [10.5728],\n",
      "        [ 8.9107],\n",
      "        [ 9.6373],\n",
      "        [10.7872],\n",
      "        [ 8.7741],\n",
      "        [11.0944],\n",
      "        [ 9.0625],\n",
      "        [10.0620],\n",
      "        [10.3082],\n",
      "        [11.5292],\n",
      "        [10.8121],\n",
      "        [10.2345],\n",
      "        [ 9.5939],\n",
      "        [10.5309],\n",
      "        [ 7.9623],\n",
      "        [ 9.7280],\n",
      "        [11.7334],\n",
      "        [ 9.8103],\n",
      "        [ 9.4700],\n",
      "        [10.0197],\n",
      "        [ 9.9501],\n",
      "        [10.0808],\n",
      "        [ 8.3297],\n",
      "        [11.1905],\n",
      "        [11.3092],\n",
      "        [11.1954],\n",
      "        [11.2999],\n",
      "        [ 9.3281],\n",
      "        [ 9.7713],\n",
      "        [11.5138],\n",
      "        [ 9.3185],\n",
      "        [ 9.1600],\n",
      "        [11.6523],\n",
      "        [ 7.6318],\n",
      "        [ 1.2578],\n",
      "        [ 9.3342],\n",
      "        [ 8.3806],\n",
      "        [ 8.3388],\n",
      "        [ 8.9406],\n",
      "        [ 8.6239],\n",
      "        [10.0663],\n",
      "        [ 9.6318],\n",
      "        [11.2043],\n",
      "        [ 8.1325],\n",
      "        [ 8.2872],\n",
      "        [10.0754],\n",
      "        [ 7.7187],\n",
      "        [ 8.3361],\n",
      "        [ 9.4276],\n",
      "        [ 9.8482],\n",
      "        [ 9.8181],\n",
      "        [ 9.7652],\n",
      "        [ 9.8265],\n",
      "        [ 9.0770],\n",
      "        [10.1272],\n",
      "        [ 1.3310],\n",
      "        [10.0027],\n",
      "        [11.4007],\n",
      "        [ 8.6372],\n",
      "        [ 9.6123],\n",
      "        [ 1.4833],\n",
      "        [ 9.0720],\n",
      "        [ 8.6303],\n",
      "        [10.7949],\n",
      "        [10.8007],\n",
      "        [10.4374],\n",
      "        [ 1.5353],\n",
      "        [ 9.5396],\n",
      "        [10.6014],\n",
      "        [10.0191],\n",
      "        [10.4583],\n",
      "        [ 9.6215],\n",
      "        [ 9.1843],\n",
      "        [11.4955],\n",
      "        [ 9.0866],\n",
      "        [ 8.1942],\n",
      "        [10.0549],\n",
      "        [ 9.1256],\n",
      "        [ 9.0835],\n",
      "        [ 9.1708],\n",
      "        [ 8.3984],\n",
      "        [ 1.6146]], device='cuda:0')\n",
      "5 0\n",
      "100\n",
      "Validation batch...\n",
      "Forward Called\n",
      "tensor([[10.2446],\n",
      "        [10.2096],\n",
      "        [ 9.2798],\n",
      "        [ 9.5734],\n",
      "        [10.8105],\n",
      "        [ 1.4291],\n",
      "        [ 8.4736],\n",
      "        [ 9.3770],\n",
      "        [ 9.1049],\n",
      "        [ 0.9488],\n",
      "        [ 8.6464],\n",
      "        [10.6541],\n",
      "        [10.5923],\n",
      "        [ 9.6434],\n",
      "        [ 9.9278],\n",
      "        [10.6558],\n",
      "        [ 0.7611],\n",
      "        [10.1416],\n",
      "        [10.3670],\n",
      "        [10.8609],\n",
      "        [ 9.1744],\n",
      "        [ 8.7492],\n",
      "        [10.7221],\n",
      "        [ 9.6755],\n",
      "        [11.5143],\n",
      "        [ 9.9494],\n",
      "        [ 9.7245],\n",
      "        [ 2.1438],\n",
      "        [ 9.6707],\n",
      "        [10.0883],\n",
      "        [ 9.4076],\n",
      "        [10.6309],\n",
      "        [ 1.2089],\n",
      "        [10.0013],\n",
      "        [11.7880],\n",
      "        [11.1460],\n",
      "        [ 9.1376],\n",
      "        [10.2431],\n",
      "        [ 2.4231],\n",
      "        [ 8.8691],\n",
      "        [10.3629],\n",
      "        [ 9.6400],\n",
      "        [10.1887],\n",
      "        [ 8.2757],\n",
      "        [ 0.8006],\n",
      "        [ 8.9548],\n",
      "        [ 9.0072],\n",
      "        [ 8.8249],\n",
      "        [ 1.1962],\n",
      "        [10.8483],\n",
      "        [ 1.8021],\n",
      "        [ 9.2499],\n",
      "        [ 9.5543],\n",
      "        [10.9614],\n",
      "        [ 8.7919],\n",
      "        [ 1.5447],\n",
      "        [10.5231],\n",
      "        [ 8.6286],\n",
      "        [ 2.0629],\n",
      "        [ 1.0368],\n",
      "        [ 8.2444],\n",
      "        [10.4256],\n",
      "        [ 1.7247],\n",
      "        [10.8405],\n",
      "        [11.3753],\n",
      "        [10.6625],\n",
      "        [10.4347],\n",
      "        [ 8.3282],\n",
      "        [10.8735],\n",
      "        [ 1.4243],\n",
      "        [ 8.7779],\n",
      "        [ 1.4456],\n",
      "        [ 8.7272],\n",
      "        [10.6903],\n",
      "        [ 1.2397],\n",
      "        [ 8.6071],\n",
      "        [ 8.8895],\n",
      "        [10.9500],\n",
      "        [ 8.6745],\n",
      "        [ 8.4143],\n",
      "        [10.2534],\n",
      "        [ 1.5281],\n",
      "        [ 9.1012],\n",
      "        [10.5855],\n",
      "        [ 0.9053],\n",
      "        [10.4053],\n",
      "        [ 8.8228],\n",
      "        [ 1.9607],\n",
      "        [ 1.9824],\n",
      "        [ 9.6136],\n",
      "        [ 1.2958],\n",
      "        [10.7143],\n",
      "        [11.5182],\n",
      "        [10.0112],\n",
      "        [10.4221],\n",
      "        [ 9.2210],\n",
      "        [ 9.3646],\n",
      "        [ 8.8844],\n",
      "        [ 9.0322],\n",
      "        [10.2543]], device='cuda:0')\n",
      "6 0\n",
      "0\n",
      "will break\n",
      "Epoch: 5/5..  Training Loss: 0.002..  Test Loss: 0.002..  Test Accuracy: 0.920\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(torchModel.parameters(), lr=0.003)\n",
    "optimizer = optim.Adam(torchModel.parameters(), lr=0.0015)\n",
    "\n",
    "epochs = 15\n",
    "steps = 0\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "torchModel.to(device)\n",
    "#optimizer.to(device)\n",
    "criterion.to(device)\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in mMiniBatcherTrain.getBatchIterator():\n",
    "        print('Training batch...')\n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        print(f'labels.shape: {labels.shape}')\n",
    "        labels = torch.from_numpy(labels).to(device)\n",
    "        \n",
    "        print('Running torch')\n",
    "        output = torchModel(images)\n",
    "        \n",
    "        print(f'output.shape: {output.shape}')\n",
    "        print('Calculating loss')\n",
    "        \n",
    "        loss = criterion(output, labels)\n",
    "        print('Back prop.')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss = loss.item()\n",
    "        print(f'Batch loss: {batch_loss}')\n",
    "        running_loss += batch_loss\n",
    "        \n",
    "   \n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    # Turn off gradients for validation, saves memory and computations\n",
    "    with torch.no_grad():\n",
    "        torchModel.eval()\n",
    "        for images, labels in mMiniBatcherTest.getBatchIterator():\n",
    "            print('Validation batch...')\n",
    "            #labels = torch.from_numpy(labels.values).type(torch.FloatTensor)\n",
    "            labels = torch.from_numpy(labels).to(device)\n",
    "            output = torchModel(images)\n",
    "            test_loss += criterion(output, labels).to('cpu') #Want the loss on CPU\n",
    "\n",
    "            top_p, top_class = output.topk(1, dim=1)\n",
    "            print(top_p)\n",
    "            #top_p_target, top_class_target = labels.topk(1, dim=1)\n",
    "            #equals = top_class == top_class_target\n",
    "            equals = top_class == labels.view(top_class.shape)\n",
    "            accuracy += torch.sum(equals.type(torch.FloatTensor)).to('cpu')\n",
    "\n",
    "    torchModel.train()\n",
    "\n",
    "    train_losses.append(running_loss/len(mMiniBatcherTrain.X))\n",
    "    test_losses.append(test_loss/len(mMiniBatcherTest.X))\n",
    "\n",
    "    print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "          \"Training Loss: {:.3f}.. \".format(train_losses[-1]),\n",
    "          \"Test Loss: {:.3f}.. \".format(test_losses[-1]),\n",
    "          \"Test Accuracy: {:.3f}\".format(accuracy/len(mMiniBatcherTest.X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "adapted-vacuum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x25cc875ddf0>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "special-delta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TorchNLP(\n",
       "  (Bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(50325, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (TorchModel): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=64, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchModel.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "capital-clerk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchModel.Bert.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "structured-headline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Called\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4626, -1.5387, -1.6581,  5.5220, -1.1519, -1.9339, -0.4945],\n",
       "        [-2.4869, -2.2417, -0.1596,  5.9095, -0.8429, -2.5162, -0.1103],\n",
       "        [-2.2634, -1.6346,  0.2437,  5.0969, -1.4610, -0.9196,  0.4518],\n",
       "        [-1.4876, -2.0991, -1.3574,  5.9189, -0.3710, -3.3775, -0.0616],\n",
       "        [-1.9867, -2.1058, -0.8074,  5.6330, -0.1044, -3.1820, -0.1562],\n",
       "        [-2.2982, -2.8106, -0.7049,  5.6376, -0.9757, -1.1950, -0.0750],\n",
       "        [-1.3132, -0.8251, -0.8038,  4.2634, -0.0722, -2.5963,  0.0976],\n",
       "        [-1.7288, -1.0971, -0.2127,  5.4893, -1.3920, -1.5332,  0.2278],\n",
       "        [-2.0425, -1.3268, -1.0715,  5.6121, -0.3769, -1.5521,  0.0577],\n",
       "        [-1.2958, -1.1475, -0.4645,  3.3163, -0.1179, -1.1458, -0.0809],\n",
       "        [-2.9055, -2.2610, -0.9447,  6.2404, -0.8267, -2.1755,  0.2848],\n",
       "        [-2.0705, -1.8187, -1.2083,  5.5571, -0.0396, -2.7881,  0.2048],\n",
       "        [-1.7872, -2.5268, -1.0414,  4.4269, -0.7507, -0.7875,  0.1495],\n",
       "        [-2.2243, -2.2796, -0.6230,  5.6976, -1.0154, -1.8560,  0.7660],\n",
       "        [-2.0808, -2.6473, -0.5863,  5.9454, -0.7398, -2.9108, -0.1682],\n",
       "        [-1.1619, -0.5904, -0.0986,  3.2129, -1.1888, -0.2766,  0.5494],\n",
       "        [-2.0235, -1.0664, -0.0868,  5.7351, -0.2674, -1.5629,  0.4473],\n",
       "        [-2.3887, -2.2231,  0.0325,  5.7711, -0.7572, -2.3600, -0.0986],\n",
       "        [-1.7973, -2.4545, -1.1000,  5.7570, -0.9475, -1.9836, -0.5926],\n",
       "        [-1.5662, -1.6547, -1.4485,  3.7843, -1.4425, -1.8323,  0.2154],\n",
       "        [-0.4742, -1.3688, -0.9707,  4.1654,  0.0107, -1.2688, -0.6327],\n",
       "        [-3.1214, -3.0270, -0.7252,  6.3862, -1.0545, -1.4159,  0.7737],\n",
       "        [-2.4808, -2.2597, -0.4638,  6.2402, -0.3606, -2.1318,  0.1496],\n",
       "        [-2.0498, -2.1140, -1.6466,  5.2267, -2.0208, -1.0849, -0.2112],\n",
       "        [-2.6305, -2.2619, -0.7004,  6.7615, -0.9292, -2.4601, -0.0890]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchModel(X_test[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "assigned-credits",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Called\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, 3, 3, 4, 3, 6, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 2, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 2, 3,\n",
       "       4, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 6, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = torchModel.predict(X_test[200:300])\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "interesting-pizza",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, 3, 3, 4, 3, 2, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 2, 3, 3, 3, 3, 3, 3, 2, 4, 3, 3, 3, 3, 6, 3, 3, 3, 3, 3, 2, 3,\n",
       "       4, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 6, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = Y_test[200:300]\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "colonial-advertising",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x25cbea031f0>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(targets, Y_pred, normalize='true', labels=list(set(Y_test)))\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(set(Y_test))).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-aquatic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
